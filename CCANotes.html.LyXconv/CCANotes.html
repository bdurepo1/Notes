<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<meta name="generator" content="http://www.nongnu.org/elyxer/"/>
<meta name="create-date" content="2016-08-07"/>
<link rel="stylesheet" href="http://elyxer.nongnu.org/lyx.css" type="text/css" media="all"/>
<title>Notes on Computability, Complexity, and Algorithms – An Ode to the Unprepared Student</title>
</head>
<body>
<div id="globalWrapper">
<h1 class="title">
Notes on Computability, Complexity, and Algorithms – An Ode to the Unprepared Student
</h1>
<h2 class="author">
Brandon A. Durepo, <a class="FlexURL" href="bdurepo@gatech.edu">bdurepo@gatech.edu</a>
</h2>
<blockquote class="Quote">
<div class="right">
&ldquo;Sapere aude.&rdquo; – Horace
</div>

</blockquote>
<div class="fulltoc">
<div class="tocheader">
Table of Contents
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section--1">Section: Preface</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Part-I">Part I: Mathematics and Logic</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section-1">Section 1: Discrete Mathematics</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-1.1">Subsection 1.1: Propositional and Sentential Logic</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.2">Subsection 1.2: Predicate Calculus and Quantification Logic</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.3">Subsection 1.3: Rules of Inference</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.4">Subsection 1.4: Proofs</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.4.1">Subsubsection 1.4.1: Terminology of Proofs</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.4.2">Subsubsection 1.4.2: Types of Proofs</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.4.3">Subsubsection 1.4.3: Strategies for Constructing Proofs</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.5">Subsection 1.5: Sets</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.5.1">Subsubsection 1.5.1: Classification of Groups by Formulating Subsets</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.6">Subsection 1.6: Relations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.7">Subsection 1.7: Functions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.8">Subsection 1.8: Recursion and Induction</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.9">Subsection 1.9: Modular Arithmetic</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-2">Section 2: Calculus and Real Analysis</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-2.1">Subsection 2.1: Sequences and Series</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.2">Subsection 2.2: Topology of Real Numbers</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.3">Subsection 2.3: Functional Limits and Continuity</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.4">Subsection 2.4: Derivatives</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.5">Subsection 2.5: Sequences and Series of Functions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.6">Subsection 2.6: Riemann Integral</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.7">Subsection 2.7: Cantor Diagonalization</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-3">Section 3: Probability and Statistics</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-3.1">Subsection 3.1: Discrete Probability Distributions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.2">Subsection 3.2: Continuous Probability Distributions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.3">Subsection 3.3: Combinatorics</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-3.3.1">Subsubsection 3.3.1: The Product Rule</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-3.3.2">Subsubsection 3.3.2: The Sum Rule</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-3.3.3">Subsubsection 3.3.3: The Subtraction Rule or The Inclusion Exclusion Principle</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-3.3.4">Subsubsection 3.3.4: The Division Rule</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-3.3.5">Subsubsection 3.3.5: The Pigeonhole Principle (Dirichlet Drawer Principle)</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.4">Subsection 3.4: Permutations and Combinations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.5">Subsection 3.5: Finite Probability</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.6">Subsection 3.6: Nonuniform Probability</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.7">Subsection 3.7: Conditional Probability</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.8">Subsection 3.8: Bernoulli Trials</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.9">Subsection 3.9: Random Variables</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.10">Subsection 3.10: Expected Value and Variance</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.11">Subsection 3.11: Limit Theorems</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-4">Section 4: Linear Algebra and Integer Linear Programming</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-4.1">Subsection 4.1: Linear Equations in Linear Algebra</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.2">Subsection 4.2: Matrix Algebra</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.3">Subsection 4.3: Determinants</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.4">Subsection 4.4: Vector Spaces</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.5">Subsection 4.5: Eigenvalues and Eigenvectors</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.6">Subsection 4.6: Orthogonality and Least Squares</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.7">Subsection 4.7: Symmetric Matrices and Quadratic Forms</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.8">Subsection 4.8: Geometry of Vector Spaces</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.9">Subsection 4.9: Basic Properties of Linear Programs</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.10">Subsection 4.10: The Simplex Method</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.11">Subsection 4.11: Duality and the Complementary</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.12">Subsection 4.12: Interior Point Methods</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Part-II">Part II: Computability</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section-5">Section 5: Deterministic Finite Automata</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-5.1">Subsection 5.1: Notation of DFA’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-5.2">Subsection 5.2: Computation of DFA’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-5.3">Subsection 5.3: Regular Languages</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-6">Section 6: Nondeterministic Finite Automata</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-6.1">Subsection 6.1: Proof of Equivalence of NFA’s and DFA’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-6.2">Subsection 6.2: Conversion from NFA to DFA</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-7">Section 7: <span class="formula"></span>NFA’s</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-7.1">Subsection 7.1: Closure of States</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-8">Section 8: Regular Expressions</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-8.1">Subsection 8.1: Precedence of Operators on Regular Expressions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-8.2">Subsection 8.2: Algebraic Laws and Identities of Regular Expressions</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-9">Section 9: Properties of Language Classes</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-9.1">Subsection 9.1: Decision Properties of Regular Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.1.1">Subsubsection 9.1.1: The Membership Test for Regular Languages </a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.1.2">Subsubsection 9.1.2: The Emptiness Test for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.1.3">Subsubsection 9.1.3: The Equivalence Test for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.1.4">Subsubsection 9.1.4: The Infiniteness Test for Regular Languages</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-9.2">Subsection 9.2: Closure Properties of Regular Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.1">Subsubsection 9.2.1: Union for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.2">Subsubsection 9.2.2: Intersection for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.3">Subsubsection 9.2.3: Difference for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.4">Subsubsection 9.2.4: Concatenation for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.5">Subsubsection 9.2.5: Kleene Closure for Regular Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-9.2.6">Subsubsection 9.2.6: Complement for Regular Languages</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-10">Section 10: Conversion of Language Representations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-11">Section 11: DFA Minimization</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-11.1">Subsection 11.1: DFA Minimization Algorithm</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-12">Section 12: The Pumping Lemma for Regular Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-12.1">Subsection 12.1: Using the Pumping Lemma to Prove a Language is Nonregular</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-13">Section 13: Context Free Grammars</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-13.1">Subsection 13.1: CFG Nomenclature</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-13.2">Subsection 13.2: Conventional Usage of Context Free Grammars</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-13.3">Subsection 13.3: Context-Free Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-13.4">Subsection 13.4: Leftmost and Rightmost Derivations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-13.5">Subsection 13.5: Normal Forms for CFG’s</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-13.5.1">Subsubsection 13.5.1: Eliminating Useless Variables from CFG’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-13.5.2">Subsubsection 13.5.2: Eliminating Epsilon Productions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-13.5.3">Subsubsection 13.5.3: Eliminating Unit Productions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-13.5.4">Subsubsection 13.5.4: Representing Grammars in Chomsky Normal Form (CNF)</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-14">Section 14: Pushdown Automata</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-14.1">Subsection 14.1: Conventional Usage of Pushdown Automata</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-14.2">Subsection 14.2: Instantaneous Descriptions and the Goes-To Relation</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-14.3">Subsection 14.3: PDA Language Descriptions</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-15">Section 15: Equivalence of CFG’s and PDA’s</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-15.1">Subsection 15.1: Converting CFG’s <span class="formula"></span> PDA’s</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-15.1.1">Subsubsection 15.1.1: Creating the Transition Function</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-15.1.2">Subsubsection 15.1.2: Proof of Equivalence between CFG and PDA</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-15.2">Subsection 15.2: Converting PDA’s <span class="formula"></span> CFG’s</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-15.2.1">Subsubsection 15.2.1: Constructing Variables of the CFG</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-15.2.2">Subsubsection 15.2.2: Constructing Productions of the CFG</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-16">Section 16: Pumping Lemma for Context Free Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-16.1">Subsection 16.1: Formal Specification of the CFL Pumping Lemma</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-17">Section 17: Properties of Context Free Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-17.1">Subsection 17.1: Decision Properties of Context Free Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.1.1">Subsubsection 17.1.1: Membership Test for CFL’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.1.2">Subsubsection 17.1.2: The CYK Algorithm</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.1.3">Subsubsection 17.1.3: Emptiness Test for CFL’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.1.4">Subsubsection 17.1.4: Infiniteness Test for CFL’s</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-17.2">Subsection 17.2: Closure Properties of Context Free Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.2.1">Subsubsection 17.2.1: Union for CFL’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.2.2">Subsubsection 17.2.2: Concatenation for CFL’s</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-17.2.3">Subsubsection 17.2.3: Kleene Closure for CFL’s</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-18">Section 18: Countability</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-18.1">Subsection 18.1: Finite Sets</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-18.2">Subsection 18.2: Infinite Sets</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-18.3">Subsection 18.3: Countable Sets</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-18.4">Subsection 18.4: Countability of Languages Over the Binary Alphabet</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-19">Section 19: Turing Machines</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-19.1">Subsection 19.1: What is a Turing Machine?</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.2">Subsection 19.2: Turing Machine Notation</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.3">Subsection 19.3: Instantaneous Descriptions of Turing Machines</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.4">Subsection 19.4: Languages of a Turing Machine</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.5">Subsection 19.5: Recursively Enumerable Languages vs. Recursive Languages</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.6">Subsection 19.6: Multi-tape Turing Machines</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.7">Subsection 19.7: Nondeterministic Turing Machines</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-19.8">Subsection 19.8: Closure Properties of Recursive and Recursively Enumerable Languages</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.1">Subsubsection 19.8.1: Union</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.2">Subsubsection 19.8.2: Intersection</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.3">Subsubsection 19.8.3: Difference and Complement</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.4">Subsubsection 19.8.4: Concatenation</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.5">Subsubsection 19.8.5: Kleene Star</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-19.8.6">Subsubsection 19.8.6: Reversal</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-20">Section 20: Decidability</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-20.1">Subsection 20.1: Encoding Turing Machines in Binary</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-20.2">Subsection 20.2: Diagonalization on the Enumerated Turing Machines</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-20.3">Subsection 20.3: Decidable Problems</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-20.4">Subsection 20.4: The Universal Turing Machine</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-20.5">Subsection 20.5: The UTM is Recursively Enumerable and Not Recursive (The Halting Problem)</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-21">Section 21: Some Undeciable Problems</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-21.1">Subsection 21.1: Rice’s Theorem</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-21.2">Subsection 21.2: Post’s Correspondence Problem</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-21.3">Subsection 21.3: PCP is Undecidable</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-21.3.1">Subsubsection 21.3.1: Reduction from <span class="formula"></span> to MPCP</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-21.3.2">Subsubsection 21.3.2: Reduction from MPCP to PCP</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-21.4">Subsection 21.4: Some Real Problems</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Part-III">Part III: Complexity</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section-22">Section 22: Time Complexity (Bachmann-Landau Notation)</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-23">Section 23: Space Complexity</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-24">Section 24: Intractable Problems</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-24.1">Subsection 24.1: Time Bounded Turing Machines</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.2">Subsection 24.2: The Partial Order of Equivalance Classes P, NP, and NP-complete</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.3">Subsection 24.3: Encoding Schemes</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.4">Subsection 24.4: Transitivity of NP-completeness</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.5">Subsection 24.5: Prooving NP-completeness</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-24.5.1">Subsubsection 24.5.1: Restriction</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-24.5.2">Subsubsection 24.5.2: Local Replacement</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-24.5.3">Subsubsection 24.5.3: Component Design</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.6">Subsection 24.6: Polynomial Time Reductions</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-24.7">Subsection 24.7: Cook’s Theorem</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-25">Section 25: Specific NP-Complete Problems</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-25.1">Subsection 25.1: SAT to 3SAT</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-25.2">Subsection 25.2: 3SAT to 3DIMM Matching</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-25.3">Subsection 25.3: 3DIMM Matching to Partition</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-25.4">Subsection 25.4: 3SAT to Vertex Cover</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-25.5">Subsection 25.5: Vertex Cover to Hamiltonian Circuit</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-25.6">Subsection 25.6: Vertex Cover to Clique</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Part-IV">Part IV: Algorithms</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section-26">Section 26: Data Structures</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-26.1">Subsection 26.1: Graphs</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-26.2">Subsection 26.2: Trees</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-26.3">Subsection 26.3: Lists</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-26.4">Subsection 26.4: Queues</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-26.5">Subsection 26.5: Arrays</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-27">Section 27: Optimatility</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-28">Section 28: Approximation Algorithms</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-28.1">Subsection 28.1: Backtracking</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-28.2">Subsection 28.2: Branch and Bound</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-28.3">Subsection 28.3: Local Search</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-29">Section 29: Randomized Algorithms</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-29.1">Subsection 29.1: Las Vegas and Monte Carlo</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-29.2">Subsection 29.2: Game Theoretic Techniques</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-29.3">Subsection 29.3: Moments and Deviations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-29.4">Subsection 29.4: Tail Inequalities</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-29.5">Subsection 29.5: The Probablistic Method</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-30">Section 30: Dynamic Programming</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-30.1">Subsection 30.1: Recurrence Relations</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-30.2">Subsection 30.2: Memoization</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-31">Section 31: Fast Fourier Transform</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-32">Section 32: Shortest Path Algorithms</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-32.1">Subsection 32.1: Dijkstra</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-32.2">Subsection 32.2: Bellman-Ford</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-33">Section 33: Maximum Flow</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-33.1">Subsection 33.1: Flows and Cuts</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.2">Subsection 33.2: The Max-Flow Min-Cut Theorem</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.3">Subsection 33.3: Flow Networks, Residual Networks, and Augmenting Flows</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.4">Subsection 33.4: Ford-Fulkerson Algorithm</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.5">Subsection 33.5: The Scaling Algorithm</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.6">Subsection 33.6: Edmonds-Karp Algorithm</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-33.7">Subsection 33.7: Dinic’s Algorithm</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-34">Section 34: Bipartite Matching</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-34.1">Subsection 34.1: Nomencalture– Matchings, Perfect Matchings, Maximum Matchings, and Bipartiteness</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-34.2">Subsection 34.2: The Frobenius-Hall Theorem</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-34.3">Subsection 34.3: Hopcroft-Karp Algorithm</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-34.4">Subsection 34.4: The Hungarian Algorithm</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-35">Section 35: Appendix: Reference Material</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-35.1">Subsection 35.1: Software</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-35.2">Subsection 35.2: Books</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-35.3">Subsection 35.3: Videos</a>
</div>
</div>
</div>

</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--1"></a>Preface
</h1>
<div class="Unindented">
The purpose of this document is to help students of all stripes succeed in Georgia Tech’s course on Computability, Complexity and Algorithms more formally known as CS6505. Many students find this course to be challenging and the topics can be opaque at times to the newcomer. However with grit, determination, and luck you, the reader, can reap the many benefits that this course offers. In proceeding sections I outline some of the key concepts you will need to be successful in the course. I make no assumptions about prerequisite knowledge and attempt to provide you the green field perspective on the subject matter. In many cases, if you have already seen the information it is safe to skip forward and not concern yourself what may be obvious to you, but I encourage you to read all the sections because additional clarity may be gained with another pass through.
</div>
<h1 class="Part">
<a class="toc" name="toc-Part-I">Part I.</a> Mathematics and Logic
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-1">1</a> Discrete Mathematics
</h1>
<div class="Unindented">
<div class="float">
<a class="Label" name="fig:lawsOfLogic"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Equivalence
</td>
<td align="center" valign="top">
Name
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∧<i>T</i> ≡ <i>p</i></span>, <span class="formula"><i>p</i>∨<i>F</i> ≡ <i>F</i></span>
</td>
<td align="center" valign="top">
Identity Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨<i>T</i> ≡ <i>T</i></span>, <span class="formula"><i>p</i>∧<i>F</i> ≡ <i>F</i></span>
</td>
<td align="center" valign="top">
Domination Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨<i>p</i> ≡ <i>p</i></span>, <span class="formula"><i>p</i>∧<i>p</i> ≡ <i>p</i></span>
</td>
<td align="center" valign="top">
Idempotent Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">¬(¬<i>p</i>) ≡ <i>p</i></span>
</td>
<td align="center" valign="top">
Double Negation Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨<i>q</i> ≡ <i>q</i>∨<i>p</i></span>, <span class="formula"><i>p</i>∧<i>q</i> ≡ <i>q</i>∧<i>p</i></span>
</td>
<td align="center" valign="top">
Communicative Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i>∨<i>q</i>)∨<i>r</i> ≡ <i>p</i>∨(<i>q</i>∨<i>r</i>)</span>, <span class="formula">(<i>p</i>∧<i>q</i>)∧<i>r</i> ≡ <i>p</i>∧(<i>q</i>∧<i>r</i>)</span>
</td>
<td align="center" valign="top">
Associative Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨(<i>q</i>∧<i>r</i>) ≡ (<i>p</i>∨<i>q</i>)∧(<i>p</i>∨<i>r</i>)</span>, <span class="formula"><i>p</i>∧(<i>q</i>∨<i>r</i>) ≡ (<i>p</i>∧<i>q</i>)∨(<i>p</i>∧<i>r</i>)</span>
</td>
<td align="center" valign="top">
Distributive Laws
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">¬(<i>p</i>∧<i>q</i>) ≡ ¬<i>p</i>∨¬<i>q</i></span>, <span class="formula">¬(<i>p</i>∨<i>q</i>) ≡ ¬<i>p</i>∧¬<i>q</i></span>
</td>
<td align="center" valign="top">
De Morgan’s Law
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨(<i>p</i>∧<i>q</i>) ≡ <i>p</i></span>, <span class="formula"><i>p</i>∧(<i>p</i>∨<i>q</i>) ≡ <i>p</i></span>
</td>
<td align="center" valign="top">
Absoption Law
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨¬<i>p</i> ≡ <i>T</i></span>, <span class="formula"><i>p</i>∧¬<i>p</i> ≡ <i>F</i></span>
</td>
<td align="center" valign="top">
Negation Laws
</td>

</tr>

</table>
 <table>
<tr>
<td align="center" valign="top">
Logical Equivalences Involving Conditional Statements
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i> → <i>q</i> ≡ ¬<i>p</i>∨<i>q</i> ≡ ¬<i>q</i> → ¬<i>p</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∨<i>q</i> ≡ ¬<i>p</i> → <i>q</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>∧<i>q</i> ≡ ¬(<i>p</i> → ¬<i>q</i>)</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">¬(<i>p</i> → <i>q</i>) ≡ <i>p</i>∧¬<i>q</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i> → <i>q</i>)∧(<i>p</i> → <i>r</i>) ≡ <i>p</i> → (<i>q</i>∧<i>r</i>)</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i> → <i>r</i>)∧(<i>q</i> → <i>r</i>) ≡ (<i>p</i>∨<i>q</i>) → <i>r</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i> → <i>q</i>)∨(<i>p</i> → <i>r</i>) ≡ <i>p</i> → (<i>q</i>∨<i>r</i>)</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i> → <i>r</i>)∨(<i>q</i> → <i>r</i>) ≡ (<i>p</i>∧<i>q</i>) → <i>r</i></span>
</td>

</tr>

</table>
 <table>
<tr>
<td align="center" valign="top">
Logical Equivalences Involving Biconditional Statements
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>↔<i>q</i> ≡ (<i>p</i> → <i>q</i>)∧(<i>q</i> → <i>p</i>)</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>↔<i>q</i> ≡ ¬<i>p</i>↔¬<i>q</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i>↔<i>q</i> ≡ (<i>p</i>∧<i>q</i>)∨(¬<i>p</i>∧¬<i>q</i>)∨(¬<i>p</i>∧¬<i>q</i>)</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">¬(<i>p</i>↔<i>q</i>) ≡ <i>p</i>↔¬<i>q</i></span>
</td>

</tr>

</table>

</div>
<div class="caption">
Figure 1  Logical equivalences. Idempotent denotes an element of a set that is unchanged in value when multiplied or otherwise operated on by itself.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.1">1.1</a> Propositional and Sentential Logic<a class="Label" name="sec:propositionalSententialLogic"> </a>
</h2>
<div class="Unindented">
All logical expressions can be described in some combination of <i>logical operators</i> and <i>implications</i>. The logical operators consist of the following: the logical conjunction <span class="formula">∧</span>, the logical disjunction <span class="formula">∨</span>, and the negation <span class="formula">¬</span>. The implication is made up of two propositional variables <span class="formula"><i>p</i></span>and <span class="formula"><i>q</i>.</span> <span class="formula"><i>p</i></span>is often called the <i>premise</i> or <i>hypothesis</i> or <i>antecedent</i>, while <span class="formula"><i>q</i></span>may be referred to as the <i>conclusion</i>, or <i>consequence</i>. Truth tables are a way of tabulating the values of arbitrary logical expressions by enumerating all possible truth values for the component of the expressions. The usefulness of this technique quickly diminishes as the number of proposition variables goes beyond 4. In this case the number of rows in the truth table is <span class="formula">2<sup>4</sup> = 16</span>. The precedence of logical operators is negation, conjunction, disjunction.
</div>
<div class="Indented">
The implication is given by the symbol <span class="formula"> → </span>. Variations on the traditional implication of <span class="formula"><i>p</i> → <i>q</i></span> include its <i>converse</i> <span class="formula"><i>q</i> → <i>p</i></span>, the <i>contraposative</i> <span class="formula">¬<i>q</i> → ¬<i>p</i></span>, and the <i>inverse</i> <span class="formula">¬<i>p</i> → ¬<i>q</i></span>. A biconditional or implication statement is a slightly more creative way to use the implication. A table of logical equivalences is provided in Figure<a class="Reference" href="#fig:lawsOfLogic">1 on page 1↑</a>.
</div>
<div class="Indented">
Use of these laws can allow you to establish an equivalence of complex propositional statements with a more distilled simplified version. Propositional statements are said to be <i>satisfiable</i> if some combination of truth assignments to the propositional variables makes the statement true.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.2">1.2</a> Predicate Calculus and Quantification Logic
</h2>
<div class="Unindented">
Predicate logic is a generalization of propositional logic onto arbitrary statements. <i>Propositional functions</i> given by a capital letter and a number of parameters are used to define propositional statements. An example, &ldquo;Computer <span class="formula"><i>x</i></span>, is functioning properly&rdquo; would be written as <span class="formula"><i>P</i>(<i>x</i>).</span> 
</div>
<div class="Indented">
Quantification expresses the extent to which a predicate is true over a range of elements. In English, the words all, some, many, none, and few are used in quantification’s. The <i>universal quantification</i> symbol for all is given by <span class="formula">∀</span>. The <i>existential quantification</i> symbol for exists is <span class="formula">∃</span>. The statement <span class="formula">∀<i>xP</i>(<i>x</i>)</span> reads &ldquo;For all computers given by <span class="formula"><i>x</i></span>, computer <span class="formula"><i>x</i></span>is functioning properly.&rdquo; If there is a single instance of a universal variable which is false then the predicate becomes false. If for all instances of an existential variables the value is false then the statement is false. Quantification operators have higher precedence than logical operators. Predicates used with quantifiers are said to be <i>bound variables</i> while those without are said to be <i>free variables</i>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:quantificationNegation"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
<span class="formula">¬∀<i>xP</i>(<i>x</i>) ≡ ∃<i>x</i>¬<i>P</i>(<i>x</i>).</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">¬∃<i>xP</i>(<i>x</i>) ≡ ∀¬<i>P</i>(</span>x).
</td>

</tr>

</table>

</div>
<div class="caption">
Figure 2  This table shows the equivalence relations on predicates with quantification symbols.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.3">1.3</a> Rules of Inference
</h2>
<div class="Unindented">
The <i>validity</i> of a proofs arguments are derived from the truth of the premises it offers. An argument in propositional logic is a sequence of propositions. All but the final proposition in the argument are called <i>premises</i> and the final proposition is called the <i>conclusion</i>. An argument is valid if the truth of all its premises implies that the conclusion is true. An argument form in propositional logic is a sequence of compound propositions involving <i>propositional variables</i>. 
</div>
<div class="Indented">
An argument’s form is valid no matter which particular propositions are substituted for the propositional variables in its premises, the conclusion is true if the premises are all true. The rules of inference provide the templates of logical propositions which, when given in a valid combination, yield valid arguments. The rules are given in Figure<a class="Reference" href="#fig:inferenceRules">3 on page 1↓</a>. Additionally, the Rules of Inference applies to quantification logic as well as shown in the table.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:inferenceRules"> </a><div class="figure">
<div class="PlainVisible">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Tautology
</td>
<td align="center" valign="top">
Name
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i>∧(<i>p</i> → <i>q</i>)) → <i>q</i></span>
</td>
<td align="center" valign="top">
Modus ponens
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(¬<i>q</i>∧(<i>p</i> → <i>q</i>)) → <i>q</i></span>
</td>
<td align="center" valign="top">
Modus tollens
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">((<i>p</i> → <i>q</i>)∧(<i>q</i> → <i>r</i>)) → (<i>p</i> → <i>r</i>)</span>
</td>
<td align="center" valign="top">
Hypothetical syllogism
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">((<i>p</i>∨<i>q</i>)∧¬<i>p</i>) → <i>q</i></span>
</td>
<td align="center" valign="top">
Disjunctive syllogism
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i> → (<i>p</i>∨<i>q</i>)</span>
</td>
<td align="center" valign="top">
Addition
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i>∧<i>q</i>) → <i>q</i></span>
</td>
<td align="center" valign="top">
Simplification
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">((<i>p</i>)∧(<i>q</i>)) → (<i>p</i>∧<i>q</i>)</span>
</td>
<td align="center" valign="top">
Conjunction
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">(<i>p</i>∨<i>q</i>)∧(¬<i>p</i>∨<i>r</i>) → (<i>q</i>∨<i>r</i>)</span>
</td>
<td align="center" valign="top">
Resolution
</td>

</tr>

</table>

</div>
<br/>
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Inference Rule
</td>
<td align="center" valign="top">
Name
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator">∀<i>xP</i>(<i>x</i>)</span><span class="ignored">)/(</span><span class="denominator">∴<i>P</i>(<i>c</i>)</span><span class="ignored">)</span></span></span>
</td>
<td align="center" valign="top">
Universal instantiation
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i>(<i>c</i>)</span><span class="ignored">)/(</span><span class="denominator">∴∀<i>xP</i>(<i>x</i>)</span><span class="ignored">)</span></span></span> for an arbitrary <span class="formula"><i>c</i></span>
</td>
<td align="center" valign="top">
Universal generalization
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator">∃<i>xP</i>(<i>x</i>)</span><span class="ignored">)/(</span><span class="denominator">∴<i>P</i>(<i>c</i>)</span><span class="ignored">)</span></span></span> for some element <span class="formula"><i>c</i></span>
</td>
<td align="center" valign="top">
Existential instantiation
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i>(<i>c</i>)</span><span class="ignored">)/(</span><span class="denominator">∴∃<i>xP</i>(<i>x</i>)</span><span class="ignored">)</span></span></span>
</td>
<td align="center" valign="top">
Existential generalization
</td>

</tr>

</table>

</div>

</div>
<div class="caption">
Figure 3 This table gives the Rules of Inference.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.4">1.4</a> Proofs
</h2>
<div class="Unindented">
In order to begin to understand how to construct valid proof it is important to understand the terminology that is used. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.4.1">1.4.1</a> Terminology of Proofs
</h3>
<ul>
<li>
a <i>theorem</i> is a statement that can be shown to be true.
</li>
<li>
A <i>proof</i> is a valid argument that establishes the truth of a theorem.
</li>
<li>
<i>axioms</i> (or <i>postulates</i>) are statements we assume to be true.
</li>
<li>
A <i>lemma</i> is a less important theorem that is helpful in the proof of other results.
</li>
<li>
A <i>corollary</i> is a theorem that can be established directly from a theorem that has been proved.
</li>
<li>
<i>without loss of generality</i> (WLOG) means that the author of a proof is omitting the proof of one of the cases in a proof by cases.
</li>

</ul>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.4.2">1.4.2</a> Types of Proofs
</h3>
<ul>
<li>
<i>Direct Proofs</i> is a proof that assumes the antecedent of the implication is true and seeks to justify and prove the conclusion of the theorem by examining the characteristics of the relationship of the antecedent and conclusion. A direct proof may use axioms, definitions, and previously proven theorems, together with rules of inference, to show that q must also be true. Here we are establishing the truth of the proof based on row 1 of the truth table found in Figure<a class="Reference" href="#fig:implicationTruthTable">4 on page 1↓</a>.
</li>

</ul>
<div class="Unindented">
<div class="float">
<a class="Label" name="fig:implicationTruthTable"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i></span>
</td>
<td align="center" valign="top">
<span class="formula"><i>q</i></span>
</td>
<td align="center" valign="top">
<span class="formula"><i>p</i> → <i>q</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>

</tr>
<tr>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
F
</td>

</tr>
<tr>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>

</tr>
<tr>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
T
</td>

</tr>

</table>
 <table>
<tr>
<td align="center" valign="top">
<span class="formula"><i>p</i></span>
</td>
<td align="center" valign="top">
<span class="formula"><i>q</i></span>
</td>
<td align="center" valign="top">
<span class="formula">¬<i>q</i> → ¬<i>p</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>

</tr>
<tr>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
F
</td>

</tr>
<tr>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
T
</td>
<td align="center" valign="top">
T
</td>

</tr>
<tr>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
F
</td>
<td align="center" valign="top">
T
</td>

</tr>

</table>

</div>
<div class="caption">
Figure 4  Truth table for the implication and its contraposative.
</div>

</div>

</div>

</div>
<ul>
<li>
In juxtaposition to the direct proof we have the indirect proof techniques. Indirect proofs do not start with the assumption of the truth of the premise to derive the truth of the conclusion. The<i> Proof by Contraposition </i>technique takes advantage of the equivalence of the contrapostion of the implication to prove the conclusion. That is, <span class="formula">¬<i>q</i> → ¬<i>p</i> ≡ <i>p</i> → <i>q</i></span> as shown in Figure<a class="Reference" href="#fig:lawsOfLogic">1 on page 1↑</a>. The template for this type of proof is constructed by assuming the conclusion <span class="formula"><i>q</i></span>is false which implies that the premise <span class="formula"><i>p</i></span> is also false. 
</li>
<li>
The trivial and vacuous proofs strategies are the simplest strategies. A <i>Trivial Proof</i> is a proof that derives the truth of the conclusion based on the fact that the premise is false. This logic is based on row 3 of the implication truth table. A Vacuous Proof is a proof based on the fact the conclusion is true also show in row 3.
</li>
<li>
<i>Proofs by Contradiction </i>seek to find a contradictory conclusion <span class="formula"><i>q</i> = <i>r</i>∧¬<i>r</i></span>, such that <span class="formula">¬<i>p</i> → <i>q</i></span> is true. We must show that <span class="formula"><i>p</i></span>is true by showing <span class="formula">¬<i>p</i></span> is false so that we can target row 4 in the implication truth table. 
</li>
<li>
<i>Proofs of Equivalence </i>To prove a theorem that is a biconditional statement, that is, a statement of the form <span class="formula"><i>p</i>↔<i>q</i></span>, we show that <span class="formula"><i>p</i> → <i>q</i></span> and <span class="formula"><i>q</i> → <i>p</i></span>. The validity of this approach is based on the tautology <span class="formula">(<i>p</i>↔<i>q</i>) ≡ (<i>p</i> → <i>q</i>)∧(<i>q</i> → <i>p</i>)</span>
</li>
<li>
<i>Proofs by Counterexample </i>in this type of proof we typically try to debunk the truth of a universal quantifier over some predicate. If we find one instance is false, then we can conclude the predicate is false<i>.</i>
</li>
<li>
<i>Proof by Cases and the Exhaustive Proof </i>sometimes using a single argument to cover the premise of a proof is not sufficient. As an alternative, we can devises cases that cover the entire domain of the proof and address each case in turn to prove the conclusion. This proof technique relies on the following tautology.<div class="formula">
[(<i>p</i><sub>1</sub>∨<i>p</i><sub>2</sub>∨…∨<i>p</i><sub><i>n</i></sub>) → <i>q</i>]↔[(<i>p</i><sub>1</sub> → <i>q</i>)∧(<i>p</i><sub>2</sub> → <i>q</i>)∧…∧(<i>p</i><sub><i>n</i></sub> → <i>q</i>)]
</div>

</li>
<li>
<i>Existence Proofs </i>a proof of this type is of the form <span class="formula">∃<i>xP</i>(<i>x</i>)</span>. This type of proof can be proven by providing a <i>witness</i> <span class="formula"><i>a</i>, </span> a instance of <span class="formula"><i>x</i></span>where <span class="formula"><i>P</i>(<i>a</i>)</span> is true. This type of strategy is called a <i>constructive</i> proof. A nonconstructive existence uses some other means to prove that \strikeout off\uuline off\uwave off<span class="formula">∃<i>xP</i>(<i>x</i>)</span>. Often contradiction is used.
</li>
<li>
<i>Uniqueness Proofs </i>in this type of proof we show that a unique element with a particular property exists. These types of proofs are composed of two steps. First you must prove the existence of the element. Then we show that if <span class="formula"><i>y</i> ≠ <i>x</i></span>, then <span class="formula"><i>y</i></span>does not have the particular property of <span class="formula"><i>x</i>.</span> Formally, uniqueness proofs are of the form:<div class="formula">
∃<i>x</i>(<i>P</i>(<i>x</i>)∧∀<i>y</i>(<i>y</i> ≠ <i>x</i> → ¬<i>P</i>(<i>y</i>))).
</div>

</li>

</ul>
<div class="Unindented">
<div class="float">
<a class="Label" name="Figure-5"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Direct Methods
</td>
<td align="center" valign="top">
Indirect Methods
</td>

</tr>
<tr>
<td align="center" valign="top">
Direct Proof
</td>
<td align="center" valign="top">
Proof by Contraposition
</td>

</tr>
<tr>
<td align="center" valign="top">
Proof by Cases
</td>
<td align="center" valign="top">
Proof by Contradiction
</td>

</tr>
<tr>
<td align="center" valign="top">
Exhaustive Proof
</td>
<td align="center" valign="top">
Proof by Counterexample
</td>

</tr>
<tr>
<td align="center" valign="top">
Existence Proof
</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">
Uniqueness Proof
</td>
<td align="center" valign="top">

</td>

</tr>

</table>

</div>
<div class="caption">
Figure 5 Classification of the proof strategies
</div>

</div>

</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.4.3">1.4.3</a> Strategies for Constructing Proofs
</h3>
<div class="Unindented">
The following general approach for constructing proofs is often helpful.
</div>
<ol>
<li>
Replace terms by their definitions.
</li>
<li>
Analyze the hypothesis and conclusion.
</li>
<li>
Attempt to construct the proof using the direct proof method, if the statement is a conditional statement.<ol>
<li>
If you fail to construct a direct proof, attempt to provide an indirect proof.
</li>
<li>
If both the direct and indirect proof methods don’t work, then attempt a proof by contradiction.
</li>

</ol>

</li>

</ol>
<div class="Unindented">
<i>Forward reasoning</i> as well as<i> backward reasoning</i> is necessary to construct valid proofs. Forward reasoning uses premises as well as previously proven theorems and axioms to prove the conclusion. In a direct proof this is the method of choice. Indirect proofs often will often require backward reasoning. In backward reasoning we attempt to find a statement <span class="formula"><i>p</i></span>that we can prove true with <span class="formula"><i>p</i> → <i>q</i>.</span>
</div>
<div class="Indented">
<i>Adaptation </i>of existing proofs is often a fruitful procedure. Even if the final conclusions required are not the same, it may be constructive to look to the previous proves for ideas which may help in your new proof.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.5">1.5</a> Sets<a class="Label" name="sec:Sets"> </a>
</h2>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.5.1">1.5.1</a> Classification of Groups by Formulating Subsets
</h3>
<div class="Unindented">
One of the primary uses of sets is to distinguish elements of a group into subsets–classification. A useful example is the classification of numbers into their respective subsets.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:numberClassification"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/NumberSetinC.png" alt="figure Diagrams/NumberSetinC.png" style="width: 166px; max-width: 333px; height: 130px; max-height: 261px;"/>

</div>
<div class="caption">
Figure 6 The diagram shows the hierarchy of numbers classified into subsets of the complex numbers.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.6">1.6</a> Relations<a class="Label" name="sec:Relations"> </a>
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.7">1.7</a> Functions<a class="Label" name="sec:Functions"> </a>
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.8">1.8</a> Recursion and Induction<a class="Label" name="sec:Induction"> </a>
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.9">1.9</a> Modular Arithmetic
</h2>
<div class="Unindented">
Figure<a class="Reference" href="#fig:moduluarArithmatic">7 on page 1↓</a> gives an overview of basic modular arithmetic operations.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:moduluarArithmatic"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Arithmetic Property
</td>
<td align="center" valign="top">
Equation
</td>

</tr>
<tr>
<td align="center" valign="top">
Modulo Positive Numbers
</td>
<td align="center" valign="top">
<span class="formula"><i>a</i>%<i>b</i> = <i>c</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Modulo Negative Numbers
</td>
<td align="center" valign="top">
<span class="formula"><i>c</i> = <i>a</i> − <i>q</i>⋅<i>b</i></span>, where <span class="formula"><i>a</i> &lt; 0</span>, and <span class="formula"> − 1 ≤ <i>q</i> ≤ <span class="symbol">⌊</span><i>a</i> ⁄ <i>b</i><span class="symbol">⌋</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Modular Congruence
</td>
<td align="center" valign="top">
<span class="formula"><i>a</i>%<i>b</i> ≡ <i>b</i>%<i>c</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Modular Addition
</td>
<td align="center" valign="top">
<span class="formula">(<i>a</i> + <i>b</i>)%<i>c</i> ≡ (<i>a</i>%<i>c</i> + <i>b</i>%<i>c</i>)%<i>c</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Modular Subtraction
</td>
<td align="center" valign="top">
<span class="formula">(<i>a</i> − <i>b</i>)%<i>c</i> ≡ (<i>a</i>%<i>c</i> − <i>b</i>%<i>c</i>)%<i>c</i></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Modular Multiplication
</td>
<td align="center" valign="top">
<span class="formula">(<i>a</i>⋅<i>b</i>)%<i>c</i> ≡ (<i>a</i>%<i>c</i>⋅<i>b</i>%<i>c</i>)%<i>c</i></span>
</td>

</tr>

</table>
 
</div>
<div class="caption">
Figure 7 This table gives an overview of useful modular arithmetic equations
</div>

</div>

</div>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-2">2</a> Calculus and Real Analysis
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.1">2.1</a> Sequences and Series
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.2">2.2</a> Topology of Real Numbers
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.3">2.3</a> Functional Limits and Continuity
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.4">2.4</a> Derivatives
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.5">2.5</a> Sequences and Series of Functions
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.6">2.6</a> Riemann Integral
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.7">2.7</a> Cantor Diagonalization
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-3">3</a> Probability and Statistics<a class="Label" name="sec:Probability-and-Odds"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.1">3.1</a> Discrete Probability Distributions
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.2">3.2</a> Continuous Probability Distributions
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.3">3.3</a> Combinatorics
</h2>
<div class="Unindented">
You can use counting techniques to answer a variety of questions. Learning how to account for the time complexity of algorithm will be very useful in this course.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-3.3.1">3.3.1</a> The Product Rule
</h3>
<div class="Unindented">
The product rule is used to count when counting separate tasks. You should apply this rule when counting nested for loops. Suppose that a procedure can be broken down into a sequence of two tasks. If there are<span class="formula"><i>n</i><sub>1</sub></span> ways to do the first task and for each of these ways of doing the first task, there are <span class="formula"><i>n</i><sub>2</sub></span> ways to do the second task, then there are <span class="formula"><i>n</i><sub>1</sub><i>n</i><sub>2</sub></span> ways to do the procedure.
</div>
<div class="Theorem">
Suppose that a procedure is carried out by performing the tasks <span class="formula"><i>T</i><sub>1</sub>, <i>T</i><sub>2</sub>, …, <i>T</i><sub><i>m</i></sub></span> in sequence. If each task <span class="formula"><i>T</i><sub><i>i</i></sub></span> , <span class="formula"><i>i</i> = 1, 2, …, <i>m</i></span> can be done in <span class="formula"><i>n</i><sub><i>i</i></sub></span> ways, regardless of how the previous tasks were done, then there are <span class="formula"><i>n</i><sub>1</sub>⋅<i>n</i><sub>2</sub>⋅…⋅<i>n</i><sub><i>m</i></sub></span> ways to carry out the procedure.
</div>
<div class="Proof">
//TODO Provide an inductive proof of the Product Rule.
</div>
<div class="Example">
Assigning tasks to employees. Suppose you hire two employees Ralph and Loretta. You are tasked with assigning cleaning responsibilities of <span class="formula"><i>n</i></span> rooms among the two employees. How many ways can you assign the responsibilities among the employees?
</div>
<div class="Solution*">
The first employee you select is unrestricted in the number of rooms to clean. Therefore <span class="formula"><i>n</i></span> rooms may be cleaned by this employee. The next employee has <span class="formula"><i>n</i> − 1</span>different rooms to clean.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-3.3.2">3.3.2</a> The Sum Rule
</h3>
<div class="Unindented">
If a task can be done either in one of <span class="formula"><i>n</i><sub>1</sub></span> ways or in one of <span class="formula"><i>n</i><sub>2</sub></span> ways, where none of the set of <span class="formula"><i>n</i><sub>1</sub></span> ways is the same as any of the set of <span class="formula"><i>n</i><sub>2</sub></span> ways, then there are <span class="formula"><i>n</i><sub>1</sub> + <i>n</i><sub>2</sub></span> ways to do the task. The key things to look for are a disjunction of disjoint ways to do a task. Use this rule when counting the number of steps in a number of sequential for loops. The Sum Rule can be generalized to <span class="formula"><i>m</i></span> tasks as follows. 
</div>
<div class="Theorem">
Suppose that a task can be done in one of <span class="formula"><i>n</i><sub>1</sub></span> ways, in one of <span class="formula"><i>n</i><sub>2</sub></span> ways, <span class="formula">…</span> ,or in one of <span class="formula"><i>n</i><sub><i>m</i></sub></span> ways, where none of the set of <span class="formula"><i>n</i><sub><i>i</i></sub></span> ways of doing the task is the same as any of the set of <span class="formula"><i>n</i><sub><i>j</i></sub></span> ways, for all pairs <span class="formula"><i>i</i></span> and <span class="formula"><i>j</i></span> with <span class="formula">1 ≤ <i>i</i> &lt; <i>j</i> ≤ <i>m</i></span>. Then the number of ways to do the task is <span class="formula"><i>n</i><sub>1</sub> + <i>n</i><sub>2</sub> + … + <i>n</i><sub><i>m</i></sub></span>. 
</div>
<div class="Proof">
//TODO Provide an inductive proof of the Sum Rule.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-3.3.3">3.3.3</a> The Subtraction Rule or The Inclusion Exclusion Principle
</h3>
<div class="Unindented">
If a task can be done in either <span class="formula"><i>n</i><sub>1</sub></span> ways or <span class="formula"><i>n</i><sub>2</sub></span> ways, then the number of ways to do the task is <span class="formula"><i>n</i><sub>1</sub> + <i>n</i><sub>2</sub></span> minus the number of ways to do the task that are common to the two different ways. This rule is often called the principle of inclusion-exclusion especially when considering the union of sets.
</div>
<div class="Indented">
<div class="formula">
|<i>A</i><sub>1</sub>∪<i>A</i><sub>2</sub>| = |<i>A</i><sub>1</sub>| + |<i>A</i><sub>2</sub>| − |<i>A</i><sub>1</sub>∩<i>A</i><sub>2</sub>|
</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-3.3.4">3.3.4</a> The Division Rule
</h3>
<div class="Unindented">
There are<span class="formula"><i>n</i> ⁄ <i>d</i></span> ways to do a task if it can be done using a procedure that can be carried out in <span class="formula"><i>n</i></span> ways, and for every way <span class="formula"><i>w</i></span>, exactly <span class="formula"><i>d</i></span> of the <span class="formula"><i>n</i></span> ways correspond to way <span class="formula"><i>w</i></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-3.3.5">3.3.5</a> The Pigeonhole Principle (Dirichlet Drawer Principle)
</h3>
<div class="Theorem">
If N objects are placed into k boxes, then there is at least one box containing at least <span class="formula"><span class="symbol">⌈</span><i>N</i> ⁄ <i>k</i><span class="symbol">⌉</span></span> objects.
</div>
<div class="Proof">
We will use a proof by contrapostion. Suppose that none of the boxes contains more than <span class="formula"><span class="symbol">⌈</span><i>N</i> ⁄ <i>k</i><span class="symbol">⌉</span> − 1</span> objects. Then, the total number of objects is at most
</div>
<div class="Proof">
<div class="formula">
<i>k</i><span class="array"><span class="arrayrow"><span class="bracket align-left">⎛</span></span><span class="arrayrow"><span class="bracket align-left">⎝</span></span></span><span class="symbol">⌈</span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>N</i></span><span class="ignored">)/(</span><span class="denominator"><i>k</i></span><span class="ignored">)</span></span><span class="symbol">⌉</span> − 1<span class="array"><span class="arrayrow"><span class="bracket align-right">⎞</span></span><span class="arrayrow"><span class="bracket align-right">⎠</span></span></span> &lt; <i>k</i><span class="array"><span class="arrayrow"><span class="bracket align-left">⎛</span></span><span class="arrayrow"><span class="bracket align-left">⎝</span></span></span><span class="array"><span class="arrayrow"><span class="bracket align-left">⎛</span></span><span class="arrayrow"><span class="bracket align-left">⎝</span></span></span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>N</i></span><span class="ignored">)/(</span><span class="denominator"><i>k</i></span><span class="ignored">)</span></span> − 1<span class="array"><span class="arrayrow"><span class="bracket align-right">⎞</span></span><span class="arrayrow"><span class="bracket align-right">⎠</span></span></span> + 1<span class="array"><span class="arrayrow"><span class="bracket align-right">⎞</span></span><span class="arrayrow"><span class="bracket align-right">⎠</span></span></span> = <i>N</i>
</div>
This is a contradiction because at most\strikeout off\uuline off\uwave off<span class="formula"><span class="symbol">⌈</span><i>N</i> ⁄ <i>k</i><span class="symbol">⌉</span> − 1</span> were claimed and yet the total is <span class="formula"><i>N</i>.</span>
</div>
<div class="Corollary">
A function f from a set with k +1 or more elements to a set with k elements is not one-to-one.
</div>
<div class="Proof">
Suppose that for each element <span class="formula"><i>y</i></span> in the codomain of <span class="formula"><i>f</i></span> we have a box that contains all elements <span class="formula"><i>x</i></span> of the domain of <span class="formula"><i>f</i></span> such that <span class="formula"><i>f</i>(<i>x</i>) = <i>y</i></span>. Because the domain contains <span class="formula"><i>k</i> + 1</span> or more elements and the codomain contains only <span class="formula"><i>k</i></span> elements, the pigeonhole principle tells us that one of these boxes contains two or more elements <span class="formula"><i>x</i></span> of the domain. This means that <span class="formula"><i>f</i></span> cannot be one-to-one.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.4">3.4</a> Permutations and Combinations
</h2>
<div class="Unindented">
A <i>permutation</i> of the elements of a set is an ordered arrangement of the elements in the set. A <i>r-permuation </i>of a set <span class="formula"><i>S</i></span> is a permutation of a subset <span class="formula"><i>R</i> ⊆ <i>S</i></span> where <span class="formula"><i>r</i> = |<i>R</i>|</span>.
</div>
<div class="Indented">
An unordered selection of elements of a set is called a <i>combination.</i> An <i>r-combination</i> of elements of a set is an unordered selection of <i>r</i> elements from the set.
</div>
<div class="Indented">
A combinatorial proof of an identity is a proof that uses counting arguments to prove that both sides of the identity count the same objects but in different ways or a proof that is based on showing that there is a bijection between the sets of objects counted by the two sides of the identity. These two types of proofs are called double counting proofs and bijective proofs, respectively.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:permCombFormulas"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Type
</td>
<td align="center" valign="top">
Repetition Allowed?
</td>
<td align="center" valign="top">
Formula
</td>

</tr>
<tr>
<td align="center" valign="top">
r-permutations
</td>
<td align="center" valign="top">
No
</td>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>n</i>!</span><span class="ignored">)/(</span><span class="denominator">(<i>n</i> − <i>r</i>)!</span><span class="ignored">)</span></span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
r-combinations
</td>
<td align="center" valign="top">
No
</td>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>n</i>!</span><span class="ignored">)/(</span><span class="denominator"><i>r</i>!(<i>n</i> − <i>r</i>)!</span><span class="ignored">)</span></span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
r-permutations
</td>
<td align="center" valign="top">
Yes
</td>
<td align="center" valign="top">
<span class="formula"><i>n</i><sup><i>r</i></sup></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
r-combinations
</td>
<td align="center" valign="top">
Yes
</td>
<td align="center" valign="top">
<span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator">(<i>n</i> + <i>r</i> − 1)!</span><span class="ignored">)/(</span><span class="denominator"><i>r</i>!(<i>n</i> − 1)!</span><span class="ignored">)</span></span></span>
</td>

</tr>

</table>

</div>
<div class="caption">
Figure 8 Formulas for calculating permutations and combinations.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.5">3.5</a> Finite Probability
</h2>
<div class="Unindented">
First we introduce some nomenclature for this domain of study. 
</div>
<ul>
<li>
An <i>experiment</i> is a procedure that yields one of a given set of possible outcomes.
</li>
<li>
The<i> sample space</i> of the experiment is the set of possible outcomes.
</li>
<li>
An <i>event</i> is a subset of the sample space.
</li>

</ul>
<div class="Unindented">
Laplace defines the probability of an event as given a set S, a finite nonempty sample space, of equally likely outcomes, and <span class="formula"><i>E</i></span> is an event, that is, <span class="formula"><i>E</i> ⊆ <i>S</i></span>, then the probability of <span class="formula"><i>E</i></span> is <span class="formula"><i>p</i>(<i>E</i>) = <span class="fraction"><span class="ignored">(</span><span class="numerator">|<i>E</i>|</span><span class="ignored">)/(</span><span class="denominator">|<i>S</i>|</span><span class="ignored">)</span></span>.</span> The probability of the complement of an event is <span class="formula"><span class="bar"><i>E</i></span> = <i>S</i> − <i>E</i></span>, and the complementary event is given by <span class="formula"><i>p</i>(<span class="bar"><i>E</i></span>) = 1 − <i>p</i>(<i>E</i>)</span>.
</div>
<div class="Indented">
We can find the probability of the union of events by adding their probabilities and subtracting the intersection of the events. <div class="formula">
<i>p</i>(<i>E</i><sub>1</sub>∪<i>E</i><sub>2)</sub> = <i>p</i>(<i>E</i><sub>1</sub>) + <i>p</i>(<i>E</i><sub>2</sub>) − <i>p</i>(<i>E</i><sub>1</sub>∩<i>E</i><sub>2</sub>).
</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.6">3.6</a> Nonuniform Probability
</h2>
<div class="Unindented">
In the previous section we operated under the conditions of equal probability for each event in the sample space. However, many questions may be posed where this is not the case. To account for nonuniform probability of events we must introduce two constraints on the members of the sample pace <span class="formula"><i>S</i></span>.
</div>
<ol>
<li>
<span class="formula">0 ≤ <i>p</i>(<i>s</i>) ≤ 1</span>, The probability of each element in the samples space must be between 0 and 1.
</li>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>s</i><i>ϵ</i><i>S</i></sub><i>p</i>(<i>s</i>) = 1</span>, The sum of the probabilities of each element of <span class="formula"><i>S</i></span> must be 1.
</li>

</ol>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.7">3.7</a> Conditional Probability
</h2>
<div class="Unindented">
Let <span class="formula"><i>E</i></span> and <span class="formula"><i>F</i></span> be events with <span class="formula"><i>p</i>(<i>F</i>) &gt; 0</span>. The conditional probability of <span class="formula"><i>E</i></span> given <span class="formula"><i>F</i></span>, denoted by <span class="formula"><i>p</i>(<i>E</i>|<i>F</i>).</span>
</div>
<div class="Indented">
<div class="formula">
<i>p</i>(<i>E</i>|<i>F</i>) = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>p</i>(<i>E</i>∩<i>F</i>)</span><span class="ignored">)/(</span><span class="denominator"><i>p</i>(<i>F</i>)</span><span class="ignored">)</span></span>
</div>

</div>
<div class="Indented">
<i>Independent events</i> are events that do not affect each other. When two events are independent, the occurrence of one of the events gives no information about the probability that the other event occurs. Mathematically, if <span class="formula"><i>p</i>(<i>E</i>) = <i>p</i>(<i>E</i>|<i>F</i>)</span> then the events <span class="formula"><i>E</i></span> and <span class="formula"><i>F</i></span> are said to be independent.
</div>
<div class="Indented">
Pairwise independence is defined as follows: The events <span class="formula"><i>E</i><sub>1</sub>, <i>E</i><sub>2</sub>, …, <i>E</i><sub><i>n</i></sub></span> are <i>pairwise independent </i>if and only if <span class="formula"><i>p</i>(<i>E</i><sub><i>i</i></sub>∩<i>E</i><sub><i>j</i></sub>) = <i>p</i>(<i>E</i><sub><i>i</i></sub>)<i>p</i>(<i>E</i><sub><i>j</i></sub>)</span> for all integers <span class="formula"><i>i</i></span> and <span class="formula"><i>j</i></span> with <span class="formula">1 ≤ <i>i</i> &lt; <i>j</i> ≤ <i>n</i></span>. Events are said to be <i>mutually independent </i>if the following is true<div class="formula">
(<i>E</i><sub><i>i</i><sub>1</sub></sub>∩<i>E</i><sub><i>i</i><sub>2</sub></sub>∩…∩<i>E</i><sub><i>i</i><sub><i>m</i></sub></sub>) = <i>p</i>(<i>E</i><sub><i>i</i><sub>1</sub></sub>)<i>p</i>(<i>E</i><sub><i>i</i><sub>2</sub></sub>)…<i>p</i>(<i>E</i><sub><i>i</i><sub><i>m</i></sub></sub>)
</div>
when for <span class="formula"><i>i</i><sub><i>j</i></sub></span>, <span class="formula">1 &lt; <i>j</i> ≤ <i>m</i></span> and <span class="formula">1 ≤ <i>i</i><sub>1</sub> &lt; <i>i</i><sub>2</sub> &lt; … &lt; <i>i</i><sub><i>m</i></sub> ≤ <i>n</i></span>. It should be noted that all mutually independent events are also pairwise independent, but not all pairwise independent events are mutually independent.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.8">3.8</a> Bernoulli Trials
</h2>
<div class="Unindented">
An experiment that only has two possible outcomes is called a <i>Bernoulli trial. </i>Bernoulli trials consist of independent events. Examples of such experiments include flipping a coin and generating bits at random.
</div>
<div class="Theorem">
The probability of exactly k successes in n independent Bernoulli trials, with probability of success p and probability of failure q = 1−p, is
</div>
<div class="Theorem">
<div class="formula">
<i>C</i>(<i>n</i>, <i>k</i>)<i>p</i><sup><i>k</i></sup><i>q</i><sup><i>n</i> − <i>k</i></sup>
</div>

</div>
<div class="Proof">
When <span class="formula"><i>n</i></span> Bernoulli trials are carried out, the outcome is an n-tuple <span class="formula">(<i>t</i><sub>1</sub>, <i>t</i><sub>2</sub>, …, <i>t</i><sub><i>n</i>)</sub></span>. Wherefore <span class="formula"><i>t</i><sub><i>i</i></sub></span>, from <span class="formula">1 ≤ <i>i</i> ≤ <i>n</i></span> each is denoted <span class="formula"><i>S</i></span> in a successful trial and <span class="formula"><i>F</i></span> in a failed trial. Because the <span class="formula"><i>n</i></span> trials are independent the probability of <span class="formula"><i>k</i></span> success and <span class="formula"><i>n</i> − <i>k</i></span> failures is <span class="formula"><i>p</i><sup><i>k</i></sup><i>q</i><sup><i>n</i> − <i>k</i></sup></span>. Further, there are <span class="formula"><i>C</i>(<i>n</i>, <i>k</i>)</span>tuples in which there are <span class="formula"><i>k</i></span> successes, and so the probability is \strikeout off\uuline off\uwave off<span class="formula"><i>C</i>(<i>n</i>, <i>k</i>)<i>p</i><sup><i>k</i></sup><i>q</i><sup><i>n</i> − <i>k</i></sup></span>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.9">3.9</a> Random Variables
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.10">3.10</a> Expected Value and Variance
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.11">3.11</a> Limit Theorems
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-4">4</a> Linear Algebra and Integer Linear Programming<a class="Label" name="sec:Linear-Programming"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.1">4.1</a> Linear Equations in Linear Algebra
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.2">4.2</a> Matrix Algebra
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.3">4.3</a> Determinants
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.4">4.4</a> Vector Spaces
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.5">4.5</a> Eigenvalues and Eigenvectors
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.6">4.6</a> Orthogonality and Least Squares
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.7">4.7</a> Symmetric Matrices and Quadratic Forms
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.8">4.8</a> Geometry of Vector Spaces
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.9">4.9</a> Basic Properties of Linear Programs
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.10">4.10</a> The Simplex Method
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.11">4.11</a> Duality and the Complementary
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.12">4.12</a> Interior Point Methods
</h2>
<h1 class="Part">
<a class="toc" name="toc-Part-II">Part II.</a> Computability
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-5">5</a> Deterministic Finite Automata<a class="Label" name="sec:deterministicFiniteAutomata"> </a>
</h1>
<div class="Unindented">
Finite automata are a systems of information represented by states, transitions, and inputs. Information about the computation is derived from the state in which the automata exists and no previous information can be remembered by the finite automata. The limits to which the finite automata can model information are expressed by the number of states.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-5.1">5.1</a> Notation of DFA’s<a class="Label" name="subsec:Notation-of-DFA's"> </a>
</h2>
<div class="Unindented">
Traditionally finite automata<a class="IndexReference" name="entry-automata-0" href="#index-automata">↓</a> are expressed by a tuple of sets which express its behavior. The tuple, for example <span class="formula"><i>L</i> = (<i>Q</i>, Σ, <i>δ</i>, <i>q</i><sub>0</sub>, <i>F</i>)</span>, contains information on the states expressed by the set Q, the input alphabet<a class="IndexReference" name="entry-alphabet-0" href="#index-alphabet">↓</a> expressed by the set <span class="formula">Σ</span>, the transitions<a class="IndexReference" name="entry-transitions-0" href="#index-transitions">↓</a> expressed by the function <span class="formula"><i>δ</i></span>, the starting state given by <span class="formula"><i>q</i><sub>0</sub></span>, and the set of final states given by <span class="formula"><i>F</i></span>. An example of a finite automata can be seen in Figure<a class="Reference" href="#fig:productDFA">15↓</a>. Strings are typically represented by variables of lowercase letters at the end of the alphabet ( w, x, y, and z) whereas characters are represented variables of lowercase letters at the beginning of the English alphabet ( a, b, and c). <span class="formula">Σ<sup>*</sup></span> represents the set of all strings over the alphabet <span class="formula">Σ</span> including the empty string–the super-script star symbol is referred to as the Kleene star<a class="IndexReference" name="entry-Kleene-star-0" href="#index-Kleene-star">↓</a>. The empty string is denoted by the epsilon symbol <span class="formula"><i>ϵ</i></span>. The empty string denotes a string of length 0, a string of no characters. Length is often expressed by vertical bars surrounding the string in question, such as <span class="formula">|<i>w</i>|</span>. A transition function <span class="formula"><i>δ</i></span> takes two parameters, a state and an input symbol, and returns the next state to which the automaton should transition on input of the symbol ( i. e <span class="formula"><i>δ</i>(<i>q</i>, </span>a)). 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-5.2">5.2</a> Computation of DFA’s<a class="Label" name="subsec:Computation-of-DFA's"> </a>
</h2>
<div class="Unindented">
Given a finite automata, computation can be carried out on an input string by processing each character of the input one-by-one and following the transitions based on the input character. by Upon encountering the last character in the input string computation stops and based on whether the state is a final state (accepting state) or a nonaccepting state, the string is either accepted or rejected. Accepted strings are said to be in the language of the automaton rejected strings are not in the language. Given an automaton <span class="formula"><i>A</i></span> the language of <span class="formula"><i>A</i></span> is denoted <span class="formula"><i>L</i>(<i>A</i>)</span>. A language is a subset of 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-5.3">5.3</a> Regular Languages<a class="Label" name="subsec:Regular-Languages"> </a>
</h2>
<div class="Unindented">
A language is a regular language<a class="IndexReference" name="entry-regular-language-0" href="#index-regular-language">↓</a> if it is accepted by some <a class="IndexReference" name="entry-deterministic-finite-automata-(DFA-0" href="#index-deterministic-finite-automata-(DFA">↓</a>deterministic finite automata (DFA). A caveat here is that the DFA must accept only those strings in the language it models and no others. Nonregular languages are those that cannot be modeled by a DFA. Examples of nonregular languages are those that require automata to count beyond a finite number of states. The classical example is the language L = {<span class="formula">0<sup><i>n</i></sup>1</span><span class="formula"><sup><i>n</i></sup></span> | <span class="formula"><i>n</i> ≥ 1</span>}. DFA’s cannot check for the same number of symbols in a string or balanced parenthesis. This job falls to context free grammars.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-6">6</a> Nondeterministic Finite Automata<a class="Label" name="sec:Nondeterministic-Finite-Automata"> </a>
</h1>
<div class="Unindented">
A <a class="IndexReference" name="entry-nondeterministic-finite-automaton-(NFA)-0" href="#index-nondeterministic-finite-automaton-(NFA)">↓</a>nondeterministic finite automaton (NFA) differs from its deterministic counterpart in that it may be in many states at once. Transitions on an input symbol may proceed to any number states. This idea is demonstrated in Figure<a class="Reference" href="#fig:nfaExample">9 on page 1↓</a>. NFA’s are equivalent to DFA’s and such anything that can be modeled with a NFA can be modeled with a DFA. Thus, the class of languages modeled by NFA’s is the regular languages.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:nfaExample"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/nfaExample.png" alt="figure Diagrams/nfaExample.png" style="width: 88px; max-width: 177px; height: 81px; max-height: 162px;"/>

</div>
<div class="caption">
Figure 9 The NFA depicted in the diagram shows that on input symbol <span class="formula"><i>a</i></span>the automaton transitions to the state <span class="formula"><i>q</i><sub>1</sub>, <i>q</i><sub>2</sub></span> and <span class="formula"><i>q</i><sub>3</sub></span> at the same time. 
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-6.1">6.1</a> Proof of Equivalence of NFA’s and DFA’s<a class="Label" name="subsec:Proof-of-Equivalence"> </a>
</h2>
<div class="Unindented">
The proof of equivalence between DFA’s and NFA’s is often called the Subset Construction. In the succeeding proof given a NFA the states <span class="formula"><i>Q</i><sub><i>N</i></sub></span>, inputs <span class="formula">Σ</span>, transition function <span class="formula"><i>δ</i><sub><i>N</i></sub></span>, start state q, and final states <span class="formula"><i>F</i></span>. The set of states of the constructed DFA <span class="formula"><i>Q</i><sub><i>D</i></sub></span> = 2<span class="formula"><sup><i>Q</i><sub><i>N</i></sub></sup></span>, that is the power set of the set of states of the NFA. A power set of a set is defined as the set of all possible subsets of a given set. The inputs to the DFA will be the same as the inputs of the NFA, <span class="formula">Σ</span>. The start state of the DFA is the set containing the start state, <span class="formula"><i>q</i><sub>0</sub></span> of the NFA. The DFA states are named such that they enumerate the powerset’s subsets with labels that correspond to the states of the NFA. The transition function for the DFA, <span class="formula"><i>δ</i><sub><i>D</i></sub></span> is defined by <span class="formula"><i>δ</i><sub><i>D</i></sub>({<i>q</i><sub>1, </sub><i>q</i><sub>2</sub>, …<i>q</i><sub><i>k</i></sub>}, <i>a</i>)</span> is the union over all i, for i = 1<span class="formula">…<i>k</i></span> of the NFA’s transition function <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>q</i><sub><i>i</i></sub>, <i>a</i>)</span>. To prove equivalence of the DFA and NFA representation we must show that <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>q</i><sub>0</sub>, <i>w</i>) = <i>δ</i><sub><i>D</i></sub>(<span class="symbol">{</span><i>q</i><sub>0</sub><span class="symbol">}</span>, <i>w</i>)</span>. The proof is an induction on the string <span class="formula"><i>w</i></span>. For the basis step we take <span class="formula"><i>w</i> = <i>ϵ</i></span> : <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>q</i><sub>0</sub>, <i>ϵ</i>) = <i>δ</i><sub><i>D</i></sub>(<span class="symbol">{</span><i>q</i><sub>0</sub><span class="symbol">}</span>, <i>ϵ</i>) = {<i>q</i><sub>0</sub>}</span> . This is true by the basis rule for extending the delta function for NFA’s and DFA’s. We assume that the inductive hypothesis holds from strings shorter than <span class="formula"><i>w</i></span>. Let <span class="formula"><i>w</i> = <i>xa</i></span>. The inductive hypothesis holds from the string <span class="formula"><i>x</i></span>. Let <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>q</i><sub>0</sub>, <i>x</i>) = <i>δ</i><sub><i>D</i></sub>({<i>q</i><sub>0</sub>}, <i>x</i>) = <i>S</i>.</span> <span class="formula"><i>S</i></span> represents a label for a set of states of the NFA. Let <span class="formula"><i>T</i></span> be the union over all states <span class="formula"><i>p</i></span> in <span class="formula"><i>S</i></span> of <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>p</i>, <i>a</i>).</span> Then <span class="formula"><i>δ</i><sub><i>N</i></sub>(<i>q</i><sub>0</sub>, <i>w</i>) = <i>δ</i><sub><i>D</i></sub>({<i>q</i><sub>0</sub>}, <i>w</i>) = <i>T</i></span> by the rule for extending delta functions of NFA’s and DFA’s. Thus, DFA’s and NFA’s are equivalent.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-6.2">6.2</a> Conversion from NFA to DFA<a class="Label" name="subsec:Conversion-from-NFA"> </a>
</h2>
<div class="Unindented">
An example of a transition function on a chess board shown in Figure<a class="Reference" href="#fig:chessBoard">10 on page 1↓</a> is given by the NFA’s transition table in Figure<a class="Reference" href="#fig:convertNFA2DFA">11 on page 1↓</a>. An equivalent DFA transition table is given by the adjoining table in the diagram. A lazy conversion technique can be carried out to only include the state sets in the DFA only when necessary. An automaton modeling the NFA representation of the chess board is depicted in Figure<a class="Reference" href="#fig:chessNFA2">12 on page 1↓</a>. A corresponding DFA automaton representation is depicted in Figure
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:chessBoard"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/chessBoard.png" alt="figure Diagrams/chessBoard.png" style="width: 90px; max-width: 181px; height: 90px; max-height: 180px;"/>

</div>
<div class="caption">
Figure 10  A traditional chess board enumerating the black and red squares with odd and even numbers, respectively. In this board a transition onto state <span class="formula">9</span> constitutes an accepting state.
</div>

</div>

</div>

</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:convertNFA2DFA"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
NFA
</td>
<td align="center" valign="top">
r
</td>
<td align="center" valign="top">
b
</td>

</tr>
<tr>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
2,4
</td>
<td align="center" valign="top">
5
</td>

</tr>
<tr>
<td align="center" valign="top">
2
</td>
<td align="center" valign="top">
4,6
</td>
<td align="center" valign="top">
1,3,5
</td>

</tr>
<tr>
<td align="center" valign="top">
3
</td>
<td align="center" valign="top">
2,6
</td>
<td align="center" valign="top">
5
</td>

</tr>
<tr>
<td align="center" valign="top">
4
</td>
<td align="center" valign="top">
2,8
</td>
<td align="center" valign="top">
1,5,7
</td>

</tr>
<tr>
<td align="center" valign="top">
5
</td>
<td align="center" valign="top">
2,4,6,8
</td>
<td align="center" valign="top">
1,3,7,9
</td>

</tr>
<tr>
<td align="center" valign="top">
6
</td>
<td align="center" valign="top">
2,8
</td>
<td align="center" valign="top">
3,5,9
</td>

</tr>
<tr>
<td align="center" valign="top">
7
</td>
<td align="center" valign="top">
4,8
</td>
<td align="center" valign="top">
5
</td>

</tr>
<tr>
<td align="center" valign="top">
8
</td>
<td align="center" valign="top">
4,6
</td>
<td align="center" valign="top">
5,7,9
</td>

</tr>
<tr>
<td align="center" valign="top">
*9
</td>
<td align="center" valign="top">
6,8
</td>
<td align="center" valign="top">
5
</td>

</tr>

</table>
 <table>
<tr>
<td align="center" valign="top">
DFA
</td>
<td align="center" valign="top">
r
</td>
<td align="center" valign="top">
b
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>5<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 5, 7<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>5<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 7, 9<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 5, 7, 9<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 5, 7<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 5, 7, 9<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
*<span class="formula"><span class="symbol">{</span>1, 3, 7, 9<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>5<span class="symbol">}</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
*<span class="formula"><span class="symbol">{</span>1, 3, 5, 7, 9<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span>
</td>
<td align="center" valign="top">
<span class="formula"><span class="symbol">{</span>1, 3, 5, 7, 9<span class="symbol">}</span></span>
</td>

</tr>

</table>

</div>
<div class="caption">
Figure 11  In the transition table for either the NFA or DFA. Odd numbered states can be viewed as the black squares of a chess board while even numbered states are the red squares. Note that the list of states in the NFA transitions expresses the fact that the NFA transitions to the enumerated states simultaneously, while the DFA bracketed states express the label of the single state to which the DFA transitions on the input symbol. In the DFA table the state set label <span class="formula"><span class="symbol">{</span>2, 4<span class="symbol">}</span></span> is assigned the state <span class="formula"><span class="symbol">{</span>2, 4, 6, 8<span class="symbol">}</span></span> on input r because it represents the union of the transitions of the states to which the NFA will transition to on input r from either state 2 or 4. This logic applies for all other states set given in the DFA table as well. Star symbols in either table indicate a final state.
</div>

</div>

</div>

</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:chessNFA2"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/chessNFA2.png" alt="figure Diagrams/chessNFA2.png" style="width: 234px; max-width: 468px; height: 198px; max-height: 396px;"/>

</div>
<div class="caption">
Figure 12  The chess NFA automaton. Transitions from odd numbers to even numbers occur on the input symbol <span class="formula"><i>r</i></span>. Transitions from even numbers to odd numbers occur on input symbol <span class="formula"><i>b</i></span>. Transition labels have been omitted for the sake of clarity.
</div>

</div>

</div>

</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:chessDFA"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/chessDFA.png" alt="figure Diagrams/chessDFA.png" style="width: 160px; max-width: 321px; height: 203px; max-height: 406px;"/>

</div>
<div class="caption">
Figure 13  The chess DFA automaton.
</div>

</div>

</div>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-7">7</a> <span class="formula"><i>ϵ</i> − </span>NFA’s<a class="Label" name="sec:epsilonNFA's"> </a>
</h1>
<div class="Unindented">
NFA’s that allow for epsilon transitions are called epsilon NFA. Epsilon transitions allow for an automaton to transition between states without regard to the input string. Effectively, it allows for the computation to skip forward in the automaton without processing input. An example of an epsilon NFA is depicted in Figure<a class="Reference" href="#fig:epsilonNFA">14 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:epsilonNFA"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/epsilonNFA.png" alt="figure Diagrams/epsilonNFA.png" style="width: 142px; max-width: 285px; height: 72px; max-height: 144px;"/>

</div>
<div class="caption">
Figure 14  Epsilon transitions are marked with a <span class="formula"><i>ϵ</i></span>symbol. Upon transitioning to state <span class="formula"><i>q</i><sub>2</sub></span> the automaton spontaneously and in parallel transitions to states <span class="formula"><i>q</i><sub>1</sub></span>, <span class="formula"><i>q</i><sub>3</sub></span> and <span class="formula"><i>q</i><sub>5</sub></span>. 
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-7.1">7.1</a> Closure of States<a class="Label" name="subsec:Closure-of-States"> </a>
</h2>
<div class="Unindented">
The closure of states is defined as the set of states reachable from state in question. The function is traditionally denoted <span class="formula"><i>CL</i>(<i>q</i>).</span> The closure of state <span class="formula"><i>q</i>2</span> in Figure <a class="Reference" href="#fig:epsilonNFA">14 on page 1↑</a> is <span class="formula"><span class="symbol">{</span><i>q</i>2, <i>q</i>1, <i>q</i>3, <i>q</i>5<span class="symbol">}</span></span>.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-8">8</a> Regular Expressions<a class="Label" name="sec:Regular-Expressions"> </a>
</h1>
<div class="Unindented">
Regular expressions use three operations: union, concatenation, and Kleene star. Concatenation on languages <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span>is denoted <span class="formula"><i>LM</i>.</span> <span class="formula"><i>LM</i></span> is defined as <span class="formula"><i>wx</i></span> where <span class="formula"><i>w</i><i>ε</i><i>L</i></span> and <span class="formula"><i>x</i><i>ε</i><i>M</i></span>. Kleene star (<span class="formula"><sup>*</sup>)</span> is the set of strings formed by concatenating 0 or more strings of <span class="formula"><i>L</i></span> in any order. The Kleene star of <span class="formula"><i>L</i></span> is then <span class="formula"><i>L</i><sup>*</sup> = <span class="symbol">{</span><i>ϵ</i><span class="symbol">}</span>∪<i>L</i>∪<i>LL</i>…</span> 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-8.1">8.1</a> Precedence of Operators on Regular Expressions<a class="Label" name="subsec:Precedence-of-Operators"> </a>
</h2>
<ol>
<li>
Parenthesis
</li>
<li>
Kleene star
</li>
<li>
Concatenation
</li>
<li>
Union
</li>

</ol>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-8.2">8.2</a> Algebraic Laws and Identities of Regular Expressions<a class="Label" name="subsec:algebraicLawsAndIdentitesRegularLanguages"> </a>
</h2>
<div class="Unindented">
Union is commutative and associative. Concatenation is associative however is not commutative.<span class="formula">∅</span> is the identity for union.<span class="formula"><i>ϵ</i></span>is the identity for concatenation. <span class="formula">∅</span> is the annihilator for concatenation.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-9">9</a> Properties of Language Classes<a class="Label" name="sec:propertiesOfLanguages"> </a>
</h1>
<div class="Unindented">
A language class is a set of languages, and language classes have two important properties.
</div>
<ul>
<li>
Decision properties<a class="IndexReference" name="entry-decision-properties-0" href="#index-decision-properties">↓</a> - algorithms that when applied to a language determine whether a certain property holds (e.g. is a language empty).
</li>
<li>
Closure properties<a class="IndexReference" name="entry-closure-properties-0" href="#index-closure-properties">↓</a> - describes the operations in which when applied to a language class produce another language in the same language class (e.g. union)
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-9.1">9.1</a> Decision Properties of Regular Languages<a class="Label" name="subsec:DecisionPropertiesOfRegularLanguages"> </a>
</h2>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.1.1">9.1.1</a> The Membership Test for Regular Languages<a class="Label" name="subsec:membershipTestForRegularLanguages"> </a> 
</h3>
<div class="Unindented">
The classic decision property for languages is the Membership Test. That is, is a given string w in the language. The algorithm to determine this is simply to simulate the string on the DFA of the language. If the simulation of w on the DFA ends in an accepting state, then the string is in the language, otherwise the string has ended in a non-accepting state of the DFA and it is thus not in the language. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.1.2">9.1.2</a> The Emptiness Test for Regular Languages<a class="Label" name="subsec:emptinessTestForRegularLanguages"> </a>
</h3>
<div class="Unindented">
Another example of decision properties is the Emptiness Problem. That is given a regular language, does it contain any strings at all? To determine whether the language has any strings first obtain the DFA-representation of the language and then compute the reachable states from the start state. A good way of doing this is Breadth-First Search on the graph of the DFA. If a accepting state is reachable from the start state then we know that at least one string is in the language.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.1.3">9.1.3</a> The Equivalence Test for Regular Languages<a class="Label" name="subsec:equivalenceTestForRegularLanguages"> </a>
</h3>
<div class="Unindented">
Another example of decision properties is testing whether two languages, L and M, are equivalent. Their DFA’s are specified as follows: <span class="formula"><i>L</i> = (<i>Q</i>, Σ, <i>δ</i><sub><i>L</i></sub>, <i>A</i>, <i>F</i><sub><i>L</i></sub>)</span> and <span class="formula"><i>M</i> = (<i>R</i>, Σ, <i>δ</i><sub><i>M</i></sub>, <i>C</i>, <i>F</i><sub><i>M</i></sub>)</span> where <span class="formula"><i>Q</i> = {<i>A</i>, <i>B</i>}</span>, <span class="formula"><i>R</i> = <span class="symbol">{</span><i>C</i>, <i>D</i><span class="symbol">}</span></span>, and <span class="formula">Σ = {0, 1}</span>. The transition function on each DFA, L and M can be seen in Figure<a class="Reference" href="#fig:productDFA">15 on page 1↓</a>. To test equivalence one may form a product on the states of each DFA such that for each respective state in Q and R the product DFA’s state set is <span class="formula"><i>Q</i> × <i>R</i></span> has a corresponding state. The start state for the product DFA would then be the pair <span class="formula"><span class="symbol">[</span><i>q</i><sub>0</sub>, <i>r</i><sub>0</sub><span class="symbol">]</span></span> . The transition function would then be formed as follows: <span class="formula"><i>δ</i>(<span class="symbol">[</span><i>q</i>, <i>r</i><span class="symbol">]</span>, 1) = <span class="symbol">[</span><i>δ</i><sub><i>L</i></sub>(<i>q</i>, 1), <i>δ</i><sub><i>M</i></sub>(<i>r</i>, 1)<span class="symbol">]</span></span>. The product DFA N pictured in Figure<a class="Reference" href="#fig:productDFA">15 on page 1↓</a> is assigned final states such that either the one of the state pair’s respective DFA enters a final state, but not both. For example, the state B is a final state in the DFA L, and the state C is a final state in the DFA M. The state pair (B,D) is then marked final in the DFA N instead of (B,C) because the state D is not a final state in the DFA M. Similarly, the state pair (A,C) is marked a final state in the DFA N because C in final state the DFA M, but A is not a final state in the DFA L. This feature of only one state being accepting is used a differentiating characteristic to determine whether the languages of the DFA’s L and M are equivalent. The languages L and M are equivalent if and only if the language of N is empty. This means that N models the feature that neither L accepts when M does not, nor does M accept when L does not. It is clear from the that the empty string <span class="formula"><i>ϵ</i></span> is accepted by M and not by L and is so modeled by the pair (A,C) in N. N accepts the empty string and therefore, L and M are not equivalent languages.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:productDFA"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/productDFA.png" alt="figure Diagrams/productDFA.png" style="width: 199px; max-width: 398px; height: 105px; max-height: 210px;"/>

</div>
<div class="caption">
Figure 15 The transition function formed on newly formed state set of \strikeout off\uuline off\uwave off<span class="formula"><i>Q</i> × <i>R</i></span> corresponds to the transitions of L and M.<span class="default">\uuline default\uwave default </span>
</div>

</div>

</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.1.4">9.1.4</a> The Infiniteness Test for Regular Languages<a class="Label" name="subsec:infinitenessTestRegularLanguages"> </a>
</h3>
<div class="Unindented">
A final example of decision problems fro regular languages in the Infiniteness Problem. The problem asks, is the given regular language composed of an infinite number of strings? We can determine if a given language is infinite by examining the DFA-representation of the language. If the DFA has n states, and the given language has a string of n or more in length, then the language is infinite. Otherwise, the language must be finite. (If a language has a string of length n or more, then surely the DFA contains a cycle that yielded such a string). The proof of this idea follows: If there is a n-state DFA that accepts a string w of length n or more, then there must be a state that appears twice on the path traced out by the simulation of w on the DFA from the start state to the final state. This is because for all strings w of length n a DFA must traverse n+1 states. A diagram of the automaton demonstrating this principle can be seen in Figure <a class="Reference" href="#fig:pumpingLemma">16 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:pumpingLemma"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/pumpingLemma.png" alt="figure Diagrams/pumpingLemma.png" style="width: 88px; max-width: 177px; height: 38px; max-height: 76px;"/>
<div class="caption">
Figure 16 In the automaton pictured above a string w is formed by the the substrings x, y, and z. The substring x is the substring that takes us to the first cycle in the automaton. The cycle occurs at state q. The edge labeled y represents the edge which returns the string w to state q for the first time. Because the substring y is locked within the string w, that is its prefix is the substring x and its postfix is the substring z, it cannot be the empty string. However, the substrings x or z may be the empty string. Then <span class="formula"><i>xy</i><sup><i>i</i></sup><i>z</i></span> for all <span class="formula"><i>i</i> ≥ 0</span> is in the language, and therefore an infinite number of strings exist in the language.
</div>

</div>

</div>

</div>

</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-1"></a>Claim: If there is a string of length <span class="formula"> ≥ <i>n</i></span> in L, then there is a string of length <span class="formula"><span class="symbol">[</span><i>n</i>, 2<i>n</i> − 1<span class="symbol">]</span></span> . 
</div>
<div class="Unindented">
Proof: Because y is the first cycle on the path to the accepting state, the length <span class="formula">|<i>xy</i>| ≤ <i>n</i></span>, and more specifically, <span class="formula">1 ≤ |<i>y</i>| ≤ <i>n</i></span> ( x and z may be empty strings). Some state along the path xy surely must repeat. If w is the shortest possible string of length n, then it cannot be longer than 2n. However, suppose it was. The string xz is another accepted string in the language. We know that xz = w - y, and the length of <span class="formula"><i>y</i> ≤ <i>n</i></span>, so the length of <span class="formula"><i>xz</i> ≥ <i>n</i></span>. Which means that <span class="formula">|<i>xz</i>| ≤ |<i>w</i>|</span>, and yet at least n in length which is accepted, but we assumed that the were no strings that were shorter than w and of length at least n. Thus, if the string w were of length <span class="formula">≧2<i>n</i></span> , there is a shorter string of length <span class="formula"><span class="symbol">[</span><i>n</i>, 2<i>n</i> − 1<span class="symbol">]</span></span> formed by removing the substrings represented by y which are <span class="formula"><span class="symbol">[</span>1, <i>n</i><span class="symbol">]</span></span> . 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-9.2">9.2</a> Closure Properties of Regular Languages<a class="Label" name="subsec:closurePropertiesOfRegularLanguages"> </a>
</h2>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.1">9.2.1</a> Union for Regular Languages<a class="Label" name="subsec:UnionForRegularLanguages"> </a>
</h3>
<div class="Unindented">
If <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> are regular languages, then <span class="formula"><i>L</i>∪<i>M</i></span> is also a regular language. The proof of this statement is as follows: Let the languages <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> be the languages of the regular expressions <span class="formula"><i>R</i></span> and <span class="formula"><i>S</i></span> respectively, then <span class="formula"><i>R</i> + <i>S</i></span> is a regular expression whose language is the <span class="formula"><i>L</i>∪<i>M</i></span>. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.2">9.2.2</a> Intersection for Regular Languages<a class="Label" name="subsec:IntersectionForRegularLanguages"> </a>
</h3>
<div class="Unindented">
If <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> are regular languages, then <span class="formula"><i>L</i>∩<i>M</i></span> is also a regular language. The proof of this statement is as follows: Let <span class="formula"><i>I</i></span> and <span class="formula"><i>J</i></span> be the DFA’s for the regular languages <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span>, respectively. Form the product DFA <span class="formula"><i>K</i></span> of <span class="formula"><i>I</i></span> and <b><span class="formula"><i>J</i></span> </b>and mark the final states of <span class="formula"><i>K</i></span> as the states in which both <span class="formula"><i>I</i></span> and <span class="formula"><i>J</i></span> are in final states. The DFA <span class="formula"><i>K</i></span> is now a regular language representing <span class="formula"><i>L</i>∩<i>M</i></span>. This idea is demonstrated in Figure<a class="Reference" href="#fig:intersectionDFA">17 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:intersectionDFA"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/intersectionDFA.png" alt="figure Diagrams/intersectionDFA.png" style="width: 199px; max-width: 398px; height: 105px; max-height: 210px;"/>

</div>
<div class="caption">
Figure 17 The product DFA <span class="formula"><i>K</i></span> represents the intersection of <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> and its final state is the state pair for which a final state exists for both <span class="formula"><i>I</i></span> and <span class="formula"><i>J</i></span>. 
</div>

</div>

</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.3">9.2.3</a> Difference for Regular Languages<a class="Label" name="subsec:DifferenceForRegularLanguages"> </a>
</h3>
<div class="Unindented">
If <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> are regular languages, then <span class="formula"><i>L</i> − <i>M</i></span> is also a regular language. <span class="formula"><i>L</i> − <i>M</i></span> represents the strings that are in <span class="formula"><i>L</i></span> but not in <span class="formula"><i>M</i></span>. The proof of this statement is as follows: Let <span class="formula"><i>I</i></span> and <span class="formula"><i>J</i></span> be the DFA’s for the regular languages <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span>, respectively. Form the product DFA <span class="formula"><i>K</i></span> of <span class="formula"><i>I</i></span> and <b><span class="formula"><i>J</i></span> </b>and mark the final states of <span class="formula"><i>K</i></span> as the states in which <span class="formula"><i>I</i></span> is in a final state and <span class="formula"><i>J</i></span> is not in a final state. The DFA <span class="formula"><i>K</i></span> now represents <span class="formula"><i>L</i> − <i>M</i></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.4">9.2.4</a> Concatenation for Regular Languages<a class="Label" name="subsec:ConcatenationForRegularLanguages"> </a>
</h3>
<div class="Unindented">
If <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> are regular languages, then <span class="formula"><i>LM</i></span> is also a regular language. The proof of this statement is as follows: Let the languages <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span> be the languages of the regular expressions <span class="formula"><i>R</i></span> and <span class="formula"><i>S</i></span> respectively, then <span class="formula"><i>RS</i></span> is a regular expression whose language is the <span class="formula"><i>LM</i></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.5">9.2.5</a> Kleene Closure for Regular Languages<a class="Label" name="subsec:KleeneClosureForRegularLanguages"> </a>
</h3>
<div class="Unindented">
<span class="formula"><i>R</i><sup>*</sup></span> is a regular expression whose language is <span class="formula"><i>L</i><sup>*</sup></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-9.2.6">9.2.6</a> Complement for Regular Languages<a class="Label" name="subsec:ComplementForRegularLanguages"> </a>
</h3>
<div class="Unindented">
The complement of a language <span class="formula"><i>L</i></span> with respect to an alphabet <span class="formula">Σ</span> such that <span class="formula">Σ<sup>*</sup></span>contains <span class="formula"><i>L</i></span> is the difference of <span class="formula">Σ<sup>*</sup></span> and the language <span class="formula"><i>L</i></span>. Since <span class="formula">Σ<sup>*</sup></span> is surely a regular language, and regular languages are closed under difference as we have seen previously, then the complement <span class="formula">Σ<sup>*</sup> − <i>L</i></span> is also regular.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-10">10</a> Conversion of Language Representations<a class="Label" name="subsec:conversionOfLanguageRepresentations"> </a>
</h1>
<div class="Unindented">
A cycle is formed on the way in which we can represent languages. There exists algorithms to convert from one representation to the next along the cycle depicted in Figure<a class="Reference" href="#fig:representationCycle">18 on page 1↓</a>. As such, given a regular expression one may convert it to a DFA.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:representationCycle"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/representationCycle.png" alt="figure Diagrams/representationCycle.png" style="width: 100px; max-width: 201px; height: 56px; max-height: 112px;"/>

</div>
<div class="caption">
Figure 18  This diagram describes the conversion cycle of representations such that from a regular expression it is possible to obtain a DFA. 
</div>

</div>

</div>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-11">11</a> DFA Minimization<a class="Label" name="sec:DFA-Minimization"> </a>
</h1>
<div class="Unindented">
Minimizing a DFA can be carried out in a naive way by enumerating all smaller DFA’s for any given DFA and checking for equivalence. However, this is terribly inefficient and a smarter algorithm can be used to generate a equivalent DFA much faster.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-11.1">11.1</a> DFA Minimization Algorithm<a class="Label" name="subsec:DFA-Minimization-Algorithm"> </a>
</h2>
<div class="Unindented">
The key idea here is to create a table used to find distinguishable states. Distinguishable state pairs are those that have one member of the pair in an accepting state while the other is not in an accepting state. The table used to distinguish these pairs is formed by the product of the DFA’s states, <span class="formula"><i>Q</i> × <i>Q</i></span>. If states can be distinguished then they represent a state in minimum DFA, while those that are indistinguishable can be merged into a single state. Effectively, we are recursively finding the shortest distinguishable string for a DFA.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-12">12</a> The Pumping Lemma for Regular Languages<a class="Label" name="sec:pumpingLemmaRegularLanguages"> </a>
</h1>
<div class="Unindented">
For every regular language L, there is an integer n, which happens to be the number of states in the DFA of L, such that for every w in L of length <span class="formula"> ≥ <i>n</i></span>. We can write w = xyz such that the following properties hold:
</div>
<ol>
<li>
<span class="formula">|<i>xy</i>| ≤ <i>n</i></span>
</li>
<li>
<span class="formula">|<i>y</i>| &gt; 0</span>
</li>
<li>
For all <span class="formula"><i>i</i> ≥ 0</span>, <span class="formula"><i>xy</i><sup><i>i</i></sup><i>z</i></span> is in L.<a class="Label" name="enu:PumpingLemmaProperty3"> </a>
</li>

</ol>
<div class="Unindented">
The Pumping Lemma is useful in determining whether a language is regular or nonregular.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-12.1">12.1</a> Using the Pumping Lemma to Prove a Language is Nonregular<a class="Label" name="subsec:usingThePumpingLemmaToProveALanguageIsNonregular"> </a>
</h2>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-2"></a>Claim: L = {<span class="formula">0<sup><i>k</i></sup>1</span><span class="formula"><sup><i>k</i></sup></span> | <span class="formula"><i>k</i> ≥ 1</span>} is a nonregular language.
</div>
<div class="Unindented">
Proof: Suppose for the purposes of contradiction that L is a regular language, then there exists an n for which the properties of the Pumping Lemma hold true.Let w = <span class="formula">0<sup><i>n</i></sup>1</span><span class="formula"><sup><i>n</i></sup></span>. The string w can be written in the form w = xyx where each component x, y, z forms some substring of w where x and consist of 0’s and <span class="formula"><i>y</i>¬ = <i>ϵ</i></span>, and z is composed of 1’s. However, for this to be a regular language all the properties of the Pumping Lemma must hold true. In particular particular property<a class="Reference" href="#enu:PumpingLemmaProperty3">12↑</a>. For <span class="formula"><i>i</i> = 2</span>, <span class="formula"><i>w</i> = <i>xyyz</i></span>. The string formed by this construction contains more 0’s than 1’s, violating the conditions on the language as specified in the set former. Similarly, if yz and consist of 1’s and <span class="formula"><i>y</i>¬ = <i>ϵ</i></span>, the string formed by this construction contains more 1’s than 0’s again violating the conditions of the language. Thus, the language must be nonregular because it does not meet the conditions of the Pumping Lemma. 
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-13">13</a> Context Free Grammars<a class="Label" name="sec:contextFreeGrammars"> </a>
</h1>
<div class="Unindented">
A context free grammar is a notation for describing languages. It is more powerful than regular expressions and finite automata, but still cannot define all possible languages. A context free grammar is composed of variables which stand for a set of strings. These variables are defined in terms of each other. These rules for how variables should be composed are often called productions. Take for example the language L = {<span class="formula">0<sup><i>n</i></sup>1</span><span class="formula"><sup><i>n</i></sup></span> | <span class="formula"><i>n</i> ≥ 1</span>}. This is a familiar language that we saw earlier in the examples on what is not a regular language. A context free grammar (CFG) for <span class="formula"><i>L</i></span> can be defined as <span class="formula"><i>S</i> → 01</span>, <span class="formula"><i>S</i> → 0<i>S</i>1</span>. Here S is defined recursively such that there will always be an equal number of 0’s and 1’s.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-13.1">13.1</a> CFG Nomenclature<a class="Label" name="subsec:CFGNomenclature"> </a>
</h2>
<ul>
<li>
Terminals - symbols of the alphabet of the language being defined.
</li>
<li>
Variables (Nonterminals) - A finite set of other symbols, each of which represents a language.
</li>
<li>
Production (Rule) - a rule defining the relationships of terminals and nonterminals. It has the form HEAD <span class="formula"> → </span> TAIL (BODY). The body is composed of terminals and nonterminals. Each production represents a language on its own and nonterminals in the BODY represent languages on their own. Nonterminals are subsets of the parent language given by the head ( e.g. <span class="formula"><i>A</i> → <i>XY</i></span>, where the concatenation of language <span class="formula"><i>X</i></span> and language<span class="formula"><i>Y</i></span> forms the language <span class="formula"><i>A</i></span>).
</li>
<li>
Derivation - The process of repeatedly replacing symbols for terminals based on the productions of a CFG.
</li>
<li>
Sentential form - the derived string.
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-13.2">13.2</a> Conventional Usage of Context Free Grammars<a class="Label" name="subsec:conventionalUsageOfContextFreeGrammars"> </a>
</h2>
<div class="Unindented">
Capital letters at the beginning of the alphabet are typically used as variables (e.g A, B, C). Lowercase letters at the beginning of the alphabet are used as terminals (a, b, c). Capital letters at the end of the alphabet can be either terminals or variables (X, Y, Z). Lowercase letters at the end of the alphabet are strings containing terminals only (e.g. w, x, y, z). Greek letters are strings of terminals or variables (<span class="formula"><i>α</i>, </span><span class="formula"><i>β</i>, <i>γ</i>)</span>. A star (*) indicates 0 or more steps are necessary to obtain a specified derivation. A variable followed by the epsilon symbol effectively causes the variable to disappear in the derivation process. A <span class="formula"> ⇒ <sub><i>lm</i></sub></span> indicates the sentential form is as specified after one setp of the left most derivation. A <span class="formula"> ⇒ <sub><i>lm</i></sub></span> indicates 0 or more leftmost derivations are required to obtain the specified sentential form. Corresponding symbols for the rightmost derivations exist as well.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-13.3">13.3</a> Context-Free Languages<a class="Label" name="subsec:contextFreeLanguages"> </a>
</h2>
<div class="Unindented">
A language that is defined by some CFG is called a context-free language. Intuitively, a context free language is a language that can count to infinite elements but not three. An example of a non-context free language is <span class="formula"><i>L</i> = {0<sup><i>n</i></sup>1<sup><i>n</i></sup>2<sup><i>n</i></sup>|<i>n</i> ≥ 1}</span>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-13.4">13.4</a> Leftmost and Rightmost Derivations<a class="Label" name="subsec:leftMostRightMostDerivations"> </a>
</h2>
<div class="Unindented">
Leftmost derivations process a string’s variables one-at-the-time from left to right. Similarly, the rightmost derivation is processed from right to left.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-13.5">13.5</a> Normal Forms for CFG’s<a class="Label" name="subsec:normalFormsForCFG"> </a>
</h2>
<div class="Unindented">
Poorly designed context free grammars may have rules that are never used in the derivation of strings. This is similar to a DFA that has unreachable states. CFG’s may also have redundant productions that may be combined. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-13.5.1">13.5.1</a> Eliminating Useless Variables from CFG’s<a class="Label" name="subsec:eliminatingUselessVariables"> </a>
</h3>
<div class="Unindented">
If a CFG’s production never derives a terminal string, then it is useless. In order to discover useless productions and eliminate them we must have an inductive algorithm which determines how the derivation proceeds by marking the variables that do derive terminals. The variables not contained in the set discovered by the algorithm can then be eliminated. The algorithm follows: For the basis step find a productions that derive a string of terminals. If there is a production that derives a string of terminals and variables whose variables have productions that yields strings of terminals alone, then this production derives terminal strings. For example if there is a production <span class="formula"><i>A</i> → <i>w</i></span>, where <span class="formula"><i>w</i></span> consists only of terminals, then this qualifies as our basis. If we then have a production <span class="formula"><i>A</i> → <i>α</i></span> who derives a string of variables and terminals than these may qualify for our inductive step. Additionally, we may have unreachable variables in the grammar. Variables that are unreachable can be eliminated from the grammar by an induction on the variables that are reachable from the start symbol <span class="formula"><i>S</i></span> and the productions that involve the symbols of those that were discovered. Variables not discovered can then be eliminated.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-13.5.2">13.5.2</a> Eliminating Epsilon Productions<a class="Label" name="subsec:elimininatingEpilsonProduction"> </a>
</h3>
<div class="Unindented">
Epsilon productions are of the form <span class="formula"><i>A</i> → <i>ϵ</i></span>. These productions can be eliminated from the grammar, however in doing so the grammar loses the ability to represent the empty string. To eliminate epsilon productions we need to discover the nullable symbols of the grammar. A nullable symbol is a symbol that eventually derives the empty string (i.e. A<span class="formula"> ⇒ <sup>*</sup><i>ϵ</i></span> ). The following inductive argument can be used to discover nullable symbols. The basis is obviously if a production directly derives epsilon as in <span class="formula"><i>A</i> → <i>ϵ</i></span>, then it is a nullable symbol. The induction then becomes, if there is a production <span class="formula"><i>A</i> → <i>α</i></span>, in which all the symbols of <span class="formula"><i>α</i></span>eventually derive epsilon then the production is nullable. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-13.5.3">13.5.3</a> Eliminating Unit Productions<a class="Label" name="subsec:eliminatingUnitProductions"> </a>
</h3>
<div class="Unindented">
Unit productions are productions whose body consist of a single variable. The key idea is that if a variable <span class="formula"><i>A</i></span> eventually derives a variable single variable <span class="formula"><i>B</i></span> by a series of unit productions, and <span class="formula"><i>B</i></span>derives the production <span class="formula"><i>B</i> → <i>α</i></span>, then we can rewrite <span class="formula"><i>A</i></span> as the production <span class="formula"><i>A</i> → <i>α</i></span> and drop all the intermediate unit productions. The algorithm to discover unit productions is as follows: Find all pairs of variables <span class="formula">(<i>A</i>, <i>B</i>)</span> such that <span class="formula"><i>A</i> ⇒ <sup>*</sup><i>B</i></span> by a sequence of unit production only. The induction has the basis <span class="formula">(<i>A</i>, <i>A</i>)</span> and the IH if we have found <span class="formula">(<i>A</i>, <i>B</i>)</span> and <span class="formula"><i>B</i></span> derives <span class="formula"><i>C</i></span>, then <span class="formula"><i>A</i></span> derives <span class="formula"><i>C</i></span> and so they form the pair <span class="formula">(<i>A</i>, <i>C</i>).</span>
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-13.5.4">13.5.4</a> Representing Grammars in Chomsky Normal Form (CNF)<a class="Label" name="subsec:representingGrammarsInChomskyNormalForm"> </a>
</h3>
<div class="Unindented">
Context free grammars in Chomsky Normal Formal are restricted to productions of two types:
</div>
<ul>
<li>
Productions with two variables (<span class="formula"><i>A</i> → <i>BC</i>).</span>
</li>
<li>
Productions with a single terminal (<span class="formula"><i>A</i> → <i>a</i>).</span>
</li>

</ul>
<div class="Unindented">
Theorem: If a language <span class="formula"><i>L</i></span> is a context free language, then the language with all epsilon productions eliminated has a context free grammar in Chomsky Normal Form. Forming the CFG such that it is in CNF can be carried out by cleaning up the grammar as described in the subsections<a class="Reference" href="#subsec:elimininatingEpilsonProduction">13.5.2 on page 1↑</a>,<a class="Reference" href="#subsec:eliminatingUnitProductions">13.5.3 on page 1↑</a>, and <a class="Reference" href="#subsec:eliminatingUselessVariables">13.5.1 on page 1↑</a>. 
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-14">14</a> Pushdown Automata<a class="Label" name="sec:Pushdown-Automata"> </a>
</h1>
<div class="Unindented">
A pushdown automata(PDA) is equivalent in power to a context free grammar (CFG) in that any language defined in terms of a CFG can be equally defined in terms of a PDA. Traditionally, when speaking about PDA’s we mean the nondeterministic type (NPDA). NPDA’s are more powerful than their deterministic counterparts. Intuitively speaking a PDA is like an <span class="formula"><i>ϵ</i> − </span>NFA with the additional power of manipulating a stack. The computation of the PDA is controlled by the state of its <span class="formula"><i>ϵ</i> − </span>NFA, the input symbol to be processed, and finally the symbol on top of its stack. Figure<a class="Reference" href="#fig:pushdownAutomata">19 on page 1↓</a>. In addition to transition to a new state, the PDA may push or pop symbols off of the stack. PDA’s are typically described by the following components <span class="formula"><i>Q</i></span> a finite set of states, <span class="formula">Σ</span> an input alphabet, <span class="formula">Γ</span> a stack alphabet, <span class="formula"><i>δ</i></span> a transition function, <span class="formula"><i>q</i><sub>0</sub></span> a start state,<span class="formula"><i>z</i><sub>0</sub></span> a stack start symbol, and a set of final states <span class="formula"><i>F</i> ⊆ <i>Q</i></span> . The transition function <span class="formula"><i>δ</i></span> is parameterized by three components: a state in <span class="formula"><i>Q</i></span>, an input symbol in <span class="formula">Σ</span>, and a stack symbol in <span class="formula">Γ</span> (e.g. <span class="formula"><i>δ</i>(<i>q</i><sub>0</sub>, <i>a</i>, <i>Z</i>)</span>). The <span class="formula"><i>δ</i></span> of given parameters yields a set of tuples containing a state to transition to and a symbol to manipulate the stack <span class="formula"><span class="symbol">(</span><i>p</i>, <i>a</i><span class="symbol">)</span></span>. Here <span class="formula"><i>p</i></span> represents the next state and <span class="formula"><i>a</i></span>is a string of stack symbols possibly empty. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-14.1">14.1</a> Conventional Usage of Pushdown Automata<a class="Label" name="subsec:conventionalUsageOfPDA"> </a>
</h2>
<div class="Unindented">
Lowercase letters at the beginning of the alphabet (e.g. a, b, c, and <span class="formula"><i>ϵ</i></span>) are used as input symbols. Capital letters at the end of the alphabet are used as stack symbols (e.g. X, Y, and Z). Lowercase letters at the end of the alphabet (e.g. w,x,y, and z) are used as strings of input symbols. Greek letters are used as strings of stack symbols (e.g. <span class="formula"><i>α</i>, <i>β</i></span> and <span class="formula"><i>γ</i>)</span> are strings of stack symbols. An example of a PDA modeling the language <span class="formula"><i>L</i> = {0<sup><i>n</i></sup>1<sup><i>n</i></sup>|<i>n</i> ≥ 1}</span> is given in Figure<a class="Reference" href="#fig:pdaExample">20 on page 1↓</a>. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-14.2">14.2</a> Instantaneous Descriptions and the Goes-To Relation<a class="Label" name="subsec:instantaneousDescriptionsAndGoesToRelation"> </a>
</h2>
<div class="Unindented">
An instantaneous description(ID) of a PDA is like a snapshot of a PDA as it computes. Each successive step in Figure<a class="Reference" href="#fig:pdaExample">20 on page 1↓</a> has a corresponding instantaneous description triple describing the current state <span class="formula"><i>q</i></span>, the remaining input <span class="formula"><i>w</i>, </span>and the contents of the stack <span class="formula"><i>a</i></span>. The vertical dash symbol, <span class="formula">⊢</span>, represents the Goes-To relation. The relation means that for a specified ID I a transition to ID J is possible in one step. For example if the transition function <span class="formula"><i>δ</i>(<i>q</i>, <i>a</i>, <i>X</i>)</span> yields <span class="formula"><span class="symbol">(</span><i>p</i>, <i>β</i><span class="symbol">)</span></span> the we may specify the Goes-To relation as <span class="formula">(<i>q</i>, <i>aw</i>, <i>Xa</i>)⊢(<i>p</i>, <i>w</i>, <i>β</i><i>α</i>)</span>. Similarly, the <span class="formula">⊢<sup>*</sup></span> means the transition occurs in zero or more steps.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-14.3">14.3</a> PDA Language Descriptions<a class="Label" name="subsec:PDALanguageDescriptions"> </a>
</h2>
<div class="Unindented">
The languages of PDA’s are defined by <span class="formula"><i>L</i>(<i>P</i>)</span> for the set of strings <span class="formula"><i>w</i></span> such that for the ID <span class="formula">(<i>q</i><sub>0</sub>, <i>w</i>, <i>Z</i>)</span><span class="formula">⊢<sup>*</sup></span><span class="formula">(<i>f</i>, <i>ϵ</i>, <i>α</i>)</span> for the final state <span class="formula"><i>f</i></span> and the stack string <span class="formula"><i>a</i></span>. This is the set of strings <span class="formula"><i>w</i></span> that are consumed by the PDA such that only the empty string, <span class="formula"><i>ϵ</i>, </span> is left in the final state. The notation <span class="formula"><i>N</i>(<i>P</i>)</span> for a given PDA <span class="formula"><i>P</i></span> describes the PDA’s language when the stack becomes empty.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:pushdownAutomata"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/pushdownAutomata.png" alt="figure Diagrams/pushdownAutomata.png" style="width: 34px; max-width: 68px; height: 88px; max-height: 177px;"/>

</div>
<div class="caption">
Figure 19  Three elements control how a PDA will compute: the input, the state, and the stack
</div>

</div>

</div>

</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:pdaExample"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/pdaExample.png" alt="figure Diagrams/pdaExample.png" style="width: 174px; max-width: 349px; height: 90px; max-height: 181px;"/>

</div>
<div class="caption">
Figure 20 The computation shows the evolution of the PDA’s stack, input and state as the string is processed. The initial starting state is shown on the left and the final accepting state is shown on the right. The following transitions define the behavior: <span class="formula"><i>δ</i>(<i>q</i>, 0, <i>Z</i>) = {(<i>q</i>, <i>XZ</i>)}</span>, <span class="formula"><i>δ</i>(<i>q</i>, 0, <i>X</i>) = {(<i>q</i>, <i>XX</i>)}</span>, <span class="formula"><i>δ</i>(<i>q</i>, 1, <i>X</i>) = {(<i>p</i>, <i>ϵ</i>)}</span>, <span class="formula"><i>δ</i>(<i>p</i>, 1, <i>X</i>) = {(<i>p</i>, <i>ϵ</i>)}</span>, <span class="formula"><i>δ</i>(<i>p</i>, <i>ϵ</i>, <i>Z</i>) = {(<i>f</i>, <i>Z</i>)}</span>
</div>

</div>

</div>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-15">15</a> Equivalence of CFG’s and PDA’s<a class="Label" name="sec:equivalenceCFGPDA"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-15.1">15.1</a> Converting CFG’s <span class="formula"> ⇒ </span> PDA’s<a class="Label" name="subsec:Converting-CFG's-"> </a>
</h2>
<div class="Unindented">
For some grammar <span class="formula"><i>G</i></span>, let the language <span class="formula"><i>L</i> = <i>L</i>(<i>G</i>).</span> We construct the PDA P such that upon emptying the stack we obtain a string in the language <span class="formula"><i>L</i></span> (i.e. <span class="formula"><i>N</i>(<i>P</i>) = <i>L</i></span>). P has one state <span class="formula"><i>q</i>.</span> The terminals of the grammar G become the input symbols <span class="formula">Σ</span> of the PDA <span class="formula"><i>P</i></span>. The variables and terminals of G make up the stack symbols <span class="formula">Γ</span> of the <span class="formula"><i>P</i></span>. The start symbol of <span class="formula"><i>G</i></span> becomes the start symbol of <span class="formula"><i>P</i>.</span> Intuitively, we must model the left sentential form of a grammar with the PDA. If the stack of the PDA <span class="formula"><i>P</i></span> is <span class="formula"><i>a</i>, </span> and <span class="formula"><i>P</i></span>has so far consumed <span class="formula"><i>x</i></span>from its input, then <span class="formula"><i>P</i></span> represents the left-sentential form <span class="formula"><i>xa</i></span>. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-15.1.1">15.1.1</a> Creating the Transition Function<a class="Label" name="subsec:creatingTheTransitionFunction"> </a>
</h3>
<div class="Unindented">
There are two kinds of rules in the transition function of P, depending on whether a terminal or variable of G is at the top of P’s stack. The <i>type-1</i> rules handle the case where “a” is the terminal on top of P’s stack (<span class="formula"><i>δ</i>(<i>q</i>, <i>a</i>, <i>a</i>) = (<i>q</i>, <i>ϵ</i>))</span>. There better be an “a” as the next input symbol, or P has guessed wrongly about the leftmost derivation of the input as it actually exists. In effect, we “cancel” the “a” on the stack against the “a” on the input. The left-sentential form represented does not change. We have now consumed one more symbol, “a”, from the input so that becomes part of the left-sentential form. But the “a” that was on the stack is removed, so it no longer participates in the left-sentential form. The <i>type-2</i> rules handle a variable, say <span class="formula"><i>A</i></span>, on the top of the stack (<span class="formula"><i>δ</i>(<i>q</i>, <i>ϵ</i>, <i>A</i>) = (<i>q</i>, <i>a</i>))</span>. We need to expand that variable by the body of one of its productions, and thus move to the next left-sentential form. Of course we’re only guessing. We have to allow any of <span class="formula"><i>A</i>’<i>s</i></span> productions to be used. If <span class="formula"><i>A</i> → <i>a</i></span> is one of these productions, then a choice for <span class="formula"><i>P</i></span>, using epsilon input, and with <span class="formula"><i>A</i></span> on top of the stack, is to replace the <span class="formula"><i>A</i></span> by <span class="formula"><i>a</i></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-15.1.2">15.1.2</a> Proof of Equivalence between CFG and PDA<a class="Label" name="subsec:proofEquivalenceCFGPDA"> </a>
</h3>
<div class="Unindented">
In order to prove equivalence between the two representations we need to prove that for all <span class="formula"><i>x</i>, </span><span class="formula">(<i>q</i>, <i>wx</i>, <i>S</i>)⊢<sup>*</sup>(<i>q</i>, <i>x</i>, <i>α</i>)↔<i>S</i> ⇒ <span class="scripts"><sup class="script">*</sup><sub class="script"><i>lm</i></sub></span><i>w</i><i>α</i></span>. That is, for all x the instantaneous description <span class="formula">(<i>q</i>, <i>wx</i>, <i>S</i>)</span> goes to <span class="formula">(<i>q</i>, <i>x</i>, <i>α</i>)</span> in some number of steps of the PDA if and only if the CFG’s leftmost derivation yields <span class="formula"><i>w</i><i>α</i></span>. It is important to note that we allow for the suffix <span class="formula"><i>x</i></span>in the string <span class="formula"><i>wx</i></span>. The string <span class="formula"><i>x</i></span> has no effect on the process of consuming <span class="formula"><i>w</i></span> and so if the that statement is true for one <span class="formula"><i>x</i></span>it is true for all <span class="formula"><i>x</i>.</span> The proof follow starting from the only if direction <span class="formula">( → )</span>. That is, if P transitions <span class="formula">(<i>q</i>, <i>wx</i>, <i>S</i>)</span> goes to <span class="formula">(<i>q</i>, <i>x</i>, <i>α</i>)</span>, then <span class="formula"><i>S</i> ⇒ <span class="scripts"><sup class="script">*</sup><sub class="script"><i>lm</i></sub></span><i>w</i><i>α</i></span>. This will be an inductive proof where the base case is 0 steps have taken place and <span class="formula"><i>w</i></span> is <span class="formula"><i>ϵ</i></span> and <span class="formula"><i>α</i></span>is <span class="formula"><i>S</i></span>. The truth of the base case becomes trivial because <span class="formula"><i>S</i></span> is <span class="formula"><i>α</i></span> and <span class="formula"><i>w</i><i>α</i></span> is just <span class="formula"><i>α</i></span> because <span class="formula"><i>ϵ</i></span> serves as the identity of concatenation. Surely then, <span class="formula"><i>S</i></span> derives itself. Now we must consider the next <span class="formula"><i>n</i></span> steps of the proof, and assume an inductive hypothesis for the sequence of <span class="formula"><i>n</i> − 1</span> steps. For the <span class="formula"><i>n</i><sup><i>th</i></sup></span> step two cases can occur. A type-1 rule is used, or a type 2 rule is used. We will consider both case in turn. The descriptions of these rules are described in the previous subsection. For the use of a <i>type-1 </i>rule in the <span class="formula"><i>n</i><sup><i>th</i></sup></span> step, the ID’s for the 0 through <span class="formula"><i>n</i> − 1</span> steps must be <span class="formula">(<i>q</i>, <i>yax</i>, <i>S</i>)⊢<sup>*</sup>(<i>q</i>, <i>ax</i>, <i>a</i><i>α</i>)⊢(<i>q</i>, <i>x</i>, <i>α</i>)</span>, where <span class="formula"><i>ya</i> = <i>w</i></span>. That is, the prefix of the string <span class="formula"><i>x</i></span>must end with the symbol <span class="formula"><i>a</i></span> with the <span class="formula"><i>a</i></span> symbol on top of the stack followed by <span class="formula"><i>α</i></span>, and in the previous <span class="formula"><i>n</i> − 1</span> steps the string <span class="formula"><i>y</i></span> is consumed by the PDA, and in the <span class="formula"><i>n</i><sup><i>th</i></sup></span> step the PDA consumes the input symbol <span class="formula"><i>a</i></span> and removes it from the stack. By the inductive hypothesis applied to the <span class="formula"><i>n</i> − 1</span> steps, we can conclude that there is a left most derivation from <span class="formula"><i>S</i></span> to <span class="formula"><i>ya</i><i>α</i></span> because y was consumed and thus equivalent to <span class="formula"><i>ϵ</i></span>and <span class="formula"><i>a</i><i>α</i></span> is on the stack. The symbol <span class="formula"><i>a</i></span>is then consumed from the input and popped from stack taking us back to the base case because <span class="formula"><i>ya</i> = <i>w</i></span>. For the use of a <i>type-2 </i>rule in the <span class="formula"><i>n</i><sup><i>th</i></sup></span> step, the step sequence must be <span class="formula">(<i>q</i>, <i>wx</i>, <i>S</i>)⊢<sup>*</sup>(<i>q</i>, <i>x</i>, <i>A</i><i>β</i>)⊢(<i>q</i>, <i>x</i>, <i>γ</i><i>β</i>)</span> where <span class="formula"><i>A</i> → <i>γ</i></span> is a production in the grammar and <span class="formula"><i>α</i> = <i>γ</i><i>β</i></span>. In this case, we have a variable <span class="formula"><i>A</i></span> on top of the stack followed by the stack string <span class="formula"><i>β</i></span>. In the <span class="formula"><i>n</i><sup><i>th</i></sup></span> step no input is consumed but the variable <span class="formula"><i>A</i></span> is replaced by the stack string <span class="formula"><i>γ</i></span>. By the inductive hypothesis we obtain <span class="formula"><i>S</i> ⇒ <span class="scripts"><sup class="script">*</sup><sub class="script"><i>lm</i></sub></span><i>wA</i><i>β</i></span> after the first <span class="formula"><i>n</i> − 1</span> steps. Because <span class="formula"><i>A</i></span> is the leftmost variable in the derivation it is replaced by <span class="formula"><i>γ</i></span>. We then have <span class="formula"><i>S</i> ⇒ <span class="scripts"><sup class="script">*</sup><sub class="script"><i>lm</i></sub></span><i>w</i><i>γ</i><i>β</i> = <i>w</i><i>α</i></span> returning us to our base case, thus proving the only if direction of the proof. Next, we prove the if direction (<span class="formula"> ← )</span>. We now must prove <span class="formula"><i>S</i> ⇒ <span class="scripts"><sup class="script">*</sup><sub class="script"><i>lm</i></sub></span><i>w</i><i>α</i> → (<i>q</i>, <i>wx</i>, <i>S</i>)⊢<sup>*</sup>(<i>q</i>, <i>x</i>, <i>α</i>)</span> for all <span class="formula"><i>x</i></span> <span class="formula">…</span>[omitted]
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-15.2">15.2</a> Converting PDA’s <span class="formula"> ⇒ </span> CFG’s<a class="Label" name="subsec:convertingPDA2CFG"> </a>
</h2>
<div class="Unindented">
In this section we obtain the grammar <span class="formula"><i>G</i></span> from a PDA <span class="formula"><i>P</i></span>. We assume that the language <span class="formula"><i>L</i></span> is accepted by the PDA upon emptying its stack, more formally <span class="formula"><i>L</i> = <i>N</i>(<i>P</i>).</span> Intuitively, we should assign variables labeled as <span class="formula"><i>pXq</i></span> to the grammar <span class="formula"><i>G</i></span> for the transitions from state <span class="formula"><i>p</i></span>to state <span class="formula"><i>q</i></span>when popping the symbol <span class="formula"><i>X</i></span> from the PDA’s stack. Upon popping the <span class="formula"><i>X</i></span> from the stack it may grow, but the stack size will not shrink below the size when <span class="formula"><i>X</i></span> was popped off the stack until the last step in processing is taken.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-15.2.1">15.2.1</a> Constructing Variables of the CFG<a class="Label" name="subsec:constructingVariablesOfCFG"> </a>
</h3>
<div class="Unindented">
The variables of <span class="formula"><i>G</i></span> are correspond to labels such as <span class="formula"><i>pXq</i></span> which can be viewed as a single symbol modeling the transition from p to q with X on the stack in which the input is consumed and generates all and only the strings <span class="formula"><i>w</i></span> until <span class="formula"><span class="symbol">(</span><i>p</i>, <i>w</i>, <i>X</i><span class="symbol">)</span>⊢<sup>*</sup>(<i>q</i>, <i>ϵ</i>, <i>ϵ</i>)</span>. Note that since the initial ID shows nothing below <span class="formula"><i>X</i></span> on the stack, we know that <span class="formula"><i>X</i></span> can’t be popped until the last step, since PDA P cannot make any moves when its stack is empty.In addition to the aforementioned variable a start symbol <span class="formula"><i>S</i></span> is needed.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-15.2.2">15.2.2</a> Constructing Productions of the CFG<a class="Label" name="subsec:constructingProductionsOfCFG"> </a>
</h3>
<div class="Unindented">
Intuitively, the productions or rules of the grammar represent steps of the PDA. Each rule for the example rule <span class="formula"><i>pXq</i></span> is sourced from the PDA in state <span class="formula"><i>p</i></span>with the stack symbol <span class="formula"><i>X</i></span>. In the easiest case we have the following for the PDA’s transition function. <span class="formula"><i>δ</i>(<i>p</i>, <i>a</i>, <i>X</i>)</span> yields <span class="formula">(<i>p</i>, <i>ϵ</i>)</span>. Here <span class="formula"><i>a</i></span> denotes either a input symbol or <span class="formula"><i>ϵ</i></span>. The grammar in this case can model the PDA’s behavior by popping <span class="formula"><i>X</i></span>and not replacing it with any other symbol <span class="formula">(<i>pXq</i> → <i>a</i>)</span>. The next simplest case simplest case involves modeling transition between productions. Transitivy is modeled by introducing an intermediate state <span class="formula"><i>r</i></span>and a variable <span class="formula"><i>Y</i></span>. The transition function in this case would look like <span class="formula"><i>δ</i>(<i>p</i>, <i>a</i>, <i>X</i>)</span> yields <span class="formula">(<i>r</i>, <i>Y</i>)</span>. The corresponding production would then be <span class="formula"><i>pXq</i> → <i>arYq</i></span>. This allows us to erase X and transition from <span class="formula"><i>p</i></span> to <span class="formula"><i>q</i></span> by way of <span class="formula"><i>r</i></span> while reading <span class="formula"><i>a</i></span>and pushing <span class="formula"><i>Y</i></span> onto the stack. The final simplest case we will consider is <span class="formula"><i>δ</i>(<i>p</i>, <i>a</i>, <i>X</i>)</span> yields <span class="formula">(<i>r</i>, <i>YZ</i>)</span> for some state <span class="formula"><i>r</i></span> and some symbols <span class="formula"><i>Y</i></span>and <span class="formula"><i>Z</i></span>. Here <span class="formula"><i>X</i></span> is replaced by <span class="formula"><i>YZ</i></span>. In order for <span class="formula"><i>X</i></span> to be erased, there must be some input string u that has the net effect of erasing <span class="formula"><i>Y</i></span>. And <span class="formula"><i>u</i></span> must take the PDA from state <span class="formula"><i>r</i></span> to some state <span class="formula"><i>s</i></span>, which we don’t know. As a result, we’re going to have to have one production for each state <span class="formula"><i>s</i></span>. But after reaching state <span class="formula"><i>s</i></span>, we must have some additional input <span class="formula"><i>v</i></span> that takes the PDA from state <span class="formula"><i>s</i></span> to state <span class="formula"><i>q</i></span>, while popping the <span class="formula"><i>Z</i></span> from the stack. The net effect is that<span class="formula"><i>auv</i></span> pops <span class="formula"><i>X</i></span> from the stack while going from state <span class="formula"><i>p</i></span> to <span class="formula"><i>q</i>.</span> The general case for creating productions to model the PDA follows. Suppose <span class="formula"><i>δ</i>(<i>p</i>, <i>a</i>, <i>X</i>)</span> yields <span class="formula">(<i>r</i>, <i>Y</i><sub>1</sub>, …<i>Y</i><sub><i>k</i></sub>)</span> for some state <span class="formula"><i>r</i></span> and <span class="formula"><i>k</i> ≥ 3.</span> Then in the grammar generate the set of productions <span class="formula"><i>pXq</i> → <i>arY</i><sub>1</sub><i>s</i><sub>1</sub><i>s</i><sub>1</sub><i>Y</i><sub>2</sub><i>s</i><sub>2</sub>…<i>s</i><sub><i>k</i> − 2</sub><i>Y</i><sub><i>k</i> − 1</sub><i>s</i><sub><i>k</i> − 1</sub><i>s</i><sub><i>k</i> − 1</sub><i>Y</i><sub><i>k</i></sub><i>q</i></span>. This models the case in which <span class="formula"><i>X</i></span> is replaced by three or more symbols transitioning from <span class="formula"><i>p</i></span> to <span class="formula"><i>q</i>.</span>
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-16">16</a> Pumping Lemma for Context Free Languages<a class="Label" name="sec:pumpingLemmaForContextFreeLanguages"> </a>
</h1>
<div class="Unindented">
Recall the concepts for the pumping lemma on regular languages outlined in Section<a class="Reference" href="#sec:pumpingLemmaRegularLanguages">12 on page 1↑</a>. The pumping lemma for regular languages relied on a cycle early on in a sufficiently long string <span class="formula"><i>w</i></span> in order &ldquo;pump&rdquo; an the string an arbitrary number of times, thus producing a infinite number of strings in the language. Similarly, the pumping lemma for context free languages models this idea, but requires two cycles along the string’s path in tandem. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-16.1">16.1</a> Formal Specification of the CFL Pumping Lemma<a class="Label" name="subsec:formalSpecificationOfContextFreeLanguages"> </a>
</h2>
<div class="Unindented">
For every context free language <span class="formula"><i>L</i></span>, there is an integer <span class="formula"><i>n</i></span>, such that for every string <span class="formula"><i>z</i></span> in <span class="formula"><i>L</i></span> of length <span class="formula"> ≥ <i>n</i></span> there exists <span class="formula"><i>z</i> = <i>uvwxy</i></span> such that the following conditions hold:
</div>
<ol>
<li>
<span class="formula">|<i>vwx</i>| ≤ <i>n</i>.</span>
</li>
<li>
<span class="formula">|<i>vx</i>| &gt; 0.</span>
</li>
<li>
For all <span class="formula"><i>i</i> ≥ 0</span>, <span class="formula"><i>uv</i><sup><i>i</i></sup><i>wx</i><sup><i>i</i></sup><i>y</i></span> is in <span class="formula"><i>L</i>.</span>
</li>

</ol>
<div class="Unindented">
If a language in question does not have these properties, then it is not a context free language.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-17">17</a> Properties of Context Free Languages<a class="Label" name="sec:propertiesOfContextFreeLanguages"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-17.1">17.1</a> Decision Properties of Context Free Languages<a class="Label" name="subsec:decisionPropertiesOfContextFreeLanguages"> </a>
</h2>
<div class="Unindented">
Like regular languages we can determine many decision properties about context free languages including whether a string in the particular CFL, whether a CFL contains any strings at all, and if the CFL contains an infinite number of strings. Unfortunately,we cannot decide whether two CFL’s are equivalent, or whether they are disjoint.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.1.1">17.1.1</a> Membership Test for CFL’s<a class="Label" name="subsec:membershipTestForCFL"> </a>
</h3>
<div class="Unindented">
The membership test is used to determine whether a given string <span class="formula"><i>w</i></span> is the language of the grammar <span class="formula"><i>L</i>(<i>G</i>).</span> We need the grammar to be in Chomsky Normal Form, so if it isn’t then convert it to this form as described in subsection<a class="Reference" href="#subsec:representingGrammarsInChomskyNormalForm">13.5.4 on page 1↑</a>. Then use the CYK algorithm to determine the status of <span class="formula"><i>w</i>.</span> The CYK algorithm uses Dynamic Programming to decide whether <span class="formula"><i>w</i></span> is in the language or not, so it may be useful to first review the section<a class="Reference" href="#sec:Dynamic-Programming">30 on page 1↓</a> first in order to gain better understanding of CYK.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.1.2">17.1.2</a> The CYK Algorithm
</h3>
<div class="Unindented">
<div class="left">
Let <span class="formula"><i>w</i> = <i>a</i><sub>0</sub>…<i>a</i><sub><i>n</i></sub></span> be a string of length <span class="formula"><i>n</i></span>where <span class="formula"><i>a</i><sub><i>i</i></sub></span> stores the symbol at the <span class="formula"><i>i</i><sup><i>th</i></sup></span> position. Construct a <span class="formula"><i>n</i></span> by <span class="formula"><i>n</i></span> triangular array. This can done efficiently by using an indexing function where upon a single-indexed array is mapped to an upper-triangular array. The following function <span class="formula"><i>k</i> = <i>j</i>(<i>j</i> + 1) ⁄ 2 + <i>i</i></span> where <span class="formula"><i>k</i></span> represents the index into the array properly maps the elements of the array. This idea can be viewed in Figure<a class="Reference" href="#fig:triangularArray">21 on page 1↓</a>. Additionally, each entry of the array should be viewed as a set of variables of the grammar. The set <span class="formula"><i>X</i><sub><i>ij</i></sub></span> is stored in position <span class="formula">(<i>i</i>, <i>j</i>)</span> of the array where <span class="formula"><i>i</i> ≤ <i>j</i></span> and is intended to be the set of variables that derive the substring of the input starting from position <span class="formula"><i>i</i></span> and ending at position <span class="formula"><i>j</i></span>. An inductive argument is used to fill the table on the length of the input string derived . The length of the string can be computed as <span class="formula"><i>j</i> − <i>i</i> + 1</span>. We start by computing the entries <span class="formula"><i>X</i><sub><i>i</i>, <i>i</i></sub></span>, which is the set of variables that derive the string consisting of the symbol at <span class="formula"><i>a</i><sub><i>i</i></sub></span> . Next, we find the variables at <span class="formula"><i>X</i><sub><i>i</i>, <i>i</i> + 1</sub></span> each of which derive the string at <span class="formula"><i>a</i><sub><i>i</i>, <i>i</i> + 1</sub></span>. Then, we move to the <span class="formula"><i>X</i><sub><i>i</i>, <i>i</i> + 2</sub></span> variables which are the sets of variables that derive the strings of length three, <span class="formula"><i>a</i><sub><i>i</i></sub>, </span><span class="formula"><i>a</i><sub><i>i</i> + 1</sub>, </span><span class="formula"><i>a</i><sub><i>i</i> + 2</sub></span> and so on . Finally, after we have computed the set <span class="formula"><i>X</i><sub>1, <i>n</i></sub></span> which represents the entire input string , we can test whether the start symbol <span class="formula"><i>S</i></span> is contained in the set . If it is then the string is in the language, otherwise it is not. Formally, the basis <span class="formula"><i>X</i><sub><i>i</i>, <i>i</i></sub> = {<i>A</i>|<i>A</i> ⇒ <sup>*</sup><i>a</i><sub><i>i</i></sub>}</span> where <span class="formula"><i>a</i><sub><i>i</i></sub></span> represents a single symbol in <span class="formula"><i>w</i></span>. The induction is then <span class="formula"><i>X</i><sub><i>i</i>, <i>j</i></sub></span>={A| there is a production <span class="formula"><i>A</i> → <i>BC</i></span>, and an integer <span class="formula"><i>k</i></span>, with <span class="formula"><i>i</i> ≤ <i>k</i> &lt; <i>j</i></span>, such that <span class="formula"><i>B</i></span> is in <span class="formula"><i>X</i><sub><i>i</i>, <i>k</i></sub></span> and <span class="formula"><i>C</i></span> is in <span class="formula"><i>X</i><sub><i>k</i> + 1, <i>j</i></sub></span>}.That is, for each <span class="formula"><i>k</i></span> between <span class="formula"><i>i</i></span> and <span class="formula"><i>j</i> − 1</span> we look for some <span class="formula"><i>B</i></span> in <span class="formula"><i>X</i><sub><i>i</i>, <i>k</i></sub></span> and some <span class="formula"><i>C</i></span> in <span class="formula"><i>X</i><sub><i>k</i> + 1, <i>j</i></sub></span> such that <span class="formula"><i>BC</i></span> is the body of an <span class="formula"><i>A</i></span> production. If for any <span class="formula"><i>k</i></span>, <span class="formula"><i>B</i></span>, and <span class="formula"><i>C</i></span> we find such a production, we add <span class="formula"><i>A</i></span> to <span class="formula"><i>X</i><sub><i>i</i>, <i>j</i></sub></span>. <div class="float">
<a class="Label" name="fig:triangularArray"> </a><div class="figure">
<div class="PlainVisible">
<div class="center">
<table>
<tr>
<td align="decimal" valign="top">
0
</td>
<td align="decimal" valign="top">
1
</td>
<td align="decimal" valign="top">
3
</td>
<td align="decimal" valign="top">
6
</td>

</tr>
<tr>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">
2
</td>
<td align="decimal" valign="top">
4
</td>
<td align="decimal" valign="top">
7
</td>

</tr>
<tr>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">
5
</td>
<td align="decimal" valign="top">
8
</td>

</tr>
<tr>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">

</td>
<td align="decimal" valign="top">
9
</td>

</tr>

</table>

</div>
<br/>
<div class="center">
<div class="caption">
Figure 21 A single index array can be viewed as a triangular array by accessing it with a function mapping the rows and columns appropriately. The function <span class="formula"><i>k</i> = <i>j</i>(<i>j</i> + 1) ⁄ 2 + <i>i</i></span> maps the index value <span class="formula"><i>k</i></span> to the appropriate <span class="formula"><i>i</i></span> and column <span class="formula"><i>j</i></span> where <span class="formula"><i>i</i> ≤ <i>j</i></span>.
</div>

</div>

</div>

</div>

</div>

</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.1.3">17.1.3</a> Emptiness Test for CFL’s<a class="Label" name="subsec:emptinessTestForCFL"> </a>
</h3>
<div class="Unindented">
The algorithm to test for an empty CFL uses the ideas we learned in subsection<a class="Reference" href="#subsec:eliminatingUselessVariables">13.5.1 on page 1↑</a>. We use these ideas of checking whether variables are useful in the derivation to determine if the start symbol <span class="formula"><i>S</i></span> is a useful symbol. If the start symbol does not derive anything, it is a useless variable, and we can state that the CFL is empty. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.1.4">17.1.4</a> Infiniteness Test for CFL’s<a class="Label" name="subsec:infinitenessTestCFL"> </a>
</h3>
<div class="Unindented">
The test for infinteness in CFL mirrors the idea that was proposed in section<a class="Reference" href="#subsec:infinitenessTestRegularLanguages">9.1.4 on page 1↑</a>. Apply those principles with the pumping lemma for context free languages outlined in section<a class="Reference" href="#sec:pumpingLemmaForContextFreeLanguages">16 on page 1↑</a>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-17.2">17.2</a> Closure Properties of Context Free Languages<a class="Label" name="subsec:closurePropertiesOfContextFreeLanguages"> </a>
</h2>
<div class="Unindented">
For many of the same operations under which the class of regular languages are closed, the context-free languages are also closed. These include the regular-expression operations: union, concatenation, and closure. Also reversal, homomorphism and inverse homomorphism. But unlike the class of regular languages, the class of context-free languages is not closed under intersection or difference. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.2.1">17.2.1</a> Union for CFL’s<a class="Label" name="subsec:unionForCFL's"> </a>
</h3>
<div class="Unindented">
//TODO
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.2.2">17.2.2</a> Concatenation for CFL’s<a class="Label" name="subsec:concatentationForCFL's"> </a>
</h3>
<div class="Unindented">
//TODO
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-17.2.3">17.2.3</a> Kleene Closure for CFL’s<a class="Label" name="subsec:kleeneClosureForCFL's"> </a>
</h3>
<div class="Unindented">
//TODO
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-18">18</a> Countability<a class="Label" name="sec:Countability"> </a>
</h1>
<div class="Unindented">
It is important to understand that all computation can be encoded as integers. The ASCII or if you like the UTF-8 table encodes English characters and algebraic numerals, which we can interpret as integers. This idea can be applied to all types of media. At the very root we may interpret all things as integers.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-18.1">18.1</a> Finite Sets
</h2>
<div class="Unindented">
A finite set is a set that contains a finite number of elements. Refer to Section<a class="Reference" href="#sec:Sets">1.5 on page 1↑</a>. It may be useful to refresh your memory on this topic. The formal definition of a finite set is one for which it is impossible to find a one to one correspondence between the members of the set and a proper subset of the set. An example of a set is <span class="formula">{<i>a</i>, <i>b</i>, <i>c</i>}.</span>
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-18.2">18.2</a> Infinite Sets
</h2>
<div class="Unindented">
An infinite set is a set for which there is a one to one correspondence between itself and a proper subset of itself. An example of a infinite set is the positive integers <span class="formula">{1, 2, 3, …}.</span> The one-to-one correspondence which validates this argument is the mapping of the positive integers with the even integers ( <span class="formula">1↔2, 2↔4, 3↔6, …)</span>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-18.3">18.3</a> Countable Sets
</h2>
<div class="Unindented">
A countable set is a set with a one to one correspondence with the positive integers, thus all countable sets are infinite sets. As another example all integers <span class="formula">ℤ</span> form a countable set. 0 is mapped to 1 and the negative integers are are mapped to the even numbers (<span class="formula"> − <i>i</i>↔2<i>i</i></span>, for all <span class="formula"><i>i</i> ≥ 1</span>), while the positive integers are mapped to odd numbers<span class="formula">(<i>i</i>↔2<i>i</i> + 1</span>, for all <span class="formula"><i>i</i> ≥ 1</span>). The enumerated sequence then becomes <span class="formula">0,  − 1, 1,  − 2, 2,  − 3, 3, …</span> Another example of an enumerable set is the binary strings, but there is a trick involved. The binary strings <span class="formula">101, 0101, 00101</span> all correspond to the integer value 5, so it seems impossible to form a correspondence such that they become countable. The trick here is to prepend a 1 to the binary strings so that the strings can become distinguishable. The aforementioned strings become <span class="formula">1101, 10101, 100101</span> as integers they are 13, 21, and 37.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-18.4">18.4</a> Countability of Languages Over the Binary Alphabet
</h2>
<div class="Unindented">
The next bit is quite confusing (pun intended). The languages over the binary alphabet <span class="formula">Σ = {0, 1}</span> are not countable. To obtain a contradiction we use a technique that confounds a set formers specification. As with the other examples suppose we could encode languages over the binary alphabet so that we could speak about some specific enumerated language. For example, the <span class="formula"><i>i</i><sup><i>th</i></sup></span> language. Define the language <span class="formula"><i>L</i></span> = { w | w is the <span class="formula"><i>i</i><sup><i>th</i></sup></span> binary string and <span class="formula"><i>w</i></span> is not in the <span class="formula"><i>i</i><sup><i>th</i></sup></span> language}. Surely, the language <span class="formula"><i>L</i></span> is a language over the binary alphabet. Thus, <span class="formula"><i>L</i></span> is the <span class="formula"><i>j</i><sup><i>th</i></sup></span> language for some particular <span class="formula"><i>j</i>.</span> Now let some binary string <span class="formula"><i>x</i></span>be the <span class="formula"><i>j</i><sup><i>th</i></sup></span> string. Now consider substituting <span class="formula"><i>x</i></span>for <span class="formula"><i>w</i></span> in the <span class="formula"><i>j</i><sup><i>th</i></sup></span> language <span class="formula"><i>L</i><sub><i>j</i></sub></span> = { <span class="formula"><i>x</i></span> | <span class="formula"><i>x</i></span>is the <span class="formula"><i>j</i><sup><i>th</i></sup></span> binary string and <span class="formula"><i>x</i></span>is not in the <span class="formula"><i>j</i><sup><i>th</i></sup></span> language}. For some arbitrary <span class="formula"><i>j</i><sup><i>th</i></sup></span> string <span class="formula"><i>x</i></span>in the <span class="formula"><i>j</i><sup><i>th</i></sup></span> language <span class="formula"><i>L</i><sub><i>j</i></sub></span>, if <span class="formula"><i>x</i></span>is in <span class="formula"><i>L</i><sub><i>j</i></sub></span>, then it cannot be by the definition of the language. If <span class="formula"><i>x</i></span>is not in the language <span class="formula"><i>L</i><sub><i>j</i></sub></span>, then <span class="formula"><i>x</i></span>is in the language by the definition of the language. This makes for a very confusing situation. Remember, <span class="formula"><i>L</i></span> contains <span class="formula"><i>w</i></span> if and only if <span class="formula"><i>w</i></span> is not the language that corresponds to the same integer <span class="formula"><i>i</i></span> that <span class="formula"><i>w</i></span> corresponds to. We now have a contradiction and therefore we know that we know the languages over the binary strings are not countable. Graphically, this concept can be seen in the Diagonalization Method in Figure<a class="Reference" href="#fig:diagonalization">22 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:diagonalization"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top" colspan="6">
Strings
</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
2
</td>
<td align="center" valign="top">
3
</td>
<td align="center" valign="top">
4
</td>
<td align="center" valign="top">
5
</td>
<td align="center" valign="top">
<span class="formula">…</span>
</td>

</tr>
<tr>
<td align="center" valign="top">
Languages
</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
0
</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
0
</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
2
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
3
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
0
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
4
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula">⋱</span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
5
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula">⋮</span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>

</table>

</div>
<div class="caption">
Figure 22  This diagram depicts a table used to describe whether strings are in a language or not. A binary integer 1 indicates that the string <span class="formula"><i>j</i><sup><i>th</i></sup></span> string is in the <span class="formula"><i>i</i><sup><i>th</i></sup></span> language, 0 indicates it is not in the language. Look at the diagonal in this table. If you were to first complement the main diagonal and then rotate it by 45 degrees upon an axis created in the <span class="formula"><i>i</i><sup><i>th</i></sup></span> row and <span class="formula"><i>i</i><sup><i>th</i></sup></span> column, then it too would look like a language, but would always disagree with itself at the <span class="formula"><i>i</i><sup><i>th</i></sup></span> row and <span class="formula"><i>i</i><sup><i>th</i></sup></span> column.
</div>

</div>

</div>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-19">19</a> Turing Machines<a class="Label" name="sec:Turing-Machines"> </a>
</h1>
<div class="Unindented">
Turing machines model the recursively enumerable languages which encompass the previously discussed languages. Sipser provides a good hierarchy to reference for how to regard which language classes are subsets of which. The diagram is provided in Figure<a class="Reference" href="#fig:languageClassHierarchy">23↓</a>. The purpose of Turing Machine theory is to provide a means of proving whether or not an algorithm exists for a given language.Reductions which will be explored in detail in later sections prove common questions are undecidable. 
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:languageClassHierarchy"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/LanguageClassHierarchy.png" alt="figure Diagrams/LanguageClassHierarchy.png" style="width: 235px; max-width: 470px; height: 149px; max-height: 299px;"/>

</div>
<div class="caption">
Figure 23  The hierarchy of language classes. Turing-recognizable languages are sometimes called recursively enumerable languages. Decidable languages are sometimes called recursive languages.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.1">19.1</a> What is a Turing Machine?
</h2>
<div class="Unindented">
A Turing Machine is a computational model composed of a tape and a head that reads and writes symbols onto the tape based on a transition function. The tape is infinite in both directions, and there is also some state that we track throughout computation. In one step of computation the Turing machine may read one symbol from the tape and modify it, and either move the head left or right one square.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.2">19.2</a> Turing Machine Notation
</h2>
<div class="Unindented">
A Turing machine is made up of the following components.
</div>
<ul>
<li>
A finite set of states (<span class="formula"><i>Q</i>).</span>
</li>
<li>
An input alphabet <span class="formula">(Σ).</span>
</li>
<li>
A tape alphabet <span class="formula">(Γ, </span>typically <span class="formula">Σ ⊆ Γ)</span>.
</li>
<li>
A transition function (<span class="formula"><i>δ</i></span>).
</li>
<li>
A start state (<span class="formula"><i>q</i><sub>0</sub><i>ε</i><i>Q</i>)</span>.
</li>
<li>
A blank symbol (<span class="formula">⊔ ⊆ Γ − Σ).</span>
</li>
<li>
A set of final states (<span class="formula"><i>F</i> ⊆ <i>Q</i>)</span>.
</li>

</ul>
<div class="Unindented">
Conventionally, the lowercase letters at the beginning of the alphabet are input symbols (<span class="formula"><i>a</i>, <i>b</i>, <i>c</i>).</span> Upper case letters at the end of the alphabet represent tape symbols <span class="formula">(<i>X</i>, <i>Y</i>, <i>Z</i>)</span>. Lowercase letters at the end of the alphabet represent input strings <span class="formula"><i>w</i>, <i>x</i>, <i>y</i>, <i>z</i></span>. Greek symbols represent tape symbols <span class="formula">(<i>α</i>, <i>β</i>, <i>γ</i>)</span>. The transition function <span class="formula"><i>δ</i></span> takes two parameters a <span class="formula"><i>q</i><sub><i>i</i></sub><i>ε</i><i>Q</i></span> and a tape symbol in <span class="formula">Γ</span>. The transition function yields a triple of the form (state, tape symbol, direction). If for a given input a transition is not defined then the Turing machine halts in the current state.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.3">19.3</a> Instantaneous Descriptions of Turing Machines
</h2>
<div class="Unindented">
Instantaneous descriptions of Turing Machines are encoded as <span class="formula"><i>α</i><i>q</i><sub><i>i</i></sub><i>β</i></span> where <span class="formula"><i>α</i></span> represents the tape before the head of the Turing Machine until the leftmost blank and <span class="formula"><i>β</i></span> represents the tape after the head until the rightmost blank. The position of the head represented by a state symbol <span class="formula"><i>q</i><sub><i>i</i></sub></span> is just left of the tape string <span class="formula"><i>β</i></span>. Further we use the symbol <span class="formula">⊢</span> to indicate &ldquo;becomes in one move&rdquo; and <span class="formula">⊢<sup>*</sup></span> as &ldquo;becomes in zero or more moves.&rdquo; 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.4">19.4</a> Languages of a Turing Machine
</h2>
<div class="Unindented">
A Turing machine’s language is defined by its final states or a halting action. An example is <span class="formula"><i>L</i>(<i>M</i>)</span> = { <span class="formula"><i>w</i></span> | <span class="formula"><i>q</i><sub>0</sub><i>w</i>⊢<sup>*</sup><i>I</i></span> , where I is an ID with a final state}. Halting can be described by <span class="formula"><i>H</i>(<i>M</i>)</span> = {<span class="formula"><i>w</i></span> | <span class="formula"><i>q</i><sub>0</sub><i>w</i>⊢<sup>*</sup><i>I</i></span>, and there is no move possible from <span class="formula"><i>I</i>}.</span>
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.5">19.5</a> Recursively Enumerable Languages vs. Recursive Languages
</h2>
<div class="Unindented">
The class of languages accepted by a Turing Machine halting or entering an accepting state is called the Recursively Enumerable language class. Some textbooks also call this the Turing Recognizable language class. Turing Machines that accept by final state, and who are <i>guaranteed to halt</i> whether it accepts or not define the Recursive Languages class. In some textbooks this is called the Decidable Language class. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.6">19.6</a> Multi-tape Turing Machines
</h2>
<div class="Unindented">
Multi tape Turing Machines allow for a ordinary Turing Machine to have <span class="formula"><i>k</i></span> tapes for any fixed <span class="formula"><i>k</i>.</span> The steps the Multi tape Turing Machine makes are dependent on the symbols the head of each tape is pointing to and their corresponding states. Each tape has its own head and they move on their own tape without restricting each others movement. On each read of the tape a new symbol and state is assigned for each tape and head. Additionally, a head may choose to not move. This model is no more powerful than the traditional Turing Machine. One may simply expand the alphabet for a traditional Turing Machine to accommodate the number of tapes that it must simulate.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.7">19.7</a> Nondeterministic Turing Machines
</h2>
<div class="Unindented">
Nondeterministic Turing Machines are granted multiple choices based on the state, direction, move triple. Once a choice is made, then the next state, new symbol and head direction are determined. As with the NFA’s, DFA’s, and PDA’s, the nondeterministic Turing Machine accepts if any sequence of choices leads to an ID with and accepting state.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-19.8">19.8</a> Closure Properties of Recursive and Recursively Enumerable Languages
</h2>
<div class="Unindented">
Recursive Languages and Recursively Enumerable Languages share the properties: union, concatenation, Kleene star, reversal, intersection, and inverse. Recursive languages have difference and complementation. Recursively Enumerable Languages have homomorphism.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:closurePropertiesOfRELandRELanguages"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/ClosurePropertiesRELandRL.png" alt="figure Diagrams/ClosurePropertiesRELandRL.png" style="width: 194px; max-width: 388px; height: 134px; max-height: 268px;"/>

</div>
<div class="caption">
Figure 24 The closure properties of Recursive and Recursively Enumerable languages
</div>

</div>

</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.1">19.8.1</a> Union
</h3>
<div class="Unindented">
Given two Turing machines <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> with languages <span class="formula"><i>L</i><sub>1</sub></span>and <span class="formula"><i>L</i><sub>2</sub></span> respectively. The union of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> can be achieved by creating a third Turing Machine <span class="formula"><i>M</i></span>. <span class="formula"><i>M</i></span>will be a two-tape Turing Machine. <span class="formula"><i>M</i></span> will proceed by copying the tape of <span class="formula"><i>M</i><sub>1</sub></span> to its first tape, and <span class="formula"><i>M</i><sub>2</sub></span> to its second tape. Next, <span class="formula"><i>M</i></span> will simulate the input of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> independently. In the case of Recursive Languages (Decidable Languages), <span class="formula"><i>M</i></span>will <i>accept</i> when either of its tapes enter an accepting state, and <i>reject</i> when <b>both</b> of its tapes halt by not accepting. The case for Recursively Enumerable Languages is a bit more relaxed. In this case, <span class="formula"><i>M</i></span> need only to enter an accepting state on one of its tapes to accept. However, it may end up running forever and never providing an answer. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.2">19.8.2</a> Intersection
</h3>
<div class="Unindented">
The idea behind intersection is quite similiar to union. Given two Turing machines <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> with languages <span class="formula"><i>L</i><sub>1</sub></span>and <span class="formula"><i>L</i><sub>2</sub></span> respectively. The intersection of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> can be achieved by creating a third Turing Machine <span class="formula"><i>M</i></span>. <span class="formula"><i>M</i></span>will be a two-tape Turing Machine. <span class="formula"><i>M</i></span>will proceed by copying the tape of <span class="formula"><i>M</i><sub>1</sub></span> to its first tape, and <span class="formula"><i>M</i><sub>2</sub></span> to its second tape. Next, <span class="formula"><i>M</i></span> will simulate the input of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> independently. In the case of Recursive Languages (Decidable Languages), <span class="formula"><i>M</i></span>will <i>accept</i> when <b>both</b> of its tapes enter an accepting state, and <i>reject</i> when <b>either</b> of its tapes halt by not accepting. In the Recursively Enumerable case, <span class="formula"><i>M</i></span> has to enter an accepting state on <b>both</b> of its tapes to accept. However, it may end up running forever and never provide an answer. 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.3">19.8.3</a> Difference and Complement
</h3>
<div class="Unindented">
Again the idea behind Difference and Complement is quite similiar to the intersection. The intersection of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> can be achieved by creating a third Turing Machine <span class="formula"><i>M</i></span>. <span class="formula"><i>M</i></span> will be a two-tape Turing Machine. <span class="formula"><i>M</i></span> will proceed by copying the tape of <span class="formula"><i>M</i><sub>1</sub></span> to its first tape, and <span class="formula"><i>M</i><sub>2</sub></span> to its second tape. Next, <span class="formula"><i>M</i></span> will simulate the input of <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> independently. <span class="formula"><i>M</i></span> will <i>accept</i> when <b><span class="formula"><i>M</i><sub>1</sub></span> </b>accepts and <span class="formula"><i>M</i><sub>2</sub></span> rejects, otherwise reject. Corollary, for the complement run the difference algorithm over the Kleene star of the input alphabet. This approach won’t work for Recursively Enumerable Languages because <span class="formula"><i>M</i><sub>2</sub></span> may never halt.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.4">19.8.4</a> Concatenation
</h3>
<div class="Unindented">
Concatenation will require the use of a two-tape nondeterministic Turing Machine <span class="formula"><i>M</i></span>. Assume that the given machines <span class="formula"><i>M</i><sub>1</sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> are semi-inifinite single-tape Turing Machines. <span class="formula"><i>M</i></span> will proceed by nondetminitically guessing the where a given input string <span class="formula"><i>w</i></span> should be split. Call the prefix substring of <span class="formula"><i>w</i></span> the string <span class="formula"><i>x</i></span>, and call the corresponding suffix <span class="formula"><i>y</i></span>. Now copy <span class="formula"><i>x</i></span> onto <span class="formula"><i>M</i>’<i>s</i></span> first tape and <span class="formula"><i>y</i></span>onto its second tape. Now simulate <span class="formula"><i>M</i><sub>1</sub>’<i>s</i></span> transition function on the first tape and <span class="formula"><i>M</i><sub>2</sub>’<i>s</i></span> transtion function on the second tape. If both accept then <span class="formula"><i>M</i></span> should <i>accept</i>, otherwise <i>reject</i>. Because we nondeterministically guess all ways that <span class="formula"><i>w</i></span> can be split the machine will always accept if <span class="formula"><i>w</i></span> is in <span class="formula"><i>L</i>(<i>L</i>(<i>M</i><sub>1</sub>)<i>L</i>(<i>M</i><sub>2</sub>)).</span> 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.5">19.8.5</a> Kleene Star
</h3>
<div class="Unindented">
For the Kleene star mirror the technique of used concatenation but instead of splitting the input string. Generate the Kleene star of the given Turing Machine and for each component of the guessed set run it against the Turing Machine and if it accepts then accept, otherwise reject.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-19.8.6">19.8.6</a> Reversal
</h3>
<div class="Unindented">
Simply reverse the input and run it against the machine.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-20">20</a> Decidability<a class="Label" name="sec:Undeciability"> </a>
</h1>
<div class="Unindented">
Now that we have seen some algorithms in the preceeding section it is easy to see that one may create a great number of algorithms for Turing Machines. However, we will soon find out that for some problems no algorithm exists. We will link the concepts we learned in the Section<a class="Reference" href="#sec:Countability">18 on page 1↑</a> to formulate a way of encoding Turing Machines in binary. This will allow us to apply the Diagonalization technique to Turing Machines. We can then formalize the notion that a problem posed to a Turing Machine is in fact the language of the Turing Machine. We can then see that for some languages no Turing Machine can exist.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-20.1">20.1</a> Encoding Turing Machines in Binary
</h2>
<div class="Unindented">
It is quite simple to come up with a scheme for encoding Turing Machines into binary strings. We will assume the Turing Machines we will be encoding have a input alphate consisting of <span class="formula">{0, 1}.</span> However, this methodology is certainly exapandable to arbitrary alphabets. We should first assign integer values to the three classes of elements of the Turing Machine: states, symbols, and directions. Now we apply a trick for distinguishing codes of the binary string. For each integer representation of the componenet. Convert the integer to binary and insert a zero for each binary digit. Now there can never be consecutive ones in the binary representation. To distinguish between parts of the encoding add consecutive ones. Now we can concatenate the elements of the Turing machine together and prepend a 1 so that the encoding represents a unique integer value, and thus the language of all possible Turing Machines becomes enumerable. Some encodings may give invalid Turing Machines and therefore we regard theses as Turing Machines that accpet only the empty language.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:TuringMachineAcceptanceTable"> </a><div class="figure">
<div class="center">
<table>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top" colspan="9">
String j<span class="formula"> → </span>
</td>

</tr>
<tr>
<td align="center" valign="top">
TM i<span class="formula"> → </span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
2
</td>
<td align="center" valign="top">
3
</td>
<td align="center" valign="top">
4
</td>
<td align="center" valign="top">
5
</td>
<td align="center" valign="top">
6
</td>
<td align="center" valign="top" colspan="2">
<span class="formula">…</span>
</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
1
</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>1, 1</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
2
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>2, 2</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
3
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>3, 3</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
x
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
4
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>4, 4</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
5
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>5, 5</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
6
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula"><i>a</i><sub>6, 6</sub></span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula">⋮</span>
</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">
<span class="formula">⋱</span>
</td>
<td align="center" valign="top">

</td>

</tr>
<tr>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>
<td align="center" valign="top">

</td>

</tr>

</table>

</div>
<div class="caption">
Figure 25 This table expreses which strings <span class="formula"><i>j</i></span> are accepted by which Turing Machines <span class="formula"><i>i</i></span>. If <span class="formula"><i>x</i></span>is 0 then the string is not accpeted, otherwise if 1 then it is accepted. The main diagonal <span class="formula"><i>D</i></span> is enumerated as <span class="formula"><i>a</i><sub>1, 1</sub>, <i>a</i><sub>2, 2</sub>, <i>a</i><sub>3, 3</sub>, …, <i>a</i><sub><i>n</i>, <i>n</i></sub></span>. 
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-20.2">20.2</a> Diagonalization on the Enumerated Turing Machines<a class="Label" name="subsec:DiagonalizationOnTuringMachines"> </a>
</h2>
<div class="Unindented">
In order to diagonalize the table given by Figure<a class="Reference" href="#fig:TuringMachineAcceptanceTable">25 on page 1↑</a>. We form a sequence <span class="formula"><i>D</i></span> by complementing the values along the main diagonal. Formally <span class="formula"><i>D</i> = </span>\strikeout off\uuline off\uwave off<span class="formula"><i>a</i><sub><i>i</i>, <i>j</i></sub>, …, <i>a</i><sub><i>n</i>, <i>n</i></sub></span> where <span class="formula"><i>i</i> = <i>j</i></span>, and the value of <span class="formula"><i>a</i><sub><i>i</i>, <i>j</i></sub></span> is the complement of its value in the table shown in Figure<a class="Reference" href="#fig:TuringMachineAcceptanceTable">25 on page 1↑</a>. Now we come to the question: Could <span class="formula"><i>D</i></span> be a row representing the language accepted by a Turing Machine of the table? Suppose this imaginary row represented by the main diagonal <span class="formula"><i>D</i></span> where row <span class="formula"><i>k</i></span>, but it can’t be row <span class="formula"><i>k</i></span> because it disagrees at the <span class="formula"><i>k</i><sup><i>th</i></sup></span> entry. Therefore this cannot be the language of any Turing Machine, and further we can descibe this language as the set that contains the <span class="formula"><i>k</i><sup><i>th</i></sup></span> string if and only if the <span class="formula"><i>k</i><sup><i>th</i></sup></span> Turing Machine does not accept the <span class="formula"><i>k</i><sup><i>th</i></sup></span> string. We can name this language <span class="formula"><i>L</i><sub><i>D</i></sub></span> and since we know that we can not create a Turing Machine for this langauge, then we know that it is not recursively enumeable (Turing-recogizable), and thus no algorithm can be given to decide <span class="formula"><i>L</i><sub><i>D</i></sub>.</span>
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-20.3">20.3</a> Decidable Problems
</h2>
<div class="Unindented">
A problem is decidable if there is an algorithm to asnwer it. Recall, an algorithm formally speaking is a Turing Machine that halts on all inputs, accepted or not. Put another way a deciable problem is a recursive language. We may visualize the relationship among the language classes and the language <span class="formula"><i>L</i><sub><i>D</i></sub></span> which we identified in subsection<a class="Reference" href="#subsec:DiagonalizationOnTuringMachines">20.2 on page 1↑</a> in the Figure
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:DeciableLanguagesDiagram"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/DecidablityLanguageClass.png" alt="figure Diagrams/DecidablityLanguageClass.png" style="width: 122px; max-width: 244px; height: 109px; max-height: 218px;"/>

</div>
<div class="caption">
Figure 26  Here we see the hierarchy of the language classes and how they relate to <span class="formula"><i>L</i><sub><i>D</i></sub></span>. The Undeciable Languages also called the Recursively Enumerable Languages have a Turing Machive and are regarded to be Turing-recognizable. That is, they have a Turing Machine that will accept strings, but there is no guarantee that the machine will halt. Within this class is the Decidable Languages also called the Recursive Languages which have Turing Machines which are guranteed to distinguish string as either accepted or rejected and they also are guranteed to halt. At the otter most ring we have the language for which no Turing Machine exists and therefore they are unrecognizable.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-20.4">20.4</a> The Universal Turing Machine
</h2>
<div class="Unindented">
A Universal Turing Machine (UTM) is a Turing Machine which accepts as input a Turing Machine <span class="formula"><i>M</i></span> and some string <span class="formula"><i>w</i></span>. The UTM accepts <span class="formula"><i>M</i></span> if and only if <span class="formula"><i>M</i></span>accepts <span class="formula"><i>w</i>.</span> A UTM will have three tapes. Tape 1 holds the input <span class="formula"><i>M</i></span>encoded as binary and <span class="formula"><i>w</i>.</span> Tape 2 holds the tape of <span class="formula"><i>M</i></span>, and Tape 3 holds the state of <span class="formula"><i>M</i>.</span> The UTM proceeds by first checking the encoding of <span class="formula"><i>M</i>.</span> If <span class="formula"><i>M</i></span> is invalid, then its language is the empty language, and the UTM halts immediately and rejects. The UTM will then examine the size of <span class="formula"><i>M</i>’<i>s</i></span> symbols to determine the required word size. Next, the UTM will initialize Tape 2 to represent the tape of <span class="formula"><i>M</i></span>with the input <span class="formula"><i>w</i></span>, and initialize Tape 3 to hold the start state. Finally, the UTM can simulate <span class="formula"><i>M</i></span> by looking for a step in the transition function of <span class="formula"><i>M</i></span>encoded on Tape 1 that matches the state encoded on Tape 3 with a tape symbol under the head of Tape 2. If a match is found change the symbol and move the head marker on Tape 2 and change the State on Tape 3. If <span class="formula"><i>M</i></span>accepts, then the UTM accepts.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-20.5">20.5</a> The UTM is Recursively Enumerable and Not Recursive (The Halting Problem)<a class="Label" name="subsec:haltingProblem"> </a>
</h2>
<div class="Unindented">
Assume for the purposes of contradiction that the language of the UTM, that is <span class="formula"><i>L</i>(<i>UTM</i>)</span>, is recursive (decidable). Meaning that for every input it halts and returns an accepting or rejecting answer. We <i>somehow magically discover</i> an algorithm that can decide whether given a Turing Machine<span class="formula"><i>M</i></span> and an input string <span class="formula"><i>w</i></span> from the acceptance table featured in Figure<a class="Reference" href="#fig:TuringMachineAcceptanceTable">25 on page 1↑</a>– call this algorithm <i>wizzBang. </i>Remember <i>wizzBang </i>takes two paramters as arguments. First, we must have a valid Turing Machine <span class="formula"><i>M</i></span>, and second we must have a string <span class="formula"><i>w</i>.</span> We’re given an input <span class="formula"><i>M</i></span>. Let’s suppose <span class="formula"><i>M</i></span> is for the i-th string <span class="formula"><i>w</i></span> of our table. The first thing to do is check whether or not <span class="formula"><i>M</i></span> is a valid encoding for a Turing machine. If the encoding is NOT valid, then the i-th Turing Machine defines the empty language. That means <span class="formula"><i>w</i></span>, the i-th string, is not in the language of the i-th Turing machine. Therefore, <span class="formula"><i>w</i></span> IS in <span class="formula"><i>L</i><sub><i>D</i></sub></span>. Remeber we complemented the major diagonal so that answers here must be inverted. Now suppose <span class="formula"><i>M</i></span> is a valid encoding for a Turing machine. Then run <i>wizzBang</i> on the input <span class="formula"><i>M</i></span> and <span class="formula"><i>w</i></span>. Here <span class="formula"><i>M</i></span> represents the i-th Turing Machine processing the input that is the i-th string. Eventually, this algorithm will halt and tell us whether or not the i-th machine accepts the i-th string. If the <i>wizzBang</i> accepts the i-th machine accepts the i-th string, then we say reject because that means <span class="formula"><i>w</i></span> is not in <span class="formula"><i>L</i><sub><i>D</i></sub></span>. However, if <i>wizzBang</i> rejects, then we accept <span class="formula"><i>w</i></span>, because <span class="formula"><i>w</i></span> IS in <span class="formula"><i>L</i><sub><i>D</i></sub></span>. HERE IS THE MAIN POINT<span class="formula"> ⇒ </span> We previously proved in subsection<a class="Reference" href="#subsec:DiagonalizationOnTuringMachines">20.2 on page 1↑</a> that no Turing Machine can exist for <span class="formula"><i>L</i><sub><i>D</i></sub></span> and therefore we must conclude that <i>wizzBang cannot exist. </i>This tells us that the UTM is Recursively Enumerable (Turing-recognizable), but not Recursive (Decidable). We will regard the language of the UTM as <span class="formula"><i>L</i><sub><i>U</i></sub></span> going forward.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-21">21</a> Some Undeciable Problems
</h1>
<div class="Unindented">
In this section we cover Rice’s Theorem which states that almost every question we ask about Recursively Enumerable Languages is undeciable. Next we look to Post’s Correspondence Problem to bridge the gap between the world of Turing Machine to solving real world problems. In addition to the classical language classes we have defined we may define properties of languages. A property is a user defined set of languages. For example, the set of languages who are infinite languages have the Infiniteness Property. We can define a language <span class="formula"><i>L</i><sub><i>P</i></sub></span> as the set of TM’s such that each TM has the property <span class="formula"><i>P</i></span>. There are two trivial propertues <span class="formula"><i>P</i></span> for which <span class="formula"><i>L</i><sub><i>P</i></sub></span> is deciable. The always-false propety, which contains no Recursively Enumerable languages, and the always-true property, which contains every Recursively Enumerable language. Rice’s Theorem states that for every other property <span class="formula"><i>P</i></span> besides the trivial ones <span class="formula"><i>L</i><sub><i>P</i></sub></span> is undecidable. In order to prove Rice’s Theorem we will have to introduce the concept of reductions. A reduction is an algorithm (Recall, an algorithm is a TM that always halts), which transforms an input string <span class="formula"><i>w</i></span> in <span class="formula"><i>L</i></span> to a string <span class="formula"><i>x</i></span>in <span class="formula"><i>L</i>’</span> with the property that <span class="formula"><i>x</i></span>is in <span class="formula"><i>L</i>’</span> if and only if <span class="formula"><i>w</i></span> is in <span class="formula"><i>L</i>.</span> The takeaway here is that given the reduction for <span class="formula"><i>L</i></span> we are able to say that <span class="formula"><i>L</i></span> is no harder than <span class="formula"><i>L</i>’.</span> We can visualize reductions as shown in Figure<a class="Reference" href="#fig:Reductions">27 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:Reductions"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/Reduction.png" alt="figure Diagrams/Reduction.png" style="width: 182px; max-width: 365px; height: 75px; max-height: 151px;"/>

</div>
<div class="caption">
Figure 27  The transducer serves as an adaptor for the input string of <span class="formula"><i>w</i></span>. It transforms <span class="formula"><i>w</i></span> into a string <span class="formula"><i>x</i></span>which <span class="formula"><i>L</i>’</span> can consume and produce an accept or reject decision. Algorithm <span class="formula"><i>L</i>’</span> allows us to draw conclusions about the properties of <span class="formula"><i>L</i>.</span>
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-21.1">21.1</a> Rice’s Theorem
</h2>
<div class="Unindented">
We now need to prove the claim of Rice’s Theorem: Every nontrivial property <span class="formula"><i>P</i></span> of the Recursively Enumerable languages, <span class="formula"><i>L</i><sub><i>P</i></sub></span>, is undecidable. We’re going to assume that the empty language does not have property P. If that is not the case, then consider the complement of P, say Q. Surely the empty language then has property Q. But if we could prove that Q were undecidable, then P also must be undecidable. That is, if L_P were a recursive language, then so would be L_Q, since the class of recursive languages is closed under complementation. We will use the UTM (i.e. <span class="formula"><i>L</i><sub><i>U</i></sub></span>) obtained in Section<a class="Reference" href="#subsec:haltingProblem">20.5 on page 1↑</a>. In this reduction we reduce <span class="formula"><i>L</i><sub><i>U</i></sub></span> to <span class="formula"><i>L</i><sub><i>P</i></sub></span>. Because <span class="formula"><i>L</i><sub><i>U</i></sub></span> is undecidable this gives us the ability to say that <span class="formula"><i>L</i><sub><i>P</i></sub></span> is undecidable. Our reduction must take the parameters <span class="formula"><i>M</i></span>and <span class="formula"><i>w</i></span> and create a new Turing Machine <span class="formula"><i>M</i>’</span> such that <span class="formula"><i>L</i>(<i>M</i>’)</span> has property <span class="formula"><i>P</i></span> if and only if <span class="formula"><i>M</i></span> accepts <span class="formula"><i>w</i></span>. That is, the result of <span class="formula"><i>M</i>’</span> is contingent on the result of <span class="formula"><i>M</i></span>’s result from taking in <span class="formula"><i>w</i></span>. Our language property testing machine <span class="formula"><i>M</i>’</span> will be testing the language <span class="formula"><i>L</i></span> such that <span class="formula"><i>L</i></span> is any language with a property <span class="formula"><i>P</i></span>, and we let <span class="formula"><i>M</i><sub><i>L</i></sub></span> be a TM that accepts <span class="formula"><i>L</i></span>. <span class="formula"><i>M</i>’</span> simulates <span class="formula"><i>M</i></span> on input <span class="formula"><i>w</i></span>, and if <span class="formula"><i>M</i></span> accepts <span class="formula"><i>w</i></span> then <span class="formula"><i>M</i>’</span> simulates <span class="formula"><i>M</i><sub><i>L</i></sub></span> on the input <span class="formula"><i>x</i></span>to <span class="formula"><i>M</i>’</span>. <span class="formula"><i>M</i>’</span> accepts its input <span class="formula"><i>x</i></span>if and only if <span class="formula"><i>M</i><sub><i>L</i></sub></span> accepts <span class="formula"><i>x</i>.</span> Suppose <span class="formula"><i>M</i></span> accepts <span class="formula"><i>w</i></span>, then <span class="formula"><i>M</i>’</span>will simulate <span class="formula"><i>M</i><sub><i>L</i></sub></span> on input <span class="formula"><i>x</i></span>and therefore accepts <span class="formula"><i>x</i></span>if and only if <span class="formula"><i>x</i></span>is in <span class="formula"><i>L</i>.</span> Formally, <span class="formula"><i>L</i>(<i>M</i>’) = <i>L</i>(<i>M</i><sub><i>L</i></sub>) = <i>L</i></span>, the language of <span class="formula"><i>M</i>’</span> is the language of <span class="formula"><i>M</i><sub><i>L</i></sub></span>, <span class="formula"><i>L</i>(<i>M</i>’)</span> has property <span class="formula"><i>P</i></span>, and <span class="formula"><i>M</i>’</span> is in <span class="formula"><i>L</i><sub><i>P</i></sub>.</span> Now suppose the other case, <span class="formula"><i>M</i></span> does not accpet (never halts) <span class="formula"><i>w</i></span>, then <span class="formula"><i>M</i>’</span> never starts the simulation of <span class="formula"><i>M</i><sub><i>L</i></sub></span> and thus never accpets the input <span class="formula"><i>x</i></span>, so <span class="formula"><i>L</i>(<i>M</i>’) = <i>L</i>(<i>M</i><sub><i>L</i></sub>) = ∅</span>. Therefore, <span class="formula"><i>L</i>(<i>M</i>’)</span> does not have the property <span class="formula"><i>P</i></span>. <span class="formula"><i>M</i>’</span> is not in <span class="formula"><i>L</i><sub><i>P</i></sub></span>. This can viewed graphically in Figure<a class="Reference" href="#fig:schematicRiceTheoremTM">28 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:schematicRiceTheoremTM"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/riceTheoremTuringMachine.png" alt="figure Diagrams/riceTheoremTuringMachine.png" style="width: 192px; max-width: 385px; height: 102px; max-height: 205px;"/>

</div>
<div class="caption">
Figure 28  Here we see a schematic of the TM <span class="formula"><i>M</i>’</span> in which the language of <span class="formula"><i>M</i><sub><i>L</i></sub></span> is the language <span class="formula"><i>L</i><sub><i>P</i></sub></span> who can only run once if <span class="formula"><i>w</i></span> is accepted by M whose language is <span class="formula"><i>L</i><sub><i>U</i></sub></span>. As a whole this can be regarded as a reduction from <span class="formula"><i>L</i><sub><i>U</i></sub></span> to <span class="formula"><i>L</i><sub><i>P</i></sub></span>. Since we know <span class="formula"><i>L</i><sub><i>U</i></sub></span> is undeciable then so is <span class="formula"><i>L</i><sub><i>P</i></sub></span>. In essence it is bootstrapped by <span class="formula"><i>L</i><sub><i>U</i></sub></span> undecidability. 
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-21.2">21.2</a> Post’s Correspondence Problem
</h2>
<div class="Unindented">
Post’s Correspondence Problem (PCP) will be a tool for us to use in developing proving other problems are undecidable so its worth the effort of understanding. PCP asks: Is there some some ordering of indicies <span class="formula"><i>i</i><sub>1</sub>…<i>i</i><sub><i>k</i></sub></span> for a list of cooresponding strings <span class="formula">(<i>w</i><sub>1</sub>, <i>x</i><sub>1</sub>), (<i>w</i><sub>2</sub>, <i>x</i><sub>2</sub>), …, (<i>w</i><sub><i>n</i></sub>, <i>x</i><sub><i>n</i></sub>)</span> such that <span class="formula"><i>w</i><sub><i>i</i></sub>…<i>w</i><sub><i>n</i></sub> = <i>x</i><sub><i>i</i></sub>…<i>x</i><sub><i>n</i></sub>.</span> A restriction we place on this question is that neither strings of <span class="formula"><i>w</i><sub><i>i</i></sub></span> nor <span class="formula"><i>x</i><sub><i>i</i></sub></span> can be the empty string, and they share the same alphabet. In less formal terms, PCP asks is there a way of concatenating <span class="formula"><i>w</i></span>-type strings with <span class="formula"><i>x</i></span>-type strings so that they beome equivalent strings. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-21.3">21.3</a> PCP is Undecidable
</h2>
<div class="Unindented">
The proof that PCP is undeciable relies on two reductions. The first reduction is from <span class="formula"><i>L</i><sub><i>U</i></sub></span>, the language of the Univeral Turing Machine, to <span class="formula"><i>MPCP</i></span>. <span class="formula"><i>MPCP</i></span> can be regarded as a modified version of the PCP problem such that the first pair must be chosen first when forming the match on <span class="formula"><i>w</i></span> and <span class="formula"><i>x</i>.</span> Then next reduction is from <span class="formula"><i>MPCP</i></span> to <span class="formula"><i>PCP</i></span>.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-21.3.1">21.3.1</a> Reduction from <span class="formula"><i>L</i><sub><i>U</i></sub></span> to MPCP
</h3>
<div class="Unindented">
//TODO
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-21.3.2">21.3.2</a> Reduction from MPCP to PCP
</h3>
<div class="Unindented">
//TODO
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-21.4">21.4</a> Some Real Problems
</h2>
<div class="Unindented">
//TODO
</div>
<h1 class="Part">
<a class="toc" name="toc-Part-III">Part III.</a> Complexity
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-22">22</a> Time Complexity (Bachmann-Landau Notation)<a class="Label" name="sec:Big-O-Analysis"> </a>
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-23">23</a> Space Complexity
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-24">24</a> Intractable Problems
</h1>
<div class="Unindented">
In this section we learn about Time-Bounded Turing Machines, The Polynomial Class of Problems, P, and the Exponenetial Class of Problems, NP. Lastly we learn about Polynomial-Time Reductions. Refer to Michael Garey and David Johnson’s <i>Computers and Intractability: A Guide to the Theory of NP-Completeness </i>as a primary source for this subject matter.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.1">24.1</a> Time Bounded Turing Machines
</h2>
<div class="Unindented">
We say a Turing machine is <span class="formula"><i>T</i>(<i>n</i>)</span> time bounded, where<span class="formula"><i>T</i>(<i>n</i>)</span> is some function of <span class="formula"><i>n</i></span>, like <span class="formula"><i>n</i><sup>2</sup></span> or <span class="formula">2<sup><i>n</i></sup></span>, if given an input of length <span class="formula"><i>n</i></span>, the machine always halts in at most <span class="formula"><i>T</i>(<i>n</i>)</span> steps. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.2">24.2</a> The Partial Order of Equivalance Classes P, NP, and NP-complete
</h2>
<div class="Unindented">
A Turing machine <span class="formula"><i>M</i></span> is said to be polynomial-time bounded if it is time bounded by any polynomial. It could be linear, or quadratic, or cubic, or <span class="formula"><i>n</i><sup>1000</sup></span>, as long as it is some polynomial. The languages who are said to be bounded by polynomial time make up the Polynomial class P. For more complex polynomials you may wonder if they qualify for the class P. A problem qualifies to be in P if it is less than some polynomial. For example, <span class="formula"><i>O</i>(<i>nlogn</i>)</span> is less than <span class="formula"><i>O</i>(<i>n</i><sup>2</sup>)</span>, and therefore it qualifies for the class P. The nondeterminitic polynomial NP class of problems is defined in term of a NTM which has a polynomial time nondeterministic algorithm. The algorithm should be composed of two seperate states. Th first is the guessing stage, and the second is the checking stage. A nondeterministic algorithm &ldquo;solves&rdquo; a descisions problem <span class="formula">Π</span> if the followung two properties hold for all instances.
</div>
<ol>
<li>
If the instance of the problem is an accepting instance, then there exists <i>some</i> structure <span class="formula"><i>S</i></span> that, when guessed for the input of the instance, will lead to the checking stage to <i>accept</i> for the instance and <span class="formula"><i>S</i></span>.
</li>
<li>
If the instance of the problem is an rejecting instance, then there exists <i>no</i> structure <span class="formula"><i>S</i></span> that, when guessed for the input of the instance, will lead to the checking stage to <i>reject</i> for the instance and <span class="formula"><i>S</i></span>.
</li>

</ol>
<div class="Unindented">
If there is a polynomial bound on the number steps an NTM must take in any branch of its computation then the problem is in NP. The term &ldquo;complete problem&rdquo; for class of problems means that the problem embodies the essence of all other problems in the class. Even though it may appear that the problem doesn’t. PCP embodies Turing Machine computation. and the Knapsack Problem embodies all NTM computation. Polynomial Time reductions allow us to define NP-Complete problems. In order to show a problem <span class="formula"><i>M</i></span> to be NP-complete, we have to show that every problem in NP is somehow embedded in <span class="formula"><i>L</i></span>. We need a transformation from every problem in NP to <span class="formula"><i>M</i></span>, and this transformation has to be sufficiently fast that if we had a deterministic polynomial time algorithm for <span class="formula"><i>M</i></span>, then we could use it to build a deterministic polynomial time algorithm for each problem in NP. Formally, we say a problem or language <span class="formula"><i>M</i></span> is NP-complete if, first of all, it is in NP, and for every language <span class="formula"><i>L</i></span> in NP, there is a polytime reduction from <span class="formula"><i>L</i></span> to <span class="formula"><i>M</i></span>.
</div>
<div class="Indented">
A final point on producing creating nondeterministic algorithms for NP problems concerns the status of the algorithms complement. There is a lack of symmetry the accepting and rejecting instances. <i>In a deterministic algorithm</i>, for a problem &ldquo;Given an instance of the problem <span class="formula"><i>I</i></span>, is <span class="formula"><i>X</i></span> true for <span class="formula"><i>I</i></span>&rdquo;, where <span class="formula"><i>X</i></span> is some property, both the problem and its complement can be solved polynomially because a deterministic algorithm always halts. To obtain the complent you would just interchange the accepting and rejecting results. <i>In a nondeterministic algorithm</i>,<i> </i>for example the complement of the TSP problem–this is not the case. Consider the complement of TSP: &ldquo;Given a set of cities, intercity distances, and a bound <span class="formula"><i>B</i>, </span> is it true that <i>no</i> tour of all the citeis has length <span class="formula"><i>B</i></span>or less? There is no know way to verify a &ldquo;yes&rdquo; answer to this problem other than computing all possible tours (an exponential algorithm). Thus membership P for a given problem implies membership in coP. However membership in NP does not imply membership in coNP. The prefix &ldquo;co&rdquo; implies the complement of this language class. A tentative view of the world of NP can be seen in Figure<a class="Reference" href="#fig:npHiearchy">29 on page 1↓</a>.
</div>
<div class="Indented">
<div class="float">
<a class="Label" name="fig:npHiearchy"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/npHierarchy.png" alt="figure Diagrams/npHierarchy.png" style="width: 114px; max-width: 229px; height: 105px; max-height: 210px;"/>

</div>
<div class="caption">
Figure 29  This diagram gives a tentative view of the membership relationship among the different language classes.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.3">24.3</a> Encoding Schemes
</h2>
<div class="Unindented">
It is important to note the effect an encoding scheme can have on an algorithm. If the encoding scheme is poorly constructed the input length might become exponential and thus violate one of the rules of prooving NP-completeness. An example of reasonable encoding schemes can be seen in in Figure<a class="Reference" href="#fig:graphEncodingSchemes">30↓</a>. Similary, if the output of our polynomial reduction becomes is not described in a polynomial length of the input then it too violates the rules of prooving NP-completeness. An example of this is a variant of the Traveling Salesman Problem (TSP) problem. This variant gives a bounds <span class="formula"><i>B</i></span> and asks for all tours of length <span class="formula"><i>B</i></span> or less yielding exponentially many tours less than <b><span class="formula"><i>B</i></span>.</b> <div class="float">
<a class="Label" name="fig:graphEncodingSchemes"> </a><div class="figure">
<div class="PlainVisible">
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Encoding Schemes
</td>
<td align="center" valign="top">
String
</td>
<td align="center" valign="top">
Length
</td>

</tr>
<tr>
<td align="center" valign="top">
Vertex list, Edge list
</td>
<td align="center" valign="top">
V[1]V[2]V[3]V[4](V[1]V[2])(V[2]V[3])
</td>
<td align="center" valign="top">
36
</td>

</tr>
<tr>
<td align="center" valign="top">
Adjacency list
</td>
<td align="center" valign="top">
(V[2])(V[1]V[3])(V[2])()
</td>
<td align="center" valign="top">
24
</td>

</tr>
<tr>
<td align="center" valign="top">
Adjacency matrix
</td>
<td align="center" valign="top">
0100/1010/0010/0000
</td>
<td align="center" valign="top">
19
</td>

</tr>

</table>

</div>
<br/>
<div class="center">
<table>
<tr>
<td align="center" valign="top">
Lower Bound
</td>
<td align="center" valign="top">
Upper Bound
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">4<i>v</i> + 10<i>e</i></span>
</td>
<td align="center" valign="top">
<span class="formula">4<i>v</i> + 10<i>e</i> + (<i>v</i> + 2<i>e</i>)⋅<span class="symbol">⌈</span>log<sub>10</sub><i>v</i><span class="symbol">⌉</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula">2<i>v</i> + 8<i>e</i></span>
</td>
<td align="center" valign="top">
<span class="formula">2<i>v</i> + 8<i>e</i> + 2<i>e</i>⋅<span class="symbol">⌈</span>log<sub>10</sub><i>v</i><span class="symbol">⌉</span></span>
</td>

</tr>
<tr>
<td align="center" valign="top">
<span class="formula"><i>v</i><sup>2</sup> + <i>v</i> − 1</span>
</td>
<td align="center" valign="top">
<span class="formula"><i>v</i><sup>2</sup> + <i>v</i> − 1</span>
</td>

</tr>

</table>

</div>

</div>
<div class="caption">
Figure 30  The table above demonstrates how a graph’s description can be described. The string length is given by length column. For sparse graphs an adjaceny list representation is beneficial. Dense graphs should be represented in an adjacency matrix. The bounds describe the input length in terms of <span class="formula"><i>v</i></span> and <span class="formula"><i>e</i></span>, for <span class="formula"><i>G</i>(<i>V</i>, <i>E</i>)</span> where <span class="formula"><i>v</i> = |<i>V</i>|</span> and <span class="formula"><i>e</i> = |<i>E</i>|</span>. Graphs encoded in any of these schemes will differ at most polynomially for any instance of a graph.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.4">24.4</a> Transitivity of NP-completeness
</h2>
<div class="Unindented">
Polynomial transformations provide membership for languages to equivalence classes with the following Lemma. Visually this can be seen in the diagram for Figure<a class="Reference" href="#fig:schematicRiceTheoremTM">28 on page 1↑</a>.
</div>
<div class="Lemma">
If <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>2</sub></span> and <span class="formula"><i>L</i><sub>1</sub></span> <span class="formula"><i>ϵ</i></span><i>P, </i>then <span class="formula"><i>L</i><sub>2</sub></span> <span class="formula"><i>ϵ</i></span><i>P. </i>Equivalently, If <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>2</sub></span> and <span class="formula"><i>L</i><sub>1</sub></span> <span class="formula">¬<i>ϵ</i></span><i> P, </i>then <span class="formula"><i>L</i><sub>2</sub></span> <span class="formula">¬<i>ϵ</i></span><i> P.<a class="Label" name="lem:pMembership"> </a></i>
</div>
<div class="Proof">
Let <span class="formula">Σ<sub>1</sub></span>and <span class="formula">Σ<sub>2</sub></span> be the alphabets of languages <span class="formula"><i>L</i><sub>1</sub></span> and <span class="formula"><i>L</i><sub>2</sub></span> respectively, and let the function <span class="formula"><i>f</i>:Σ<span class="scripts"><sup class="script">*</sup><sub class="script">1</sub></span> → Σ<span class="scripts"><sup class="script">*</sup><sub class="script">2</sub></span></span> be a <i>polytime</i> function from <span class="formula"><i>L</i><sub>1</sub></span> to <span class="formula"><i>L</i><sub>2</sub></span>. Let <span class="formula"><i>M</i><sub><i>f</i></sub></span> be a determinitic <i>polytime</i> DTM recoginizer computing the function <span class="formula"><i>f</i></span>. Let <span class="formula"><i>M</i><sub>2</sub></span> be a <i>polytime </i>DTM recognzier for <span class="formula"><i>L</i><sub>2</sub>.</span> A <i>polytime</i> recognizer for <span class="formula"><i>L</i><sub>1</sub></span> can be constructed by composing <span class="formula"><i>M</i><sub><i>f</i></sub></span> and <span class="formula"><i>M</i><sub>2</sub></span>. For an input <span class="formula"><i>x</i></span><span class="formula"><i>ϵ</i></span> <span class="formula"><i>L</i><sub>1</sub></span> we first apply the part of the program attributed to <span class="formula"><i>M</i><sub><i>f</i></sub></span> which yields <span class="formula"><i>f</i>(<i>x</i>)</span> <span class="formula"><i>ϵ</i></span> <span class="formula">Σ<sub>2</sub></span> ( a string of the <span class="formula"><i>L</i><sub>2</sub></span>’s alphabet). We the apply the recognizer <span class="formula"><i>M</i><sub>2</sub></span> to the program to determine if the string <span class="formula"><i>f</i>(<i>x</i>)</span> <span class="formula"><i>ϵ</i></span><span class="formula"><i>L</i><sub>2</sub>.</span> Since <span class="formula"><i>x</i></span><span class="formula"><i>ϵ</i></span><span class="formula"><i>L</i><sub>1</sub></span> if and only if <span class="formula"><i>f</i>(<i>x</i>)</span> <span class="formula"><i>ϵ</i></span><span class="formula"><i>L</i><sub>2</sub></span> we now have a recognizer for <span class="formula"><i>L</i><sub>1</sub>.</span> The fact that this yields a polynomial algorithm is derived from the fact that both <span class="formula"><i>M</i><sub><i>f</i></sub></span> and <span class="formula"><i>M</i><sub>2</sub></span> are polytime algorithms themselves. 
</div>
<div class="Unindented">
Reductions have the feature of transitivity. 
</div>
<div class="Lemma">
That is, if <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>2</sub></span> and <span class="formula"><i>L</i><sub>2</sub> ∝ <i>L</i><sub>3</sub></span>, then <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>3</sub></span>.<a class="Label" name="lem:reductionTransitiviy"> </a>
</div>
<div class="Proof">
Let <span class="formula">Σ<sub>1</sub>, Σ<sub>2</sub>, Σ<sub>3</sub></span> be the alphabets for <span class="formula"><i>L</i><sub>1</sub>, <i>L</i><sub>2</sub></span> and <span class="formula"><i>L</i><sub>3</sub></span> respectively. The function mapping the language of <span class="formula"><i>L</i><sub>1</sub></span> to the language of <span class="formula"><i>L</i><sub>2</sub></span> is given by <span class="formula"><i>f</i><sub>1</sub>:Σ<span class="scripts"><sup class="script">*</sup><sub class="script">1</sub></span> → Σ<span class="scripts"><sup class="script">*</sup><sub class="script">2</sub></span></span>, and the function mapping the language of <span class="formula"><i>L</i><sub>2</sub></span> to the language of <span class="formula"><i>L</i><sub>3</sub></span> is <span class="formula"><i>f</i><sub>2</sub>:Σ<span class="scripts"><sup class="script">*</sup><sub class="script">2</sub></span> → Σ<span class="scripts"><sup class="script">*</sup><sub class="script">3</sub></span></span>. Then the function transforming the language of <span class="formula"><i>L</i><sub>1</sub></span> to the language of <span class="formula"><i>L</i><sub>3</sub></span> is the composition of the given functions, <span class="formula"><i>f</i>(<i>x</i>) = <i>f</i><sub>2</sub>(<i>f</i><sub>1</sub>(<i>x</i>))</span>, for all strings <span class="formula"><i>x</i></span>in <span class="formula"><i>L</i><sub>1</sub></span>. Clearly, <span class="formula"><i>f</i>(<i>x</i>)<i>ϵ</i><i>L</i><sub>3</sub></span> if and only if <span class="formula"><i>x</i><i>ϵ</i><i>L</i><sub>1</sub></span>. The fact that <span class="formula"><i>f</i></span> can be computed polynomially is derived from Lemma<a class="Reference" href="#lem:pMembership">24.4 on page 1↑</a>.
</div>
<div class="Unindented">
An import lemma that allows us to constuct the NP-complete equivalence class is the application of reduction transitivity to NP-complete problems.
</div>
<div class="Lemma">
If <span class="formula"><i>L</i><sub>1</sub></span> and <span class="formula"><i>L</i><sub>2</sub></span> belong to NP, <span class="formula"><i>L</i><sub>1</sub></span> is NP-complete, and <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>2</sub></span>, then <span class="formula"><i>L</i><sub>2</sub></span> is NP-complete.
</div>
<div class="Proof">
Since <span class="formula"><i>L</i><sub>2</sub></span> <span class="formula"><i>ϵ</i></span><i>NP</i> all we need to do is show that, for every <span class="formula"><i>L</i>’</span><i> <span class="formula"><i>ϵ</i></span> NP</i>, <span class="formula"><i>L</i>’ ∝ <i>L</i><sub>2</sub></span>. Consider any <span class="formula"><i>L</i>’</span> <span class="formula"><i>ϵ</i></span> <i>NP</i>. Since <span class="formula"><i>L</i><sub>1</sub></span> is NP-complete, then surely <span class="formula"><i>L</i>’ ∝ <i>L</i><sub>1</sub></span> by the definition of NP-completeness. The tranistivity of <span class="formula"> ∝ </span> seen in Lemma<a class="Reference" href="#lem:reductionTransitiviy">24.4 on page 1↑</a>, and the fact that <span class="formula"><i>L</i><sub>1</sub> ∝ <i>L</i><sub>2</sub></span> implies that <span class="formula"><i>L</i>’ ∝ <i>L</i><sub>2</sub></span> . 
</div>
<div class="Proof">
So it clear that once we have a single NP-complete problem to stand in for <span class="formula"><i>L</i><sub>1</sub></span> it serves as a means to bootstrap the process of creating the NP-complete equivalence class. The first NP-complete problem that allows the process was provided by Steve Cook and is discussed in Section<a class="Reference" href="#subsec:Cook's-Theorem">24.7 on page 1↓</a>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.5">24.5</a> Prooving NP-completeness
</h2>
<div class="Unindented">
In order to prove that a problem is NP-complete you will need to demonstrate the following:
</div>
<ol>
<li>
Show that the problem is in NP by giving a nondeterministic polytime decider.
</li>
<li>
Select an known NP-complete problem.
</li>
<li>
Construct a transformation function <span class="formula"><i>f</i></span> from the NP-completer problem to the problem in question.
</li>
<li>
Prove that the tranformation function <span class="formula"><i>f</i></span> is a polynomial tranformaton.
</li>

</ol>
<div class="Unindented">
Garey and Johnson suggest that three design patterns exist for proving NP-completeness: restriction, local replacement and component design. Descriptions of the three patters are given.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-24.5.1">24.5.1</a> Restriction
</h3>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-24.5.2">24.5.2</a> Local Replacement
</h3>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-24.5.3">24.5.3</a> Component Design
</h3>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.6">24.6</a> Polynomial Time Reductions
</h2>
<div class="Unindented">
Polynomial time transducers are TM’s that take in an input of length n, operate deterministically for some polynomial time <span class="formula"><i>p</i>(<i>n</i>)</span>. Produces an output on a separate output tape, and the output must me at most <span class="formula"><i>p</i>(<i>n</i>)</span>. Consider two languages or problems, say <span class="formula"><i>L</i></span> and <span class="formula"><i>M</i></span>. We say <span class="formula"><i>L</i></span> is polytime-reducible to <span class="formula"><i>M</i></span> if there is a polytime transducer <span class="formula"><i>T</i></span> that takes an input <span class="formula"><i>w</i></span> that is an instance of <span class="formula"><i>L</i></span>, produces output <span class="formula"><i>x</i></span> that is an instance of <span class="formula"><i>M</i></span>, and the answer to <span class="formula"><i>L</i></span> on <span class="formula"><i>w</i></span> is the same as the answer to <span class="formula"><i>M</i></span> on <span class="formula"><i>x</i></span>. That is, <span class="formula"><i>w</i></span> is in <span class="formula"><i>L</i></span> if and only if <span class="formula"><i>x</i></span> is in <span class="formula"><i>M</i></span>. 
</div>
<div class="Indented">
Steve Cook and Dick Karp were the pioneers of NP-Completeness theory. Cook concentrated on 3-SAT – the question of whether an expression of proposeitional logic was satisfiable, that is, made true by some assignment of truth values to the propositional variables. But shortly after Cook wrote his original paper on NP-completeness, Dick Karp wrote another paper that showed many of the classical problems that had been puzzling mathematicians, sometimes for centuries, were NP-complete. Karp used only polytime reductions to the problem Cook had proved NP-complete. Since then, it is generally accepted that the preferred definition of NP-completeness is the one we gave here – the existence of polytime reductions. To make the distinction, this notion of NP-completeness is often called Karp-completeness. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-24.7">24.7</a> Cook’s Theorem<a class="Label" name="subsec:Cook's-Theorem"> </a>
</h2>
<div class="Unindented">
Recall from the Section<a class="Reference" href="#sec:propositionalSententialLogic">1.1 on page 1↑</a> on propositional logic that we expresses the truth of expressions with boolean operators. Expressions are built from two components variables and constants using boolean the operators (<span class="formula">∧, ∨, ¬).</span> Constants and the value of variables are either true (1) or false (0). The order of precedence for the boolean operatios is NOT, AND, OR. The Satisfiability Problem (SAT) is concened with determinig if there is a satisfying assignment of boolean values to an expression such that the expression is true. Instances of the SAT problem are represented with the parenthesis, logical operators, and variables <span class="formula"><i>x</i><sub><i>i</i></sub></span> where <span class="formula"><i>i</i></span> is the <span class="formula"><i>i</i><sup><i>th</i></sup></span> binary integer. 
</div>
<div class="Indented">
In order to prove that SAT is NP-Complete we must first show that it is in NP. This can be done by giving an NTM that decides if an instance of SAT of length <span class="formula"><i>n</i></span>is satisfiable. The algorithm for this Turing Machine can use nondeterminisc guessing to accomplish the goal. First the NTM guesses truth values for the variables of the expression. The NTM then checks the truth values of the expression. If the expression is true, then accept, otherwise reject. We now know that SAT is in NP.
</div>
<div class="Indented">
The next step is to prove that SAT is NP-complete. Refer to Garey and Johnson pg 39-44 for the indepth proof. Prior to reading this you should understand Logic Programming <a class="FlexURL" href="https://en.wikipedia.org/wiki/Logic_programming">https://en.wikipedia.org/wiki/Logic_programming</a> and Lambda Calculus <a class="FlexURL" href="https://en.wikipedia.org/wiki/Lambda_calculus">https://en.wikipedia.org/wiki/Lambda_calculus</a>. At a high level the transformation function that they provide is based on the idea that the intermediate descriptions of the Turing machine can be translated into logical programming constraints which represent the clauses of the satisfiability problem. 
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-25">25</a> Specific NP-Complete Problems
</h1>
<div class="Unindented">
Garey and Johnson provide six additional foundational NP-complete problems which they have found to be the most useful. The relationship between these problems can be seen in Figure<a class="Reference" href="#fig:npCompleteTree">31 on page 1↓</a>. 
</div>
<ol>
<li>
3SAT asks the question: Is there a truth assignment for a set of clauses in which all clauses have 3 variables? 
</li>
<li>
Three Dimmensional Matching asks the question: For the Cartesian product of three disjount sets <span class="formula"><i>X</i>, <i>Y</i>, </span> and <span class="formula"><i>Z</i></span>, is there some subset of the product that has unique coordinates for all members of the set? Formally, <span class="formula"><i>X</i> × <i>Y</i> × <i>Z</i></span> = P, where the <span class="formula">|<i>X</i>| = |<i>Y</i>| = |<i>Z</i>| = <i>q</i></span>, does there exists a matching <span class="formula"><i>M</i> ⊆ <i>P</i></span> such that for all members of <span class="formula"><i>M</i></span> no coordiates of the triple <span class="formula">(<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>, <i>z</i><sub><i>i</i></sub>)</span> are duplicated in any other element of <span class="formula"><i>M</i></span>, with <span class="formula">|<i>M</i>| = <i>q</i></span>? That is, for M = {<span class="formula">(<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>, <i>z</i><sub><i>i</i></sub>)</span> ,<span class="formula">(<i>x</i><sub><i>j</i></sub>, <i>y</i><sub><i>j</i></sub>, <i>z</i><sub><i>j</i></sub>), </span><span class="formula">…, (<i>x</i><sub><i>q</i></sub>, <i>y</i><sub><i>q</i></sub>, <i>z</i><sub><i>q</i></sub>)</span>}, <span class="formula"><i>x</i><sub><i>i</i></sub> ≠ <i>x</i><sub><i>j</i></sub></span>, <span class="formula"><i>y</i><sub><i>i</i></sub> ≠ <i>y</i><sub><i>j</i></sub></span>, and <span class="formula"><i>z</i><sub><i>i</i></sub> ≠ <i>z</i><sub><i>j</i></sub></span>. 
</li>
<li>
Vertex Cover asks the question: Is there a vertex cover for a given graph <span class="formula"><i>G</i></span> of size <span class="formula"><i>K</i></span> or less? A vertex cover is a set of vertices of a graph who are incident on edges which whose vertices make up all the vertices of the graph. Formally, for a graph <span class="formula"><i>G</i>(<i>V</i>, <i>E</i>), </span> is there a vertex cover <span class="formula"><i>V</i>’ ⊆ <i>V</i></span> such that <span class="formula">|<i>V</i>’| ≤ <i>K</i></span>, and for each edge <span class="formula">{<i>u</i>, <i>v</i>}</span> <span class="formula"><i>ϵ</i></span> <span class="formula"><i>E</i></span> either <span class="formula"><i>u</i></span> or <span class="formula"><i>v</i></span> belong to <span class="formula"><i>V</i>’</span>, but not both?
</li>
<li>
Clique asks the question: For a given graph <span class="formula"><i>G</i>(<i>V</i>, <i>E</i>)</span> is there a strongly connected component of size <span class="formula"><i>J</i></span> or more in <span class="formula"><i>G</i></span>? A strongly connected componenet is a set of vertices with a path between all pairs of vertices (i.e. a complete subgraph)
</li>
<li>
.Hamiltonian Circuit asks the question: Is there a cycle in the graph in which all vertices are visited only once? Formally, for a given graph <span class="formula"><i>G</i>(<i>V</i>, <i>E</i>)</span>, with <span class="formula"><i>V</i> = {<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …<i>v</i><sub><i>n</i></sub>}</span>, where n = <span class="formula">|<i>V</i>|</span>. Is there an ordering of the members of <span class="formula"><i>V</i></span> such that <span class="formula">{<i>v</i><sub>1, </sub><i>v</i><sub><i>n</i></sub>}</span> <span class="formula"><i>ϵ</i></span> <span class="formula"><i>E</i></span> and <span class="formula">{<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i> + 1</sub>}</span> <span class="formula"><i>ϵ</i></span> <span class="formula"><i>V</i></span> for all <span class="formula"><i>i</i></span>, <span class="formula">1 ≤ <i>i</i> &lt; <i>n</i></span>?
</li>
<li>
Partition asks the question: Is there some way to evenly dividing a set of elements such that the sum of their values is equivalent? Formally, for a given set of elements <span class="formula"><i>A</i> = {<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, …<i>a</i><sub><i>n</i></sub>}</span>, where <span class="formula"><i>weight</i>(<i>a</i><sub><i>i</i></sub>)</span> <span class="formula"><i>ϵ</i></span><span class="formula">ℤ<sup> + </sup></span>, is there a set <span class="formula"><i>A</i>’ ⊆ <i>A</i></span> such that:<div class="formula">
<span class="displaystyle"><span class="limits"><span class="limit">⎲</span><span class="limit">⎳</span></span></span><sub><i>a</i><i>ϵ</i><i>A</i>’</sub><i>weight</i>(<i>a</i>) = <span class="limits"><sup class="limit"> </sup><span class="limit">⎲</span><span class="limit">⎳</span><sub class="limit"><i>a</i><i>ϵ</i><i>A</i> − <i>A</i>’</sub></span><i>weight</i>(<i>a</i>)
</div>

</li>

</ol>
<div class="Unindented">
<div class="float">
<a class="Label" name="fig:npCompleteTree"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/npcompleteTree.png" alt="figure Diagrams/npcompleteTree.png" style="width: 167px; max-width: 335px; height: 117px; max-height: 235px;"/>

</div>
<div class="caption">
Figure 31 This diagram depicts the hiearchy of the NP-completeness proofs in this section.
</div>

</div>

</div>

</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.1">25.1</a> SAT to 3SAT
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.2">25.2</a> 3SAT to 3DIMM Matching
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.3">25.3</a> 3DIMM Matching to Partition
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.4">25.4</a> 3SAT to Vertex Cover
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.5">25.5</a> Vertex Cover to Hamiltonian Circuit
</h2>
<div class="Unindented">
For the given graph G, the graph <span class="formula"><i>G</i>’</span> can be generated to demonstrate the equivalence of VC and HC. You can view both of these graphs in Figure<a class="Reference" href="#fig:vcToHC">32 on page 1↓</a>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-25.6">25.6</a> Vertex Cover to Clique
</h2>
<div class="Unindented">
<div class="float">
<a class="Label" name="fig:vcToHC"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Diagrams/vcToHC.png" alt="figure Diagrams/vcToHC.png" style="width: 160px; max-width: 321px; height: 108px; max-height: 216px;"/>

</div>
<div class="caption">
Figure 32  A polynomial time mapping reduction from a graph <span class="formula"><i>G</i></span> with a vertex cover of size <span class="formula">|<i>K</i>|</span> allows us to generate a graph <span class="formula"><i>G</i>’</span> which has a Hamiltonian circuit. Here <span class="formula"><i>K</i> = {<i>a</i><sub>1</sub>}.</span> 
</div>

</div>

</div>

</div>
<h1 class="Part">
<a class="toc" name="toc-Part-IV">Part IV.</a> Algorithms
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-26">26</a> Data Structures
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-26.1">26.1</a> Graphs
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-26.2">26.2</a> Trees
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-26.3">26.3</a> Lists
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-26.4">26.4</a> Queues
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-26.5">26.5</a> Arrays
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-27">27</a> Optimatility
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-28">28</a> Approximation Algorithms<a class="Label" name="sec:Approximation-Algorithms"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-28.1">28.1</a> Backtracking
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-28.2">28.2</a> Branch and Bound
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-28.3">28.3</a> Local Search
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-29">29</a> Randomized Algorithms<a class="Label" name="sec:Randomization-Algorithms"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-29.1">29.1</a> Las Vegas and Monte Carlo
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-29.2">29.2</a> Game Theoretic Techniques
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-29.3">29.3</a> Moments and Deviations
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-29.4">29.4</a> Tail Inequalities
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-29.5">29.5</a> The Probablistic Method
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-30">30</a> Dynamic Programming<a class="Label" name="sec:Dynamic-Programming"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-30.1">30.1</a> Recurrence Relations
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-30.2">30.2</a> Memoization
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-31">31</a> Fast Fourier Transform<a class="Label" name="sec:Fast-Fourier-Transform"> </a>
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-32">32</a> Shortest Path Algorithms
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-32.1">32.1</a> Dijkstra
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-32.2">32.2</a> Bellman-Ford
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-33">33</a> Maximum Flow<a class="Label" name="sec:Maximum-Flow"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.1">33.1</a> Flows and Cuts
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.2">33.2</a> The Max-Flow Min-Cut Theorem
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.3">33.3</a> Flow Networks, Residual Networks, and Augmenting Flows
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.4">33.4</a> Ford-Fulkerson Algorithm
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.5">33.5</a> The Scaling Algorithm
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.6">33.6</a> Edmonds-Karp Algorithm
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-33.7">33.7</a> Dinic’s Algorithm
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-34">34</a> Bipartite Matching<a class="Label" name="sec:Bipartite-Matching"> </a>
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-34.1">34.1</a> Nomencalture– Matchings, Perfect Matchings, Maximum Matchings, and Bipartiteness
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-34.2">34.2</a> The Frobenius-Hall Theorem
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-34.3">34.3</a> Hopcroft-Karp Algorithm
</h2>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-34.4">34.4</a> The Hungarian Algorithm
</h2>
<h1 class="Section">
<a class="toc" name="toc-Section-35">35</a> Appendix: Reference Material<a class="Label" name="sec:Appendix:-Reference-Material"> </a>
</h1>
<div class="Unindented">
The following sections provide some useful resources that will help you along the way. 
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-35.1">35.1</a> Software
</h2>
<ul>
<li>
Draw.io is a online tool for creating all sorts of diagrams. It will be useful when creating automata.<a class="FlexURL" href="https://www.draw.io">https://www.draw.io</a>
</li>
<li>
LyX is a \SpecialChar LaTeX word processing application that will be useful when drafting homework.<a class="FlexURL" href="https://www.lyx.org">https://www.lyx.org</a>
</li>
<li>
Python is a useful programming language for experimenting with algorithms. <a class="FlexURL" href="https://www.python.org">https://www.python.org</a>
</li>
<li>
Mendeley is a good tool to organize your electronic library of books and journal articles. <a class="FlexURL" href="https://www.mendeley.com/">https://www.mendeley.com/</a>
</li>
<li>
Mathematica or MatLab to help your with linear programming <a class="FlexURL" href="https://software.oit.gatech.edu">https://software.oit.gatech.edu</a>
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-35.2">35.2</a> Books
</h2>
<div class="Unindented">
Even if you buy all these books it will not make you any better. I strongly suggest you acquire these for free and purchase the ones you find useful at a later date.
</div>
<ul>
<li>
<i>How to Prove It: A Structured Approach</i> by Daniel J. Velleman <a class="FlexURL" href="https://amzn.com/0521675995">https://amzn.com/0521675995</a>
</li>
<li>
<i>Mathematical Reasoning: Writing and Proof</i> by Ted Sundstrom <a class="FlexURL" href="https://amzn.com/1500143413">https://amzn.com/1500143413</a>
</li>
<li>
<i>Book of Proof</i> by Richard Hammack <a class="FlexURL" href="https://amzn.com/0989472108">https://amzn.com/0989472108</a>
</li>
<li>
<i>Understanding Analysis</i> by Stephen Abbot <a class="FlexURL" href="https://amzn.com/1493927116">https://amzn.com/1493927116</a>
</li>
<li>
<i>Introduction to Probability</i> by Dimitri P. Bertsekas and John N. Tsitsiklis <a class="FlexURL" href="https://amzn.com/188652923X">https://amzn.com/188652923X</a>
</li>
<li>
<i>Discrete Mathematics and Its Applications</i> by Kenneth Rosen <a class="FlexURL" href="https://amzn.com/0073383090">https://amzn.com/0073383090</a>
</li>
<li>
<i>Introduction to the Theory of Computation</i> by Michael Sipser <a class="FlexURL" href="https://amzn.com/113318779X">https://amzn.com/113318779X</a>
</li>
<li>
<i>Introduction to Automata Theory, Languages and Computation</i> by John Hopcroft, Rajeev Motwani and Jeffery Ullman <a class="FlexURL" href="https://amzn.com/0321455363">https://amzn.com/0321455363</a>
</li>
<li>
<i>Computers and Intractability: A Guide to the Theory of NP-Completeness</i> by Michael Garey and David Johnson <a class="FlexURL" href="https://amzn.com/0716710455">https://amzn.com/0716710455</a>
</li>
<li>
<i>Algorithm Design</i> by Jon Kleinberg and Eva Tardos <a class="FlexURL" href="https://amzn.com/0321295358">https://amzn.com/0321295358</a>
</li>
<li>
<i>Algorithms</i> by Sanjoy Dasgupta, Christos Papadimitriou, and Vijay Vazirani <a class="FlexURL" href="https://amzn.com/0073523402">https://amzn.com/0073523402</a>
</li>
<li>
<i>Introduction to Algorithms</i> by Thomas Cormen, Charles Leiserson, Ronald Rivest, and Clifford Stein <a class="FlexURL" href="https://amzn.com/0262033844">https://amzn.com/0262033844</a>
</li>
<li>
<i>Approximation Algorithms</i> by Vijay Vazirani <a class="FlexURL" href="https://amzn.com/3540653678">https://amzn.com/3540653678</a>
</li>
<li>
<i>Randomized Algorithms</i> by Rajeev Motwani and Raghavan Prabhakar <a class="FlexURL" href="https://amzn.com/0521474655">https://amzn.com/0521474655</a>
</li>
<li>
<i>Linear Algebra and Its Applications </i>by David C. Lay <a class="FlexURL" href="https://amzn.com/032198238X">https://amzn.com/032198238X</a>
</li>
<li>
<i>Linear and Nonlinear Programming</i> by David Luenberger and Ye Yingyu <a class="FlexURL" href="https://amzn.com/3319188410">https://amzn.com/3319188410</a>
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-35.3">35.3</a> Videos
</h2>
<ul>
<li>
Professor Harry Porter’s YouTube playlist on the theory of computation. <a class="FlexURL" href="https://www.youtube.com/playlist?list=PLbtzT1TYeoMjNOGEiaRmm_vMIwUAidnQz">https://www.youtube.com/playlist?list=PLbtzT1TYeoMjNOGEiaRmm_vMIwUAidnQz</a>
</li>
<li>
Professor Tim Roughgardener’s playlist on Logic <a class="FlexURL" href="https://www.youtube.com/playlist?list=PLLH73N9cB21Xsgy39DP3xDqBN3lTaR8R5">https://www.youtube.com/playlist?list=PLLH73N9cB21Xsgy39DP3xDqBN3lTaR8R5</a> 
</li>
<li>
Professor Tim Roughgardener’s playlist on Data Structures and Algorithms I <a class="FlexURL" href="https://www.youtube.com/playlist?list=PLLH73N9cB21W1TZ6zz1dLkyIm50HylGyg">https://www.youtube.com/playlist?list=PLLH73N9cB21W1TZ6zz1dLkyIm50HylGyg</a> 
</li>
<li>
Professor Tim Roughgardener’s playlist on Data Structures and Algorithms II <a class="FlexURL" href="https://www.youtube.com/playlist?list=PLLH73N9cB21VPj3H2xwTTye5TC8-UniA2">https://www.youtube.com/playlist?list=PLLH73N9cB21VPj3H2xwTTye5TC8-UniA2</a>
</li>

</ul>

</div>
</body>
</html>
